{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e50f283",
   "metadata": {},
   "source": [
    "# <center> Poisson Fourier Neural Operator training for sparse2dense experiments</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a7b9d",
   "metadata": {},
   "source": [
    "In this notebook we train the PoissonNet for the experiment sparse2dense where we test its performance when varying the sampling rate and the gaussian smoothing parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1909837",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9c31b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities from dave\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../fourier_neural_operator/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b936b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utilities3 import *\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "\n",
    "from Adam import Adam\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b6168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/scratch/Github_repos/DeepShapeRecon/FNO_sparse2dense_sampling/utils.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95954b95",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afeb53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 30\n",
    "modes = 10\n",
    "training_steps = 10000\n",
    "learning_rate = 0.0025\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae54c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/'\n",
    "# batch_size = 20\n",
    "# n_samples = 5000\n",
    "# sigma = 2\n",
    "\n",
    "root_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/'\n",
    "batch_size = 20\n",
    "n_samples = 10000\n",
    "sigma = 1.5\n",
    "\n",
    "# root_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/'\n",
    "# batch_size = 20\n",
    "# n_samples = 25000\n",
    "# sigma = 1.0\n",
    "\n",
    "# root_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/'\n",
    "# batch_size = 20\n",
    "# n_samples = 50000\n",
    "# sigma = 0.7\n",
    "\n",
    "# root_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/'\n",
    "# batch_size = 20\n",
    "# n_samples = 100000\n",
    "# sigma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a612c307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/Github_repos/DeepShapeRecon/FNO_sparse2dense_sampling/utils.py:1787: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  self.files_name = np.array(np.array([x for x in\n"
     ]
    }
   ],
   "source": [
    "loader_train = utils.ShapeNet_FNO_sparse2dense_DataLoader(root_path, n_samples, sigma, 'train', batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c003c490",
   "metadata": {},
   "source": [
    "## PoissonNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac367e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "model = utils.FNO3d(modes, modes, modes, width).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d31a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e0a099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/scratch/Data/Fourier_Neural_Data/Sparse2Dense/checkpoints/n_samples_'+str(n_samples)+'_sigma_'+str(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad4639bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 10.20\n",
    "if 1:\n",
    "    model.load_state_dict(torch.load(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e34deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  0  of  100000  with loss  13.239762306213379\n",
      "Training step  1  of  100000  with loss  10.986595153808594\n",
      "Training step  2  of  100000  with loss  12.421419143676758\n",
      "Training step  3  of  100000  with loss  12.48019027709961\n",
      "Training step  4  of  100000  with loss  11.448732376098633\n",
      "Training step  5  of  100000  with loss  13.71816635131836\n",
      "Training step  6  of  100000  with loss  13.548208236694336\n",
      "Training step  7  of  100000  with loss  12.164697647094727\n",
      "Training step  8  of  100000  with loss  11.237825393676758\n",
      "Training step  9  of  100000  with loss  13.851476669311523\n",
      "Training step  10  of  100000  with loss  12.168966293334961\n",
      "Training step  11  of  100000  with loss  12.655155181884766\n",
      "Training step  12  of  100000  with loss  12.428014755249023\n",
      "Training step  13  of  100000  with loss  12.21209716796875\n",
      "Training step  14  of  100000  with loss  10.992338180541992\n",
      "Training step  15  of  100000  with loss  11.740423202514648\n",
      "Training step  16  of  100000  with loss  12.919443130493164\n",
      "Training step  17  of  100000  with loss  11.138392448425293\n",
      "Training step  18  of  100000  with loss  10.228497505187988\n",
      "Training step  19  of  100000  with loss  11.721105575561523\n",
      "Training step  20  of  100000  with loss  11.450422286987305\n",
      "Training step  21  of  100000  with loss  11.545509338378906\n",
      "Training step  22  of  100000  with loss  11.530519485473633\n",
      "Training step  23  of  100000  with loss  11.536870956420898\n",
      "Training step  24  of  100000  with loss  10.850409507751465\n",
      "Training step  25  of  100000  with loss  11.74638557434082\n",
      "Training step  26  of  100000  with loss  12.10055160522461\n",
      "Training step  27  of  100000  with loss  10.323315620422363\n",
      "Training step  28  of  100000  with loss  11.580894470214844\n",
      "Training step  29  of  100000  with loss  12.07911491394043\n",
      "Training step  30  of  100000  with loss  13.12949275970459\n",
      "Training step  31  of  100000  with loss  10.996650695800781\n",
      "Training step  32  of  100000  with loss  13.285379409790039\n",
      "Training step  33  of  100000  with loss  11.125597953796387\n",
      "Training step  34  of  100000  with loss  11.136550903320312\n",
      "Training step  35  of  100000  with loss  11.06938362121582\n",
      "Training step  36  of  100000  with loss  12.172298431396484\n",
      "Training step  37  of  100000  with loss  11.755727767944336\n",
      "Training step  38  of  100000  with loss  10.788936614990234\n",
      "Training step  39  of  100000  with loss  12.821361541748047\n",
      "Training step  40  of  100000  with loss  12.224128723144531\n",
      "Training step  41  of  100000  with loss  12.327508926391602\n",
      "Training step  42  of  100000  with loss  14.324196815490723\n",
      "Training step  43  of  100000  with loss  12.281856536865234\n",
      "Training step  44  of  100000  with loss  11.830081939697266\n",
      "Training step  45  of  100000  with loss  12.19051742553711\n",
      "Training step  46  of  100000  with loss  11.328710556030273\n",
      "Training step  47  of  100000  with loss  11.140233993530273\n",
      "Training step  48  of  100000  with loss  12.609737396240234\n",
      "Training step  49  of  100000  with loss  12.925294876098633\n",
      "Training step  50  of  100000  with loss  10.934152603149414\n",
      "Training step  51  of  100000  with loss  11.381658554077148\n",
      "Training step  52  of  100000  with loss  12.035388946533203\n",
      "Training step  53  of  100000  with loss  12.137105941772461\n",
      "Training step  54  of  100000  with loss  11.569390296936035\n",
      "Training step  55  of  100000  with loss  13.351712226867676\n",
      "Training step  56  of  100000  with loss  9.760946273803711\n",
      "Saving checkpoints\n",
      "Training step  57  of  100000  with loss  9.640799522399902\n",
      "Saving checkpoints\n",
      "Training step  58  of  100000  with loss  9.849092483520508\n",
      "Training step  59  of  100000  with loss  13.142790794372559\n",
      "Training step  60  of  100000  with loss  13.04201602935791\n",
      "Training step  61  of  100000  with loss  10.088521957397461\n",
      "Training step  62  of  100000  with loss  10.869233131408691\n",
      "Training step  63  of  100000  with loss  11.148896217346191\n",
      "Training step  64  of  100000  with loss  11.427029609680176\n",
      "Training step  65  of  100000  with loss  11.536264419555664\n",
      "Training step  66  of  100000  with loss  10.78225326538086\n",
      "Training step  67  of  100000  with loss  12.035439491271973\n",
      "Training step  68  of  100000  with loss  10.004015922546387\n",
      "Training step  69  of  100000  with loss  10.738399505615234\n",
      "Training step  70  of  100000  with loss  13.7074613571167\n",
      "Training step  71  of  100000  with loss  11.818439483642578\n",
      "Training step  72  of  100000  with loss  12.413163185119629\n",
      "Training step  73  of  100000  with loss  10.48574447631836\n",
      "Training step  74  of  100000  with loss  11.628637313842773\n",
      "Training step  75  of  100000  with loss  10.546880722045898\n",
      "Training step  76  of  100000  with loss  10.19146728515625\n",
      "Training step  77  of  100000  with loss  12.013532638549805\n",
      "Training step  78  of  100000  with loss  11.897818565368652\n",
      "Training step  79  of  100000  with loss  11.15887451171875\n",
      "Training step  80  of  100000  with loss  10.534202575683594\n",
      "Training step  81  of  100000  with loss  11.85783863067627\n",
      "Training step  82  of  100000  with loss  12.07988166809082\n",
      "Training step  83  of  100000  with loss  11.46429443359375\n",
      "Training step  84  of  100000  with loss  10.354570388793945\n",
      "Training step  85  of  100000  with loss  11.49825668334961\n",
      "Training step  86  of  100000  with loss  10.367107391357422\n",
      "Training step  87  of  100000  with loss  11.573837280273438\n",
      "Training step  88  of  100000  with loss  10.9899263381958\n",
      "Training step  89  of  100000  with loss  9.98635196685791\n",
      "Training step  90  of  100000  with loss  11.127969741821289\n",
      "Training step  91  of  100000  with loss  10.647253036499023\n",
      "Training step  92  of  100000  with loss  10.464958190917969\n",
      "Training step  93  of  100000  with loss  11.361377716064453\n",
      "Training step  94  of  100000  with loss  11.21042251586914\n",
      "Training step  95  of  100000  with loss  10.875203132629395\n",
      "Training step  96  of  100000  with loss  11.561346054077148\n",
      "Training step  97  of  100000  with loss  11.493459701538086\n",
      "Training step  98  of  100000  with loss  9.932718276977539\n",
      "Training step  99  of  100000  with loss  10.864452362060547\n",
      "Training step  100  of  100000  with loss  12.904483795166016\n",
      "Training step  101  of  100000  with loss  11.858074188232422\n",
      "Training step  102  of  100000  with loss  10.1547269821167\n",
      "Training step  103  of  100000  with loss  9.659290313720703\n",
      "Training step  104  of  100000  with loss  9.803361892700195\n",
      "Training step  105  of  100000  with loss  11.363439559936523\n",
      "Training step  106  of  100000  with loss  11.380014419555664\n",
      "Training step  107  of  100000  with loss  11.540145874023438\n",
      "Training step  108  of  100000  with loss  10.388551712036133\n",
      "Training step  109  of  100000  with loss  10.429903030395508\n",
      "Training step  110  of  100000  with loss  10.169921875\n",
      "Training step  111  of  100000  with loss  10.973426818847656\n",
      "Training step  112  of  100000  with loss  11.962247848510742\n",
      "Training step  113  of  100000  with loss  9.996278762817383\n",
      "Training step  114  of  100000  with loss  10.537569999694824\n",
      "Training step  115  of  100000  with loss  10.190281867980957\n",
      "Training step  116  of  100000  with loss  10.806983947753906\n",
      "Training step  117  of  100000  with loss  12.420417785644531\n",
      "Training step  118  of  100000  with loss  10.347148895263672\n",
      "Training step  119  of  100000  with loss  10.66856575012207\n",
      "Training step  120  of  100000  with loss  10.883909225463867\n",
      "Training step  121  of  100000  with loss  9.892169952392578\n",
      "Training step  122  of  100000  with loss  10.390352249145508\n",
      "Training step  123  of  100000  with loss  11.084842681884766\n",
      "Training step  124  of  100000  with loss  10.758744239807129\n",
      "Training step  125  of  100000  with loss  10.48743724822998\n",
      "Training step  126  of  100000  with loss  10.48457145690918\n",
      "Training step  127  of  100000  with loss  10.18580436706543\n",
      "Training step  128  of  100000  with loss  10.557305335998535\n",
      "Training step  129  of  100000  with loss  11.642987251281738\n",
      "Training step  130  of  100000  with loss  11.84604549407959\n",
      "Training step  131  of  100000  with loss  12.797708511352539\n",
      "Training step  132  of  100000  with loss  9.790206909179688\n",
      "Training step  133  of  100000  with loss  10.542289733886719\n",
      "Training step  134  of  100000  with loss  9.831988334655762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  135  of  100000  with loss  10.471293449401855\n",
      "Training step  136  of  100000  with loss  11.782316207885742\n",
      "Training step  137  of  100000  with loss  10.681689262390137\n",
      "Training step  138  of  100000  with loss  9.637889862060547\n",
      "Saving checkpoints\n",
      "Training step  139  of  100000  with loss  10.269527435302734\n",
      "Training step  140  of  100000  with loss  11.18637466430664\n",
      "Training step  141  of  100000  with loss  10.074653625488281\n",
      "Training step  142  of  100000  with loss  10.583532333374023\n",
      "Training step  143  of  100000  with loss  9.431962966918945\n",
      "Saving checkpoints\n",
      "Training step  144  of  100000  with loss  9.453712463378906\n",
      "Training step  145  of  100000  with loss  10.607980728149414\n",
      "Training step  146  of  100000  with loss  9.78826904296875\n",
      "Training step  147  of  100000  with loss  10.409717559814453\n",
      "Training step  148  of  100000  with loss  10.234540939331055\n",
      "Training step  149  of  100000  with loss  11.314552307128906\n",
      "Training step  150  of  100000  with loss  10.22601318359375\n",
      "Training step  151  of  100000  with loss  9.970197677612305\n",
      "Training step  152  of  100000  with loss  12.048646926879883\n",
      "Training step  153  of  100000  with loss  10.598430633544922\n",
      "Training step  154  of  100000  with loss  9.843572616577148\n",
      "Training step  155  of  100000  with loss  9.48115062713623\n",
      "Training step  156  of  100000  with loss  9.665153503417969\n",
      "Training step  157  of  100000  with loss  10.753952980041504\n",
      "Training step  158  of  100000  with loss  10.147357940673828\n",
      "Training step  159  of  100000  with loss  10.309402465820312\n",
      "Training step  160  of  100000  with loss  9.890100479125977\n",
      "Training step  161  of  100000  with loss  10.786867141723633\n",
      "Training step  162  of  100000  with loss  9.574077606201172\n",
      "Training step  163  of  100000  with loss  9.702685356140137\n",
      "Training step  164  of  100000  with loss  11.463665008544922\n",
      "Training step  165  of  100000  with loss  9.43437671661377\n",
      "Training step  166  of  100000  with loss  9.785232543945312\n",
      "Training step  167  of  100000  with loss  10.346857070922852\n",
      "Training step  168  of  100000  with loss  11.249608993530273\n",
      "Training step  169  of  100000  with loss  11.22407054901123\n",
      "Training step  170  of  100000  with loss  10.350204467773438\n",
      "Training step  171  of  100000  with loss  11.821341514587402\n",
      "Training step  172  of  100000  with loss  11.966307640075684\n",
      "Training step  173  of  100000  with loss  9.536358833312988\n",
      "Training step  174  of  100000  with loss  10.396438598632812\n",
      "Training step  175  of  100000  with loss  11.51782512664795\n",
      "Training step  176  of  100000  with loss  9.444063186645508\n",
      "Training step  177  of  100000  with loss  10.48979663848877\n",
      "Training step  178  of  100000  with loss  12.2153959274292\n",
      "Training step  179  of  100000  with loss  10.63494873046875\n",
      "Training step  180  of  100000  with loss  9.731881141662598\n",
      "Training step  181  of  100000  with loss  11.072854042053223\n",
      "Training step  182  of  100000  with loss  10.955741882324219\n",
      "Training step  183  of  100000  with loss  10.82644271850586\n",
      "Training step  184  of  100000  with loss  9.382715225219727\n",
      "Saving checkpoints\n",
      "Training step  185  of  100000  with loss  9.666681289672852\n",
      "Training step  186  of  100000  with loss  10.581585884094238\n",
      "Training step  187  of  100000  with loss  9.91665267944336\n",
      "Training step  188  of  100000  with loss  9.38092041015625\n",
      "Saving checkpoints\n",
      "Training step  189  of  100000  with loss  10.07902717590332\n",
      "Training step  190  of  100000  with loss  9.529545783996582\n",
      "Training step  191  of  100000  with loss  11.615097045898438\n",
      "Training step  192  of  100000  with loss  12.314502716064453\n",
      "Training step  193  of  100000  with loss  10.495189666748047\n",
      "Training step  194  of  100000  with loss  9.869401931762695\n",
      "Training step  195  of  100000  with loss  12.470666885375977\n",
      "Training step  196  of  100000  with loss  9.613417625427246\n",
      "Training step  197  of  100000  with loss  11.601835250854492\n",
      "Training step  198  of  100000  with loss  8.768083572387695\n",
      "Saving checkpoints\n",
      "Training step  199  of  100000  with loss  10.424894332885742\n",
      "Training step  200  of  100000  with loss  10.387369155883789\n",
      "Training step  201  of  100000  with loss  10.768489837646484\n",
      "Training step  202  of  100000  with loss  10.88155746459961\n",
      "Training step  203  of  100000  with loss  10.450813293457031\n",
      "Training step  204  of  100000  with loss  8.871768951416016\n",
      "Training step  205  of  100000  with loss  9.22664737701416\n",
      "Training step  206  of  100000  with loss  10.893863677978516\n",
      "Training step  207  of  100000  with loss  10.083739280700684\n",
      "Training step  208  of  100000  with loss  10.037775039672852\n",
      "Training step  209  of  100000  with loss  11.091489791870117\n",
      "Training step  210  of  100000  with loss  10.627443313598633\n",
      "Training step  211  of  100000  with loss  11.266056060791016\n",
      "Training step  212  of  100000  with loss  9.131778717041016\n",
      "Training step  213  of  100000  with loss  9.28683853149414\n",
      "Training step  214  of  100000  with loss  11.208162307739258\n",
      "Training step  215  of  100000  with loss  12.26095199584961\n",
      "Training step  216  of  100000  with loss  10.304595947265625\n",
      "Training step  217  of  100000  with loss  10.496826171875\n",
      "Training step  218  of  100000  with loss  9.462440490722656\n",
      "Training step  219  of  100000  with loss  10.128315925598145\n",
      "Training step  220  of  100000  with loss  11.114173889160156\n",
      "Training step  221  of  100000  with loss  10.115266799926758\n",
      "Training step  222  of  100000  with loss  9.277074813842773\n",
      "Training step  223  of  100000  with loss  10.591257095336914\n",
      "Training step  224  of  100000  with loss  10.500606536865234\n",
      "Training step  225  of  100000  with loss  10.728270530700684\n",
      "Training step  226  of  100000  with loss  11.14655876159668\n",
      "Training step  227  of  100000  with loss  8.91403865814209\n",
      "Training step  228  of  100000  with loss  10.217720985412598\n",
      "Training step  229  of  100000  with loss  10.03972053527832\n",
      "Training step  230  of  100000  with loss  10.720111846923828\n",
      "Training step  231  of  100000  with loss  11.958135604858398\n",
      "Training step  232  of  100000  with loss  10.770329475402832\n",
      "Training step  233  of  100000  with loss  11.337657928466797\n",
      "Training step  234  of  100000  with loss  10.297576904296875\n",
      "Training step  235  of  100000  with loss  9.89435863494873\n",
      "Training step  236  of  100000  with loss  10.725696563720703\n",
      "Training step  237  of  100000  with loss  10.612482070922852\n",
      "Training step  238  of  100000  with loss  11.482872009277344\n",
      "Training step  239  of  100000  with loss  9.724782943725586\n",
      "Training step  240  of  100000  with loss  9.613809585571289\n",
      "Training step  241  of  100000  with loss  9.606813430786133\n",
      "Training step  242  of  100000  with loss  9.003725051879883\n",
      "Training step  243  of  100000  with loss  11.468332290649414\n",
      "Training step  244  of  100000  with loss  12.654743194580078\n",
      "Training step  245  of  100000  with loss  10.412744522094727\n",
      "Training step  246  of  100000  with loss  10.338713645935059\n",
      "Training step  247  of  100000  with loss  9.52305793762207\n",
      "Training step  248  of  100000  with loss  9.904891967773438\n",
      "Training step  249  of  100000  with loss  9.736724853515625\n",
      "Training step  250  of  100000  with loss  11.046598434448242\n",
      "Training step  251  of  100000  with loss  10.498638153076172\n",
      "Training step  252  of  100000  with loss  9.241018295288086\n",
      "Training step  253  of  100000  with loss  10.683836936950684\n",
      "Training step  254  of  100000  with loss  10.305302619934082\n",
      "Training step  255  of  100000  with loss  10.19590950012207\n",
      "Training step  256  of  100000  with loss  9.386211395263672\n",
      "Training step  257  of  100000  with loss  10.450047492980957\n",
      "Training step  258  of  100000  with loss  9.634818077087402\n",
      "Training step  259  of  100000  with loss  11.510488510131836\n",
      "Training step  260  of  100000  with loss  9.644062042236328\n",
      "Training step  261  of  100000  with loss  9.742470741271973\n",
      "Training step  262  of  100000  with loss  9.469037055969238\n",
      "Training step  263  of  100000  with loss  9.381855010986328\n",
      "Training step  264  of  100000  with loss  11.974798202514648\n",
      "Training step  265  of  100000  with loss  10.107498168945312\n",
      "Training step  266  of  100000  with loss  10.822607040405273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  267  of  100000  with loss  10.566181182861328\n",
      "Training step  268  of  100000  with loss  10.414207458496094\n",
      "Training step  269  of  100000  with loss  10.80898666381836\n",
      "Training step  270  of  100000  with loss  10.01443099975586\n",
      "Training step  271  of  100000  with loss  10.365194320678711\n",
      "Training step  272  of  100000  with loss  10.374505996704102\n",
      "Training step  273  of  100000  with loss  10.451618194580078\n",
      "Training step  274  of  100000  with loss  10.01776123046875\n",
      "Training step  275  of  100000  with loss  10.037239074707031\n",
      "Training step  276  of  100000  with loss  9.725468635559082\n",
      "Training step  277  of  100000  with loss  9.568548202514648\n",
      "Training step  278  of  100000  with loss  11.644128799438477\n",
      "Training step  279  of  100000  with loss  9.700618743896484\n",
      "Training step  280  of  100000  with loss  9.637807846069336\n",
      "Training step  281  of  100000  with loss  12.62130355834961\n",
      "Training step  282  of  100000  with loss  10.836769104003906\n",
      "Training step  283  of  100000  with loss  10.125969886779785\n",
      "Training step  284  of  100000  with loss  11.587723731994629\n",
      "Training step  285  of  100000  with loss  10.625669479370117\n",
      "Training step  286  of  100000  with loss  11.362847328186035\n",
      "Training step  287  of  100000  with loss  9.320245742797852\n",
      "Training step  288  of  100000  with loss  11.494318008422852\n",
      "Training step  289  of  100000  with loss  10.325355529785156\n",
      "Training step  290  of  100000  with loss  9.208742141723633\n",
      "Training step  291  of  100000  with loss  9.939258575439453\n",
      "Training step  292  of  100000  with loss  10.587176322937012\n",
      "Training step  293  of  100000  with loss  9.71343994140625\n",
      "Training step  294  of  100000  with loss  9.915848731994629\n",
      "Training step  295  of  100000  with loss  9.985440254211426\n",
      "Training step  296  of  100000  with loss  9.780280113220215\n",
      "Training step  297  of  100000  with loss  12.771217346191406\n",
      "Training step  298  of  100000  with loss  9.198003768920898\n",
      "Training step  299  of  100000  with loss  10.037544250488281\n",
      "Training step  300  of  100000  with loss  11.17917537689209\n",
      "Training step  301  of  100000  with loss  10.21489143371582\n",
      "Training step  302  of  100000  with loss  11.145589828491211\n",
      "Training step  303  of  100000  with loss  9.510865211486816\n",
      "Training step  304  of  100000  with loss  11.395326614379883\n",
      "Training step  305  of  100000  with loss  11.002920150756836\n",
      "Training step  306  of  100000  with loss  11.173709869384766\n",
      "Training step  307  of  100000  with loss  10.164411544799805\n",
      "Training step  308  of  100000  with loss  10.760351181030273\n",
      "Training step  309  of  100000  with loss  11.312883377075195\n",
      "Training step  310  of  100000  with loss  10.407194137573242\n",
      "Training step  311  of  100000  with loss  10.054275512695312\n",
      "Training step  312  of  100000  with loss  10.126119613647461\n",
      "Training step  313  of  100000  with loss  9.820868492126465\n",
      "Training step  314  of  100000  with loss  10.047712326049805\n",
      "Training step  315  of  100000  with loss  10.173018455505371\n",
      "Training step  316  of  100000  with loss  9.689079284667969\n",
      "Training step  317  of  100000  with loss  10.592098236083984\n",
      "Training step  318  of  100000  with loss  10.936614990234375\n",
      "Training step  319  of  100000  with loss  10.919351577758789\n",
      "Training step  320  of  100000  with loss  10.601884841918945\n",
      "Training step  321  of  100000  with loss  10.517121315002441\n",
      "Training step  322  of  100000  with loss  10.456429481506348\n",
      "Training step  323  of  100000  with loss  10.660548210144043\n",
      "Training step  324  of  100000  with loss  9.759035110473633\n",
      "Training step  325  of  100000  with loss  9.822693824768066\n",
      "Training step  326  of  100000  with loss  9.966095924377441\n",
      "Training step  327  of  100000  with loss  9.718982696533203\n",
      "Training step  328  of  100000  with loss  9.965511322021484\n",
      "Training step  329  of  100000  with loss  9.692472457885742\n",
      "Training step  330  of  100000  with loss  10.727913856506348\n",
      "Training step  331  of  100000  with loss  9.126283645629883\n",
      "Training step  332  of  100000  with loss  9.547070503234863\n",
      "Training step  333  of  100000  with loss  11.394075393676758\n",
      "Training step  334  of  100000  with loss  11.136417388916016\n",
      "Training step  335  of  100000  with loss  10.808055877685547\n",
      "Training step  336  of  100000  with loss  9.992511749267578\n",
      "Training step  337  of  100000  with loss  11.277006149291992\n",
      "Training step  338  of  100000  with loss  11.492843627929688\n",
      "Training step  339  of  100000  with loss  10.02383804321289\n",
      "Training step  340  of  100000  with loss  11.171989440917969\n",
      "Training step  341  of  100000  with loss  9.02734375\n",
      "Training step  342  of  100000  with loss  11.979385375976562\n",
      "Training step  343  of  100000  with loss  10.601516723632812\n",
      "Training step  344  of  100000  with loss  10.67289924621582\n",
      "Training step  345  of  100000  with loss  9.70226001739502\n",
      "Training step  346  of  100000  with loss  9.659454345703125\n",
      "Training step  347  of  100000  with loss  11.752501487731934\n",
      "Training step  348  of  100000  with loss  8.829448699951172\n",
      "Training step  349  of  100000  with loss  10.240829467773438\n",
      "Training step  350  of  100000  with loss  10.204015731811523\n",
      "Training step  351  of  100000  with loss  10.589988708496094\n",
      "Training step  352  of  100000  with loss  11.832208633422852\n",
      "Training step  353  of  100000  with loss  9.626457214355469\n",
      "Training step  354  of  100000  with loss  11.270084381103516\n",
      "Training step  355  of  100000  with loss  10.484085083007812\n",
      "Training step  356  of  100000  with loss  11.83175277709961\n",
      "Training step  357  of  100000  with loss  10.025546073913574\n",
      "Training step  358  of  100000  with loss  10.557315826416016\n",
      "Training step  359  of  100000  with loss  9.314565658569336\n",
      "Training step  360  of  100000  with loss  10.097675323486328\n",
      "Training step  361  of  100000  with loss  10.731632232666016\n",
      "Training step  362  of  100000  with loss  9.90587043762207\n",
      "Training step  363  of  100000  with loss  9.885579109191895\n",
      "Training step  364  of  100000  with loss  9.288446426391602\n",
      "Training step  365  of  100000  with loss  10.689010620117188\n",
      "Training step  366  of  100000  with loss  11.286951065063477\n",
      "Training step  367  of  100000  with loss  11.178943634033203\n",
      "Training step  368  of  100000  with loss  10.066097259521484\n",
      "Training step  369  of  100000  with loss  9.823948860168457\n",
      "Training step  370  of  100000  with loss  9.643604278564453\n",
      "Training step  371  of  100000  with loss  10.669363021850586\n",
      "Training step  372  of  100000  with loss  11.116416931152344\n",
      "Training step  373  of  100000  with loss  10.08562183380127\n",
      "Training step  374  of  100000  with loss  10.097146034240723\n",
      "Training step  375  of  100000  with loss  10.74174690246582\n",
      "Training step  376  of  100000  with loss  11.091438293457031\n",
      "Training step  377  of  100000  with loss  10.943140029907227\n",
      "Training step  378  of  100000  with loss  9.942485809326172\n",
      "Training step  379  of  100000  with loss  9.979506492614746\n",
      "Training step  380  of  100000  with loss  9.458513259887695\n",
      "Training step  381  of  100000  with loss  10.133996963500977\n",
      "Training step  382  of  100000  with loss  8.89277172088623\n",
      "Training step  383  of  100000  with loss  10.73259162902832\n",
      "Training step  384  of  100000  with loss  10.838233947753906\n",
      "Training step  385  of  100000  with loss  10.981249809265137\n",
      "Training step  386  of  100000  with loss  9.572992324829102\n",
      "Training step  387  of  100000  with loss  10.120257377624512\n",
      "Training step  388  of  100000  with loss  11.641424179077148\n",
      "Training step  389  of  100000  with loss  10.624882698059082\n",
      "Training step  390  of  100000  with loss  10.720138549804688\n",
      "Training step  391  of  100000  with loss  10.381959915161133\n",
      "Training step  392  of  100000  with loss  8.523714065551758\n",
      "Saving checkpoints\n",
      "Training step  393  of  100000  with loss  10.567316055297852\n",
      "Training step  394  of  100000  with loss  11.493265151977539\n",
      "Training step  395  of  100000  with loss  10.414604187011719\n",
      "Training step  396  of  100000  with loss  11.166096687316895\n",
      "Training step  397  of  100000  with loss  10.84859848022461\n",
      "Training step  398  of  100000  with loss  9.696353912353516\n",
      "Training step  399  of  100000  with loss  10.232176780700684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  400  of  100000  with loss  9.47709846496582\n",
      "Training step  401  of  100000  with loss  10.682880401611328\n",
      "Training step  402  of  100000  with loss  10.098819732666016\n",
      "Training step  403  of  100000  with loss  8.043462753295898\n",
      "Saving checkpoints\n",
      "Training step  404  of  100000  with loss  9.63914680480957\n",
      "Training step  405  of  100000  with loss  10.236284255981445\n",
      "Training step  406  of  100000  with loss  10.53149700164795\n",
      "Training step  407  of  100000  with loss  10.401326179504395\n",
      "Training step  408  of  100000  with loss  8.965582847595215\n",
      "Training step  409  of  100000  with loss  9.32552719116211\n",
      "Training step  410  of  100000  with loss  9.230177879333496\n",
      "Training step  411  of  100000  with loss  9.355731964111328\n",
      "Training step  412  of  100000  with loss  10.175984382629395\n",
      "Training step  413  of  100000  with loss  10.435591697692871\n",
      "Training step  414  of  100000  with loss  9.087166786193848\n",
      "Training step  415  of  100000  with loss  9.205066680908203\n",
      "Training step  416  of  100000  with loss  9.971670150756836\n",
      "Training step  417  of  100000  with loss  9.601753234863281\n",
      "Training step  418  of  100000  with loss  10.402630805969238\n",
      "Training step  419  of  100000  with loss  10.549885749816895\n",
      "Training step  420  of  100000  with loss  10.423962593078613\n",
      "Training step  421  of  100000  with loss  10.592462539672852\n",
      "Training step  422  of  100000  with loss  9.44107437133789\n",
      "Training step  423  of  100000  with loss  9.33035945892334\n",
      "Training step  424  of  100000  with loss  9.89716911315918\n",
      "Training step  425  of  100000  with loss  10.467355728149414\n",
      "Training step  426  of  100000  with loss  8.757911682128906\n",
      "Training step  427  of  100000  with loss  9.39744758605957\n",
      "Training step  428  of  100000  with loss  10.082523345947266\n",
      "Training step  429  of  100000  with loss  10.558887481689453\n",
      "Training step  430  of  100000  with loss  10.199350357055664\n",
      "Training step  431  of  100000  with loss  10.524354934692383\n",
      "Training step  432  of  100000  with loss  10.904867172241211\n",
      "Training step  433  of  100000  with loss  9.52653980255127\n",
      "Training step  434  of  100000  with loss  8.767556190490723\n",
      "Training step  435  of  100000  with loss  10.516423225402832\n",
      "Training step  436  of  100000  with loss  10.158855438232422\n",
      "Training step  437  of  100000  with loss  10.660118103027344\n",
      "Training step  438  of  100000  with loss  8.887327194213867\n",
      "Training step  439  of  100000  with loss  10.979464530944824\n",
      "Training step  440  of  100000  with loss  9.043347358703613\n",
      "Training step  441  of  100000  with loss  10.166548728942871\n",
      "Training step  442  of  100000  with loss  8.971601486206055\n",
      "Training step  443  of  100000  with loss  10.705013275146484\n",
      "Training step  444  of  100000  with loss  12.416818618774414\n",
      "Training step  445  of  100000  with loss  9.741836547851562\n",
      "Training step  446  of  100000  with loss  9.15415096282959\n",
      "Training step  447  of  100000  with loss  10.995258331298828\n",
      "Training step  448  of  100000  with loss  10.897068977355957\n",
      "Training step  449  of  100000  with loss  9.290460586547852\n",
      "Training step  450  of  100000  with loss  10.085674285888672\n",
      "Training step  451  of  100000  with loss  10.424398422241211\n",
      "Training step  452  of  100000  with loss  9.928308486938477\n",
      "Training step  453  of  100000  with loss  10.363449096679688\n",
      "Training step  454  of  100000  with loss  9.348546981811523\n",
      "Training step  455  of  100000  with loss  9.806782722473145\n",
      "Training step  456  of  100000  with loss  8.59328556060791\n",
      "Training step  457  of  100000  with loss  8.572639465332031\n",
      "Training step  458  of  100000  with loss  8.889389038085938\n",
      "Training step  459  of  100000  with loss  9.041934967041016\n",
      "Training step  460  of  100000  with loss  9.866311073303223\n",
      "Training step  461  of  100000  with loss  9.129176139831543\n",
      "Training step  462  of  100000  with loss  9.654380798339844\n",
      "Training step  463  of  100000  with loss  10.08829116821289\n",
      "Training step  464  of  100000  with loss  11.40549373626709\n",
      "Training step  465  of  100000  with loss  9.849287986755371\n",
      "Training step  466  of  100000  with loss  8.943663597106934\n",
      "Training step  467  of  100000  with loss  9.102595329284668\n",
      "Training step  468  of  100000  with loss  10.701810836791992\n",
      "Training step  469  of  100000  with loss  10.257532119750977\n",
      "Training step  470  of  100000  with loss  9.40771770477295\n",
      "Training step  471  of  100000  with loss  10.467845916748047\n",
      "Training step  472  of  100000  with loss  12.230955123901367\n",
      "Training step  473  of  100000  with loss  10.151329040527344\n",
      "Training step  474  of  100000  with loss  8.802908897399902\n",
      "Training step  475  of  100000  with loss  9.325775146484375\n",
      "Training step  476  of  100000  with loss  11.301307678222656\n",
      "Training step  477  of  100000  with loss  10.810635566711426\n",
      "Training step  478  of  100000  with loss  10.486306190490723\n",
      "Training step  479  of  100000  with loss  9.962164878845215\n",
      "Training step  480  of  100000  with loss  9.078231811523438\n",
      "Training step  481  of  100000  with loss  10.335144996643066\n",
      "Training step  482  of  100000  with loss  10.99177074432373\n",
      "Training step  483  of  100000  with loss  10.768613815307617\n",
      "Training step  484  of  100000  with loss  10.809770584106445\n",
      "Training step  485  of  100000  with loss  11.139501571655273\n",
      "Training step  486  of  100000  with loss  9.945615768432617\n",
      "Training step  487  of  100000  with loss  10.016862869262695\n",
      "Training step  488  of  100000  with loss  9.472827911376953\n",
      "Training step  489  of  100000  with loss  10.140689849853516\n",
      "Training step  490  of  100000  with loss  9.572803497314453\n",
      "Training step  491  of  100000  with loss  9.01902961730957\n",
      "Training step  492  of  100000  with loss  9.456377029418945\n",
      "Training step  493  of  100000  with loss  10.747386932373047\n",
      "Training step  494  of  100000  with loss  9.180303573608398\n",
      "Training step  495  of  100000  with loss  9.525606155395508\n",
      "Training step  496  of  100000  with loss  9.460084915161133\n",
      "Training step  497  of  100000  with loss  10.381502151489258\n",
      "Training step  498  of  100000  with loss  10.324250221252441\n",
      "Training step  499  of  100000  with loss  9.674969673156738\n",
      "Training step  500  of  100000  with loss  9.287126541137695\n",
      "Training step  501  of  100000  with loss  9.120393753051758\n",
      "Training step  502  of  100000  with loss  9.646200180053711\n",
      "Training step  503  of  100000  with loss  10.10720443725586\n",
      "Training step  504  of  100000  with loss  10.821168899536133\n",
      "Training step  505  of  100000  with loss  10.5569429397583\n",
      "Training step  506  of  100000  with loss  11.69974136352539\n",
      "Training step  507  of  100000  with loss  10.43368911743164\n",
      "Training step  508  of  100000  with loss  10.594005584716797\n",
      "Training step  509  of  100000  with loss  10.904346466064453\n",
      "Training step  510  of  100000  with loss  10.20564079284668\n",
      "Training step  511  of  100000  with loss  10.689094543457031\n",
      "Training step  512  of  100000  with loss  10.735605239868164\n",
      "Training step  513  of  100000  with loss  11.600170135498047\n",
      "Training step  514  of  100000  with loss  10.099462509155273\n",
      "Training step  515  of  100000  with loss  10.131805419921875\n",
      "Training step  516  of  100000  with loss  10.039551734924316\n",
      "Training step  517  of  100000  with loss  10.822273254394531\n",
      "Training step  518  of  100000  with loss  10.848617553710938\n",
      "Training step  519  of  100000  with loss  11.16156005859375\n",
      "Training step  520  of  100000  with loss  10.054927825927734\n",
      "Training step  521  of  100000  with loss  10.07097053527832\n",
      "Training step  522  of  100000  with loss  9.963088035583496\n",
      "Training step  523  of  100000  with loss  11.047964096069336\n",
      "Training step  524  of  100000  with loss  10.900041580200195\n",
      "Training step  525  of  100000  with loss  11.635047912597656\n",
      "Training step  526  of  100000  with loss  10.187884330749512\n",
      "Training step  527  of  100000  with loss  10.558430671691895\n",
      "Training step  528  of  100000  with loss  9.646356582641602\n",
      "Training step  529  of  100000  with loss  9.736961364746094\n",
      "Training step  530  of  100000  with loss  10.230545997619629\n",
      "Training step  531  of  100000  with loss  10.21989631652832\n",
      "Training step  532  of  100000  with loss  10.43502426147461\n",
      "Training step  533  of  100000  with loss  10.618114471435547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  534  of  100000  with loss  9.500150680541992\n",
      "Training step  535  of  100000  with loss  11.083949089050293\n",
      "Training step  536  of  100000  with loss  9.763446807861328\n",
      "Training step  537  of  100000  with loss  10.088297843933105\n",
      "Training step  538  of  100000  with loss  10.614084243774414\n",
      "Training step  539  of  100000  with loss  10.134323120117188\n",
      "Training step  540  of  100000  with loss  10.985052108764648\n",
      "Training step  541  of  100000  with loss  11.181102752685547\n",
      "Training step  542  of  100000  with loss  10.012157440185547\n",
      "Training step  543  of  100000  with loss  10.486190795898438\n",
      "Training step  544  of  100000  with loss  9.9282808303833\n",
      "Training step  545  of  100000  with loss  9.486743927001953\n",
      "Training step  546  of  100000  with loss  8.757387161254883\n",
      "Training step  547  of  100000  with loss  10.502485275268555\n",
      "Training step  548  of  100000  with loss  9.845500946044922\n",
      "Training step  549  of  100000  with loss  10.495412826538086\n",
      "Training step  550  of  100000  with loss  9.395197868347168\n",
      "Training step  551  of  100000  with loss  10.550222396850586\n",
      "Training step  552  of  100000  with loss  9.301837921142578\n",
      "Training step  553  of  100000  with loss  10.357904434204102\n",
      "Training step  554  of  100000  with loss  9.957854270935059\n",
      "Training step  555  of  100000  with loss  10.56778335571289\n",
      "Training step  556  of  100000  with loss  10.151399612426758\n",
      "Training step  557  of  100000  with loss  10.573323249816895\n",
      "Training step  558  of  100000  with loss  9.81834888458252\n",
      "Training step  559  of  100000  with loss  9.951957702636719\n",
      "Training step  560  of  100000  with loss  11.314153671264648\n",
      "Training step  561  of  100000  with loss  10.306633949279785\n",
      "Training step  562  of  100000  with loss  12.548933029174805\n",
      "Training step  563  of  100000  with loss  10.389713287353516\n",
      "Training step  564  of  100000  with loss  9.249727249145508\n",
      "Training step  565  of  100000  with loss  10.092199325561523\n",
      "Training step  566  of  100000  with loss  9.542289733886719\n",
      "Training step  567  of  100000  with loss  11.554500579833984\n",
      "Training step  568  of  100000  with loss  11.485450744628906\n",
      "Training step  569  of  100000  with loss  8.627130508422852\n",
      "Training step  570  of  100000  with loss  9.011778831481934\n",
      "Training step  571  of  100000  with loss  9.324873924255371\n",
      "Training step  572  of  100000  with loss  10.48073959350586\n",
      "Training step  573  of  100000  with loss  9.955808639526367\n",
      "Training step  574  of  100000  with loss  10.351153373718262\n",
      "Training step  575  of  100000  with loss  10.663283348083496\n",
      "Training step  576  of  100000  with loss  9.03532886505127\n",
      "Training step  577  of  100000  with loss  9.215168952941895\n",
      "Training step  578  of  100000  with loss  8.872173309326172\n",
      "Training step  579  of  100000  with loss  10.883773803710938\n",
      "Training step  580  of  100000  with loss  9.72292709350586\n",
      "Training step  581  of  100000  with loss  9.852907180786133\n",
      "Training step  582  of  100000  with loss  9.441624641418457\n",
      "Training step  583  of  100000  with loss  9.372713088989258\n",
      "Training step  584  of  100000  with loss  8.872678756713867\n",
      "Training step  585  of  100000  with loss  9.984703063964844\n",
      "Training step  586  of  100000  with loss  10.429336547851562\n",
      "Training step  587  of  100000  with loss  9.765436172485352\n",
      "Training step  588  of  100000  with loss  9.724238395690918\n",
      "Training step  589  of  100000  with loss  10.325016975402832\n",
      "Training step  590  of  100000  with loss  10.40317153930664\n",
      "Training step  591  of  100000  with loss  9.962145805358887\n",
      "Training step  592  of  100000  with loss  9.544922828674316\n",
      "Training step  593  of  100000  with loss  11.666170120239258\n",
      "Training step  594  of  100000  with loss  9.036527633666992\n",
      "Training step  595  of  100000  with loss  10.381050109863281\n",
      "Training step  596  of  100000  with loss  9.371938705444336\n",
      "Training step  597  of  100000  with loss  9.35731315612793\n",
      "Training step  598  of  100000  with loss  9.454397201538086\n",
      "Training step  599  of  100000  with loss  9.59288215637207\n",
      "Training step  600  of  100000  with loss  10.557445526123047\n",
      "Training step  601  of  100000  with loss  10.813051223754883\n",
      "Training step  602  of  100000  with loss  10.217961311340332\n",
      "Training step  603  of  100000  with loss  9.629829406738281\n",
      "Training step  604  of  100000  with loss  9.670372009277344\n",
      "Training step  605  of  100000  with loss  10.596101760864258\n",
      "Training step  606  of  100000  with loss  10.710592269897461\n",
      "Training step  607  of  100000  with loss  10.09196662902832\n",
      "Training step  608  of  100000  with loss  9.795058250427246\n",
      "Training step  609  of  100000  with loss  10.95914077758789\n",
      "Training step  610  of  100000  with loss  9.20532512664795\n",
      "Training step  611  of  100000  with loss  10.610591888427734\n",
      "Training step  612  of  100000  with loss  10.50580883026123\n",
      "Training step  613  of  100000  with loss  9.824542999267578\n",
      "Training step  614  of  100000  with loss  9.888561248779297\n",
      "Training step  615  of  100000  with loss  9.922133445739746\n",
      "Training step  616  of  100000  with loss  9.149303436279297\n",
      "Training step  617  of  100000  with loss  11.586448669433594\n",
      "Training step  618  of  100000  with loss  10.427480697631836\n",
      "Training step  619  of  100000  with loss  9.689858436584473\n",
      "Training step  620  of  100000  with loss  10.325870513916016\n",
      "Training step  621  of  100000  with loss  10.216015815734863\n",
      "Training step  622  of  100000  with loss  8.762545585632324\n",
      "Training step  623  of  100000  with loss  9.194644927978516\n",
      "Training step  624  of  100000  with loss  9.928149223327637\n",
      "Training step  625  of  100000  with loss  10.27931022644043\n",
      "Training step  626  of  100000  with loss  8.875006675720215\n",
      "Training step  627  of  100000  with loss  10.873546600341797\n",
      "Training step  628  of  100000  with loss  9.459720611572266\n",
      "Training step  629  of  100000  with loss  9.519153594970703\n",
      "Training step  630  of  100000  with loss  10.737506866455078\n",
      "Training step  631  of  100000  with loss  9.684148788452148\n",
      "Training step  632  of  100000  with loss  10.001401901245117\n",
      "Training step  633  of  100000  with loss  9.931912422180176\n",
      "Training step  634  of  100000  with loss  10.9107027053833\n",
      "Training step  635  of  100000  with loss  9.998759269714355\n",
      "Training step  636  of  100000  with loss  9.556268692016602\n",
      "Training step  637  of  100000  with loss  9.955368041992188\n",
      "Training step  638  of  100000  with loss  10.455015182495117\n",
      "Training step  639  of  100000  with loss  9.103626251220703\n",
      "Training step  640  of  100000  with loss  9.834551811218262\n",
      "Training step  641  of  100000  with loss  10.854496002197266\n",
      "Training step  642  of  100000  with loss  10.07685375213623\n",
      "Training step  643  of  100000  with loss  9.622982025146484\n",
      "Training step  644  of  100000  with loss  12.079244613647461\n",
      "Training step  645  of  100000  with loss  9.671173095703125\n",
      "Training step  646  of  100000  with loss  9.328540802001953\n",
      "Training step  647  of  100000  with loss  9.294452667236328\n",
      "Training step  648  of  100000  with loss  9.232475280761719\n",
      "Training step  649  of  100000  with loss  10.683206558227539\n",
      "Training step  650  of  100000  with loss  10.17701530456543\n",
      "Training step  651  of  100000  with loss  10.855228424072266\n",
      "Training step  652  of  100000  with loss  9.883106231689453\n",
      "Training step  653  of  100000  with loss  11.326509475708008\n",
      "Training step  654  of  100000  with loss  8.676965713500977\n",
      "Training step  655  of  100000  with loss  9.72767448425293\n",
      "Training step  656  of  100000  with loss  9.182891845703125\n",
      "Training step  657  of  100000  with loss  11.360000610351562\n",
      "Training step  658  of  100000  with loss  11.413116455078125\n",
      "Training step  659  of  100000  with loss  10.546998023986816\n",
      "Training step  660  of  100000  with loss  9.280111312866211\n",
      "Training step  661  of  100000  with loss  10.209624290466309\n",
      "Training step  662  of  100000  with loss  8.96704387664795\n",
      "Training step  663  of  100000  with loss  9.990608215332031\n",
      "Training step  664  of  100000  with loss  9.894830703735352\n",
      "Training step  665  of  100000  with loss  10.039859771728516\n",
      "Training step  666  of  100000  with loss  9.139630317687988\n",
      "Training step  667  of  100000  with loss  9.589792251586914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  668  of  100000  with loss  8.993901252746582\n",
      "Training step  669  of  100000  with loss  11.230012893676758\n",
      "Training step  670  of  100000  with loss  8.532942771911621\n",
      "Training step  671  of  100000  with loss  9.90760612487793\n",
      "Training step  672  of  100000  with loss  9.417181015014648\n",
      "Training step  673  of  100000  with loss  9.654657363891602\n",
      "Training step  674  of  100000  with loss  8.793529510498047\n",
      "Training step  675  of  100000  with loss  10.689970016479492\n",
      "Training step  676  of  100000  with loss  8.416099548339844\n",
      "Training step  677  of  100000  with loss  9.818303108215332\n",
      "Training step  678  of  100000  with loss  10.478459358215332\n",
      "Training step  679  of  100000  with loss  9.500214576721191\n",
      "Training step  680  of  100000  with loss  9.52673053741455\n",
      "Training step  681  of  100000  with loss  9.317159652709961\n",
      "Training step  682  of  100000  with loss  10.660118103027344\n",
      "Training step  683  of  100000  with loss  11.557927131652832\n",
      "Training step  684  of  100000  with loss  11.370002746582031\n",
      "Training step  685  of  100000  with loss  9.05998420715332\n",
      "Training step  686  of  100000  with loss  8.408867835998535\n",
      "Training step  687  of  100000  with loss  9.913976669311523\n",
      "Training step  688  of  100000  with loss  9.393413543701172\n",
      "Training step  689  of  100000  with loss  11.12137222290039\n",
      "Training step  690  of  100000  with loss  10.327746391296387\n",
      "Training step  691  of  100000  with loss  10.060524940490723\n",
      "Training step  692  of  100000  with loss  10.651311874389648\n",
      "Training step  693  of  100000  with loss  10.138221740722656\n",
      "Training step  694  of  100000  with loss  8.752640724182129\n",
      "Training step  695  of  100000  with loss  9.099950790405273\n",
      "Training step  696  of  100000  with loss  11.242464065551758\n",
      "Training step  697  of  100000  with loss  8.821525573730469\n",
      "Training step  698  of  100000  with loss  7.995621681213379\n",
      "Saving checkpoints\n",
      "Training step  699  of  100000  with loss  10.03346061706543\n",
      "Training step  700  of  100000  with loss  10.010658264160156\n",
      "Training step  701  of  100000  with loss  10.350521087646484\n",
      "Training step  702  of  100000  with loss  9.698196411132812\n",
      "Training step  703  of  100000  with loss  10.515850067138672\n",
      "Training step  704  of  100000  with loss  10.297309875488281\n",
      "Training step  705  of  100000  with loss  10.161638259887695\n",
      "Training step  706  of  100000  with loss  9.81981086730957\n",
      "Training step  707  of  100000  with loss  10.825581550598145\n",
      "Training step  708  of  100000  with loss  9.894815444946289\n",
      "Training step  709  of  100000  with loss  10.113999366760254\n",
      "Training step  710  of  100000  with loss  9.213410377502441\n",
      "Training step  711  of  100000  with loss  11.365130424499512\n",
      "Training step  712  of  100000  with loss  10.447587966918945\n",
      "Training step  713  of  100000  with loss  10.065242767333984\n",
      "Training step  714  of  100000  with loss  9.287162780761719\n",
      "Training step  715  of  100000  with loss  10.146825790405273\n",
      "Training step  716  of  100000  with loss  11.022479057312012\n",
      "Training step  717  of  100000  with loss  9.656655311584473\n",
      "Training step  718  of  100000  with loss  10.473917007446289\n",
      "Training step  719  of  100000  with loss  9.909432411193848\n",
      "Training step  720  of  100000  with loss  9.80927562713623\n",
      "Training step  721  of  100000  with loss  10.639053344726562\n",
      "Training step  722  of  100000  with loss  10.181610107421875\n",
      "Training step  723  of  100000  with loss  10.511490821838379\n",
      "Training step  724  of  100000  with loss  11.348179817199707\n",
      "Training step  725  of  100000  with loss  8.47844123840332\n",
      "Training step  726  of  100000  with loss  8.129093170166016\n",
      "Training step  727  of  100000  with loss  9.734033584594727\n",
      "Training step  728  of  100000  with loss  9.947640419006348\n",
      "Training step  729  of  100000  with loss  11.379323959350586\n",
      "Training step  730  of  100000  with loss  9.138606071472168\n",
      "Training step  731  of  100000  with loss  9.96396255493164\n",
      "Training step  732  of  100000  with loss  10.158167839050293\n",
      "Training step  733  of  100000  with loss  10.036556243896484\n",
      "Training step  734  of  100000  with loss  10.614601135253906\n",
      "Training step  735  of  100000  with loss  9.500901222229004\n",
      "Training step  736  of  100000  with loss  10.094476699829102\n",
      "Training step  737  of  100000  with loss  9.719226837158203\n",
      "Training step  738  of  100000  with loss  10.191247940063477\n",
      "Training step  739  of  100000  with loss  9.677350997924805\n",
      "Training step  740  of  100000  with loss  9.993976593017578\n",
      "Training step  741  of  100000  with loss  10.023300170898438\n",
      "Training step  742  of  100000  with loss  9.899295806884766\n",
      "Training step  743  of  100000  with loss  9.300182342529297\n",
      "Training step  744  of  100000  with loss  9.643768310546875\n",
      "Training step  745  of  100000  with loss  9.457252502441406\n",
      "Training step  746  of  100000  with loss  10.225067138671875\n",
      "Training step  747  of  100000  with loss  8.901165008544922\n",
      "Training step  748  of  100000  with loss  10.056339263916016\n",
      "Training step  749  of  100000  with loss  9.6595458984375\n",
      "Training step  750  of  100000  with loss  10.142783164978027\n",
      "Training step  751  of  100000  with loss  10.884222030639648\n",
      "Training step  752  of  100000  with loss  9.266559600830078\n",
      "Training step  753  of  100000  with loss  10.345171928405762\n",
      "Training step  754  of  100000  with loss  9.760120391845703\n",
      "Training step  755  of  100000  with loss  9.597962379455566\n",
      "Training step  756  of  100000  with loss  9.79395866394043\n",
      "Training step  757  of  100000  with loss  9.658676147460938\n",
      "Training step  758  of  100000  with loss  11.05765151977539\n",
      "Training step  759  of  100000  with loss  10.149362564086914\n",
      "Training step  760  of  100000  with loss  9.780126571655273\n",
      "Training step  761  of  100000  with loss  8.74472427368164\n",
      "Training step  762  of  100000  with loss  9.422462463378906\n",
      "Training step  763  of  100000  with loss  9.767139434814453\n",
      "Training step  764  of  100000  with loss  10.374216079711914\n",
      "Training step  765  of  100000  with loss  10.739826202392578\n",
      "Training step  766  of  100000  with loss  9.566635131835938\n",
      "Training step  767  of  100000  with loss  9.881221771240234\n",
      "Training step  768  of  100000  with loss  8.890328407287598\n",
      "Training step  769  of  100000  with loss  10.322832107543945\n",
      "Training step  770  of  100000  with loss  9.5408935546875\n",
      "Training step  771  of  100000  with loss  10.045316696166992\n",
      "Training step  772  of  100000  with loss  9.990120887756348\n",
      "Training step  773  of  100000  with loss  11.605497360229492\n",
      "Training step  774  of  100000  with loss  10.555817604064941\n",
      "Training step  775  of  100000  with loss  9.227919578552246\n",
      "Training step  776  of  100000  with loss  9.647363662719727\n",
      "Training step  777  of  100000  with loss  11.038342475891113\n",
      "Training step  778  of  100000  with loss  10.87324047088623\n",
      "Training step  779  of  100000  with loss  11.650510787963867\n",
      "Training step  780  of  100000  with loss  9.605403900146484\n",
      "Training step  781  of  100000  with loss  9.127494812011719\n",
      "Training step  782  of  100000  with loss  9.737895011901855\n",
      "Training step  783  of  100000  with loss  8.226541519165039\n",
      "Training step  784  of  100000  with loss  9.93106460571289\n",
      "Training step  785  of  100000  with loss  9.025993347167969\n",
      "Training step  786  of  100000  with loss  9.080188751220703\n",
      "Training step  787  of  100000  with loss  10.019124984741211\n",
      "Training step  788  of  100000  with loss  10.973941802978516\n",
      "Training step  789  of  100000  with loss  8.800814628601074\n",
      "Training step  790  of  100000  with loss  10.54908275604248\n",
      "Training step  791  of  100000  with loss  11.17192268371582\n",
      "Training step  792  of  100000  with loss  10.510625839233398\n",
      "Training step  793  of  100000  with loss  9.157829284667969\n",
      "Training step  794  of  100000  with loss  9.035332679748535\n",
      "Training step  795  of  100000  with loss  9.52934455871582\n",
      "Training step  796  of  100000  with loss  9.65526008605957\n",
      "Training step  797  of  100000  with loss  9.090730667114258\n",
      "Training step  798  of  100000  with loss  9.857292175292969\n",
      "Training step  799  of  100000  with loss  10.420005798339844\n",
      "Training step  800  of  100000  with loss  9.328449249267578\n",
      "Training step  801  of  100000  with loss  10.2188720703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  802  of  100000  with loss  11.340018272399902\n",
      "Training step  803  of  100000  with loss  10.452713012695312\n",
      "Training step  804  of  100000  with loss  11.608524322509766\n",
      "Training step  805  of  100000  with loss  10.743480682373047\n",
      "Training step  806  of  100000  with loss  10.097801208496094\n",
      "Training step  807  of  100000  with loss  9.885847091674805\n",
      "Training step  808  of  100000  with loss  10.63477897644043\n",
      "Training step  809  of  100000  with loss  9.837921142578125\n",
      "Training step  810  of  100000  with loss  9.720479965209961\n",
      "Training step  811  of  100000  with loss  12.754865646362305\n",
      "Training step  812  of  100000  with loss  9.63859748840332\n",
      "Training step  813  of  100000  with loss  9.805227279663086\n",
      "Training step  814  of  100000  with loss  9.908895492553711\n",
      "Training step  815  of  100000  with loss  9.223072052001953\n",
      "Training step  816  of  100000  with loss  9.441461563110352\n",
      "Training step  817  of  100000  with loss  11.06701946258545\n",
      "Training step  818  of  100000  with loss  11.046095848083496\n",
      "Training step  819  of  100000  with loss  10.208412170410156\n",
      "Training step  820  of  100000  with loss  9.763313293457031\n",
      "Training step  821  of  100000  with loss  10.440122604370117\n",
      "Training step  822  of  100000  with loss  9.307062149047852\n",
      "Training step  823  of  100000  with loss  9.342109680175781\n",
      "Training step  824  of  100000  with loss  8.986442565917969\n",
      "Training step  825  of  100000  with loss  10.920854568481445\n",
      "Training step  826  of  100000  with loss  10.768497467041016\n",
      "Training step  827  of  100000  with loss  11.720111846923828\n",
      "Training step  828  of  100000  with loss  9.853925704956055\n",
      "Training step  829  of  100000  with loss  9.506454467773438\n",
      "Training step  830  of  100000  with loss  10.198734283447266\n",
      "Training step  831  of  100000  with loss  12.147868156433105\n",
      "Training step  832  of  100000  with loss  9.337944984436035\n",
      "Training step  833  of  100000  with loss  9.326953887939453\n",
      "Training step  834  of  100000  with loss  9.580673217773438\n",
      "Training step  835  of  100000  with loss  10.408121109008789\n",
      "Training step  836  of  100000  with loss  10.40735912322998\n",
      "Training step  837  of  100000  with loss  9.703238487243652\n",
      "Training step  838  of  100000  with loss  10.209741592407227\n",
      "Training step  839  of  100000  with loss  10.332393646240234\n",
      "Training step  840  of  100000  with loss  11.378931045532227\n",
      "Training step  841  of  100000  with loss  10.385263442993164\n",
      "Training step  842  of  100000  with loss  10.693023681640625\n",
      "Training step  843  of  100000  with loss  9.28754997253418\n",
      "Training step  844  of  100000  with loss  9.276901245117188\n",
      "Training step  845  of  100000  with loss  10.261093139648438\n",
      "Training step  846  of  100000  with loss  10.233427047729492\n",
      "Training step  847  of  100000  with loss  11.567473411560059\n",
      "Training step  848  of  100000  with loss  10.579404830932617\n",
      "Training step  849  of  100000  with loss  9.663310050964355\n",
      "Training step  850  of  100000  with loss  9.266924858093262\n",
      "Training step  851  of  100000  with loss  9.648517608642578\n",
      "Training step  852  of  100000  with loss  8.753201484680176\n",
      "Training step  853  of  100000  with loss  9.809101104736328\n",
      "Training step  854  of  100000  with loss  9.730023384094238\n",
      "Training step  855  of  100000  with loss  8.902307510375977\n",
      "Training step  856  of  100000  with loss  11.083749771118164\n",
      "Training step  857  of  100000  with loss  9.8620023727417\n",
      "Training step  858  of  100000  with loss  10.18856430053711\n",
      "Training step  859  of  100000  with loss  10.295143127441406\n",
      "Training step  860  of  100000  with loss  9.666025161743164\n",
      "Training step  861  of  100000  with loss  11.415802001953125\n",
      "Training step  862  of  100000  with loss  9.826864242553711\n",
      "Training step  863  of  100000  with loss  10.441980361938477\n",
      "Training step  864  of  100000  with loss  9.023368835449219\n",
      "Training step  865  of  100000  with loss  11.144519805908203\n",
      "Training step  866  of  100000  with loss  10.337030410766602\n",
      "Training step  867  of  100000  with loss  9.522567749023438\n",
      "Training step  868  of  100000  with loss  8.923906326293945\n",
      "Training step  869  of  100000  with loss  9.428492546081543\n",
      "Training step  870  of  100000  with loss  9.17495346069336\n",
      "Training step  871  of  100000  with loss  9.615345001220703\n",
      "Training step  872  of  100000  with loss  9.597660064697266\n",
      "Training step  873  of  100000  with loss  10.76992416381836\n",
      "Training step  874  of  100000  with loss  10.299182891845703\n",
      "Training step  875  of  100000  with loss  9.243157386779785\n",
      "Training step  876  of  100000  with loss  8.34628963470459\n",
      "Training step  877  of  100000  with loss  9.39475154876709\n",
      "Training step  878  of  100000  with loss  9.495997428894043\n",
      "Training step  879  of  100000  with loss  10.870677947998047\n",
      "Training step  880  of  100000  with loss  11.68741226196289\n",
      "Training step  881  of  100000  with loss  11.319522857666016\n",
      "Training step  882  of  100000  with loss  9.06900691986084\n",
      "Training step  883  of  100000  with loss  9.378761291503906\n",
      "Training step  884  of  100000  with loss  10.021516799926758\n",
      "Training step  885  of  100000  with loss  9.248072624206543\n",
      "Training step  886  of  100000  with loss  10.294520378112793\n",
      "Training step  887  of  100000  with loss  8.160029411315918\n",
      "Training step  888  of  100000  with loss  9.288920402526855\n",
      "Training step  889  of  100000  with loss  10.503694534301758\n",
      "Training step  890  of  100000  with loss  8.797908782958984\n",
      "Training step  891  of  100000  with loss  9.536581039428711\n",
      "Training step  892  of  100000  with loss  9.860097885131836\n",
      "Training step  893  of  100000  with loss  10.616827011108398\n",
      "Training step  894  of  100000  with loss  10.088079452514648\n",
      "Training step  895  of  100000  with loss  10.616065979003906\n",
      "Training step  896  of  100000  with loss  8.60643196105957\n",
      "Training step  897  of  100000  with loss  11.032005310058594\n",
      "Training step  898  of  100000  with loss  10.769427299499512\n",
      "Training step  899  of  100000  with loss  10.942428588867188\n",
      "Training step  900  of  100000  with loss  9.569046974182129\n",
      "Training step  901  of  100000  with loss  9.16065502166748\n",
      "Training step  902  of  100000  with loss  10.916219711303711\n",
      "Training step  903  of  100000  with loss  9.502082824707031\n",
      "Training step  904  of  100000  with loss  11.042561531066895\n",
      "Training step  905  of  100000  with loss  9.012876510620117\n",
      "Training step  906  of  100000  with loss  10.82728099822998\n",
      "Training step  907  of  100000  with loss  10.716157913208008\n",
      "Training step  908  of  100000  with loss  9.804027557373047\n",
      "Training step  909  of  100000  with loss  10.447246551513672\n",
      "Training step  910  of  100000  with loss  9.295281410217285\n",
      "Training step  911  of  100000  with loss  9.062210083007812\n",
      "Training step  912  of  100000  with loss  10.116260528564453\n",
      "Training step  913  of  100000  with loss  10.22919750213623\n",
      "Training step  914  of  100000  with loss  10.982926368713379\n",
      "Training step  915  of  100000  with loss  11.92755126953125\n",
      "Training step  916  of  100000  with loss  11.218517303466797\n",
      "Training step  917  of  100000  with loss  11.022319793701172\n",
      "Training step  918  of  100000  with loss  10.344310760498047\n",
      "Training step  919  of  100000  with loss  10.460803031921387\n",
      "Training step  920  of  100000  with loss  9.62111759185791\n",
      "Training step  921  of  100000  with loss  9.483379364013672\n",
      "Training step  922  of  100000  with loss  10.541107177734375\n",
      "Training step  923  of  100000  with loss  8.790384292602539\n",
      "Training step  924  of  100000  with loss  10.202247619628906\n",
      "Training step  925  of  100000  with loss  10.291892051696777\n",
      "Training step  926  of  100000  with loss  10.22012996673584\n",
      "Training step  927  of  100000  with loss  8.859582901000977\n",
      "Training step  928  of  100000  with loss  10.031526565551758\n",
      "Training step  929  of  100000  with loss  10.298192977905273\n",
      "Training step  930  of  100000  with loss  9.873575210571289\n",
      "Training step  931  of  100000  with loss  10.060799598693848\n",
      "Training step  932  of  100000  with loss  10.99959945678711\n",
      "Training step  933  of  100000  with loss  9.62890625\n",
      "Training step  934  of  100000  with loss  10.775461196899414\n",
      "Training step  935  of  100000  with loss  11.509004592895508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  936  of  100000  with loss  9.673654556274414\n",
      "Training step  937  of  100000  with loss  10.301504135131836\n",
      "Training step  938  of  100000  with loss  9.385834693908691\n",
      "Training step  939  of  100000  with loss  9.382022857666016\n",
      "Training step  940  of  100000  with loss  10.234512329101562\n",
      "Training step  941  of  100000  with loss  10.043135643005371\n",
      "Training step  942  of  100000  with loss  9.842658996582031\n",
      "Training step  943  of  100000  with loss  9.29295825958252\n",
      "Training step  944  of  100000  with loss  10.142051696777344\n",
      "Training step  945  of  100000  with loss  10.440073013305664\n",
      "Training step  946  of  100000  with loss  9.411884307861328\n",
      "Training step  947  of  100000  with loss  10.62699031829834\n",
      "Training step  948  of  100000  with loss  11.883187294006348\n",
      "Training step  949  of  100000  with loss  10.616238594055176\n",
      "Training step  950  of  100000  with loss  10.084833145141602\n",
      "Training step  951  of  100000  with loss  10.263375282287598\n",
      "Training step  952  of  100000  with loss  10.106136322021484\n",
      "Training step  953  of  100000  with loss  9.663373947143555\n",
      "Training step  954  of  100000  with loss  9.455700874328613\n",
      "Training step  955  of  100000  with loss  9.738121032714844\n",
      "Training step  956  of  100000  with loss  10.797513961791992\n",
      "Training step  957  of  100000  with loss  11.472168922424316\n",
      "Training step  958  of  100000  with loss  10.190805435180664\n",
      "Training step  959  of  100000  with loss  10.604162216186523\n",
      "Training step  960  of  100000  with loss  10.823297500610352\n",
      "Training step  961  of  100000  with loss  8.882758140563965\n",
      "Training step  962  of  100000  with loss  9.121190071105957\n",
      "Training step  963  of  100000  with loss  9.598424911499023\n",
      "Training step  964  of  100000  with loss  10.004678726196289\n",
      "Training step  965  of  100000  with loss  9.598896026611328\n",
      "Training step  966  of  100000  with loss  10.751728057861328\n",
      "Training step  967  of  100000  with loss  10.073161125183105\n",
      "Training step  968  of  100000  with loss  9.794057846069336\n",
      "Training step  969  of  100000  with loss  10.744535446166992\n",
      "Training step  970  of  100000  with loss  9.457706451416016\n",
      "Training step  971  of  100000  with loss  9.10174560546875\n",
      "Training step  972  of  100000  with loss  8.816020011901855\n",
      "Training step  973  of  100000  with loss  9.40414047241211\n",
      "Training step  974  of  100000  with loss  9.617963790893555\n",
      "Training step  975  of  100000  with loss  10.617449760437012\n",
      "Training step  976  of  100000  with loss  10.995295524597168\n",
      "Training step  977  of  100000  with loss  8.793975830078125\n",
      "Training step  978  of  100000  with loss  9.121980667114258\n",
      "Training step  979  of  100000  with loss  9.973876953125\n",
      "Training step  980  of  100000  with loss  11.344114303588867\n",
      "Training step  981  of  100000  with loss  10.602177619934082\n",
      "Training step  982  of  100000  with loss  9.867973327636719\n",
      "Training step  983  of  100000  with loss  9.607268333435059\n",
      "Training step  984  of  100000  with loss  10.347898483276367\n",
      "Training step  985  of  100000  with loss  11.08251953125\n",
      "Training step  986  of  100000  with loss  9.408149719238281\n",
      "Training step  987  of  100000  with loss  8.73942756652832\n",
      "Training step  988  of  100000  with loss  9.400777816772461\n",
      "Training step  989  of  100000  with loss  10.986560821533203\n",
      "Training step  990  of  100000  with loss  9.35543441772461\n",
      "Training step  991  of  100000  with loss  9.509437561035156\n",
      "Training step  992  of  100000  with loss  10.734859466552734\n",
      "Training step  993  of  100000  with loss  10.128185272216797\n",
      "Training step  994  of  100000  with loss  9.369182586669922\n",
      "Training step  995  of  100000  with loss  9.792898178100586\n",
      "Training step  996  of  100000  with loss  10.157125473022461\n",
      "Training step  997  of  100000  with loss  9.67503833770752\n",
      "Training step  998  of  100000  with loss  10.252864837646484\n",
      "Training step  999  of  100000  with loss  9.368719100952148\n",
      "Training step  1000  of  100000  with loss  9.212130546569824\n",
      "Training step  1001  of  100000  with loss  9.286421775817871\n",
      "Training step  1002  of  100000  with loss  9.800806999206543\n",
      "Training step  1003  of  100000  with loss  10.476682662963867\n",
      "Training step  1004  of  100000  with loss  8.978034973144531\n",
      "Training step  1005  of  100000  with loss  9.747300148010254\n",
      "Training step  1006  of  100000  with loss  11.510406494140625\n",
      "Training step  1007  of  100000  with loss  9.72313117980957\n",
      "Training step  1008  of  100000  with loss  9.738811492919922\n",
      "Training step  1009  of  100000  with loss  9.852792739868164\n",
      "Training step  1010  of  100000  with loss  8.78038215637207\n",
      "Training step  1011  of  100000  with loss  10.742656707763672\n",
      "Training step  1012  of  100000  with loss  10.296988487243652\n",
      "Training step  1013  of  100000  with loss  11.416170120239258\n",
      "Training step  1014  of  100000  with loss  9.777400016784668\n",
      "Training step  1015  of  100000  with loss  9.69595718383789\n",
      "Training step  1016  of  100000  with loss  9.684447288513184\n",
      "Training step  1017  of  100000  with loss  9.435321807861328\n",
      "Training step  1018  of  100000  with loss  9.659870147705078\n",
      "Training step  1019  of  100000  with loss  10.10527229309082\n",
      "Training step  1020  of  100000  with loss  10.810018539428711\n",
      "Training step  1021  of  100000  with loss  9.601001739501953\n",
      "Training step  1022  of  100000  with loss  9.797447204589844\n",
      "Training step  1023  of  100000  with loss  9.51896858215332\n",
      "Training step  1024  of  100000  with loss  11.118428230285645\n",
      "Training step  1025  of  100000  with loss  9.225685119628906\n",
      "Training step  1026  of  100000  with loss  11.165508270263672\n",
      "Training step  1027  of  100000  with loss  11.321605682373047\n",
      "Training step  1028  of  100000  with loss  11.086944580078125\n",
      "Training step  1029  of  100000  with loss  10.11892032623291\n",
      "Training step  1030  of  100000  with loss  11.916229248046875\n",
      "Training step  1031  of  100000  with loss  8.991559982299805\n",
      "Training step  1032  of  100000  with loss  9.747182846069336\n",
      "Training step  1033  of  100000  with loss  9.119735717773438\n",
      "Training step  1034  of  100000  with loss  10.638099670410156\n",
      "Training step  1035  of  100000  with loss  9.534178733825684\n",
      "Training step  1036  of  100000  with loss  9.850334167480469\n",
      "Training step  1037  of  100000  with loss  10.654736518859863\n",
      "Training step  1038  of  100000  with loss  10.079401016235352\n",
      "Training step  1039  of  100000  with loss  10.289291381835938\n",
      "Training step  1040  of  100000  with loss  11.004720687866211\n",
      "Training step  1041  of  100000  with loss  10.563974380493164\n",
      "Training step  1042  of  100000  with loss  9.207174301147461\n",
      "Training step  1043  of  100000  with loss  9.532966613769531\n",
      "Training step  1044  of  100000  with loss  10.105838775634766\n",
      "Training step  1045  of  100000  with loss  10.411216735839844\n",
      "Training step  1046  of  100000  with loss  9.596397399902344\n",
      "Training step  1047  of  100000  with loss  8.869794845581055\n",
      "Training step  1048  of  100000  with loss  9.56641960144043\n",
      "Training step  1049  of  100000  with loss  11.32177734375\n",
      "Training step  1050  of  100000  with loss  10.490072250366211\n",
      "Training step  1051  of  100000  with loss  8.84762191772461\n",
      "Training step  1052  of  100000  with loss  11.37200927734375\n",
      "Training step  1053  of  100000  with loss  10.785277366638184\n",
      "Training step  1054  of  100000  with loss  9.711541175842285\n",
      "Training step  1055  of  100000  with loss  10.245372772216797\n",
      "Training step  1056  of  100000  with loss  11.040382385253906\n",
      "Training step  1057  of  100000  with loss  9.893733978271484\n",
      "Training step  1058  of  100000  with loss  10.225447654724121\n",
      "Training step  1059  of  100000  with loss  9.268630027770996\n",
      "Training step  1060  of  100000  with loss  9.719091415405273\n",
      "Training step  1061  of  100000  with loss  10.817249298095703\n",
      "Training step  1062  of  100000  with loss  8.233642578125\n",
      "Training step  1063  of  100000  with loss  9.98365592956543\n",
      "Training step  1064  of  100000  with loss  9.594524383544922\n",
      "Training step  1065  of  100000  with loss  10.526826858520508\n",
      "Training step  1066  of  100000  with loss  10.00401496887207\n",
      "Training step  1067  of  100000  with loss  8.937658309936523\n",
      "Training step  1068  of  100000  with loss  9.685659408569336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1069  of  100000  with loss  9.224624633789062\n",
      "Training step  1070  of  100000  with loss  8.867350578308105\n",
      "Training step  1071  of  100000  with loss  12.138755798339844\n",
      "Training step  1072  of  100000  with loss  11.134865760803223\n",
      "Training step  1073  of  100000  with loss  9.198999404907227\n",
      "Training step  1074  of  100000  with loss  9.76858139038086\n",
      "Training step  1075  of  100000  with loss  10.199674606323242\n",
      "Training step  1076  of  100000  with loss  9.406122207641602\n",
      "Training step  1077  of  100000  with loss  8.658055305480957\n",
      "Training step  1078  of  100000  with loss  9.787857055664062\n",
      "Training step  1079  of  100000  with loss  10.693816184997559\n",
      "Training step  1080  of  100000  with loss  10.273578643798828\n",
      "Training step  1081  of  100000  with loss  9.56019401550293\n",
      "Training step  1082  of  100000  with loss  10.36838150024414\n",
      "Training step  1083  of  100000  with loss  9.452831268310547\n",
      "Training step  1084  of  100000  with loss  9.657252311706543\n",
      "Training step  1085  of  100000  with loss  10.039641380310059\n",
      "Training step  1086  of  100000  with loss  9.994112014770508\n",
      "Training step  1087  of  100000  with loss  9.055306434631348\n",
      "Training step  1088  of  100000  with loss  9.664776802062988\n",
      "Training step  1089  of  100000  with loss  8.77914047241211\n",
      "Training step  1090  of  100000  with loss  10.829643249511719\n",
      "Training step  1091  of  100000  with loss  9.067248344421387\n",
      "Training step  1092  of  100000  with loss  9.37894344329834\n",
      "Training step  1093  of  100000  with loss  11.454667091369629\n",
      "Training step  1094  of  100000  with loss  8.895613670349121\n",
      "Training step  1095  of  100000  with loss  9.93864631652832\n",
      "Training step  1096  of  100000  with loss  9.697940826416016\n",
      "Training step  1097  of  100000  with loss  10.565850257873535\n",
      "Training step  1098  of  100000  with loss  10.467001914978027\n",
      "Training step  1099  of  100000  with loss  11.32680892944336\n",
      "Training step  1100  of  100000  with loss  10.424583435058594\n",
      "Training step  1101  of  100000  with loss  10.822310447692871\n",
      "Training step  1102  of  100000  with loss  11.601621627807617\n",
      "Training step  1103  of  100000  with loss  8.6072998046875\n",
      "Training step  1104  of  100000  with loss  10.671581268310547\n",
      "Training step  1105  of  100000  with loss  11.694900512695312\n",
      "Training step  1106  of  100000  with loss  8.790833473205566\n",
      "Training step  1107  of  100000  with loss  10.141904830932617\n",
      "Training step  1108  of  100000  with loss  10.410435676574707\n",
      "Training step  1109  of  100000  with loss  10.346357345581055\n",
      "Training step  1110  of  100000  with loss  9.783670425415039\n",
      "Training step  1111  of  100000  with loss  9.660045623779297\n",
      "Training step  1112  of  100000  with loss  9.6541166305542\n",
      "Training step  1113  of  100000  with loss  9.305179595947266\n",
      "Training step  1114  of  100000  with loss  9.51094913482666\n",
      "Training step  1115  of  100000  with loss  9.58552360534668\n",
      "Training step  1116  of  100000  with loss  8.846885681152344\n",
      "Training step  1117  of  100000  with loss  8.844871520996094\n",
      "Training step  1118  of  100000  with loss  11.190139770507812\n",
      "Training step  1119  of  100000  with loss  11.429998397827148\n",
      "Training step  1120  of  100000  with loss  10.330623626708984\n",
      "Training step  1121  of  100000  with loss  9.64217758178711\n",
      "Training step  1122  of  100000  with loss  8.720525741577148\n",
      "Training step  1123  of  100000  with loss  9.745960235595703\n",
      "Training step  1124  of  100000  with loss  10.01107406616211\n",
      "Training step  1125  of  100000  with loss  9.835935592651367\n",
      "Training step  1126  of  100000  with loss  10.019832611083984\n",
      "Training step  1127  of  100000  with loss  10.26909065246582\n",
      "Training step  1128  of  100000  with loss  10.816619873046875\n",
      "Training step  1129  of  100000  with loss  9.792905807495117\n",
      "Training step  1130  of  100000  with loss  9.48577880859375\n",
      "Training step  1131  of  100000  with loss  10.469096183776855\n",
      "Training step  1132  of  100000  with loss  9.475380897521973\n",
      "Training step  1133  of  100000  with loss  8.914791107177734\n",
      "Training step  1134  of  100000  with loss  9.504659652709961\n",
      "Training step  1135  of  100000  with loss  8.905200958251953\n",
      "Training step  1136  of  100000  with loss  9.148717880249023\n",
      "Training step  1137  of  100000  with loss  11.900751113891602\n",
      "Training step  1138  of  100000  with loss  10.711971282958984\n",
      "Training step  1139  of  100000  with loss  10.097420692443848\n",
      "Training step  1140  of  100000  with loss  9.452863693237305\n",
      "Training step  1141  of  100000  with loss  10.109850883483887\n",
      "Training step  1142  of  100000  with loss  10.263248443603516\n",
      "Training step  1143  of  100000  with loss  10.292112350463867\n",
      "Training step  1144  of  100000  with loss  10.346415519714355\n",
      "Training step  1145  of  100000  with loss  8.792043685913086\n",
      "Training step  1146  of  100000  with loss  10.279109954833984\n",
      "Training step  1147  of  100000  with loss  10.489407539367676\n",
      "Training step  1148  of  100000  with loss  8.924043655395508\n",
      "Training step  1149  of  100000  with loss  11.994510650634766\n",
      "Training step  1150  of  100000  with loss  11.057783126831055\n",
      "Training step  1151  of  100000  with loss  9.975120544433594\n",
      "Training step  1152  of  100000  with loss  9.98013687133789\n",
      "Training step  1153  of  100000  with loss  9.818668365478516\n",
      "Training step  1154  of  100000  with loss  10.34435749053955\n",
      "Training step  1155  of  100000  with loss  8.827085494995117\n",
      "Training step  1156  of  100000  with loss  10.779386520385742\n",
      "Training step  1157  of  100000  with loss  9.908662796020508\n",
      "Training step  1158  of  100000  with loss  11.030776023864746\n",
      "Training step  1159  of  100000  with loss  9.62728500366211\n",
      "Training step  1160  of  100000  with loss  8.806785583496094\n",
      "Training step  1161  of  100000  with loss  10.77369499206543\n",
      "Training step  1162  of  100000  with loss  10.45470905303955\n",
      "Training step  1163  of  100000  with loss  8.85545539855957\n",
      "Training step  1164  of  100000  with loss  9.560944557189941\n",
      "Training step  1165  of  100000  with loss  10.905567169189453\n",
      "Training step  1166  of  100000  with loss  10.966678619384766\n",
      "Training step  1167  of  100000  with loss  9.452231407165527\n",
      "Training step  1168  of  100000  with loss  11.326837539672852\n",
      "Training step  1169  of  100000  with loss  10.336313247680664\n",
      "Training step  1170  of  100000  with loss  11.81295394897461\n",
      "Training step  1171  of  100000  with loss  10.4200439453125\n",
      "Training step  1172  of  100000  with loss  9.778719902038574\n",
      "Training step  1173  of  100000  with loss  10.118678092956543\n",
      "Training step  1174  of  100000  with loss  10.61808967590332\n",
      "Training step  1175  of  100000  with loss  9.46633529663086\n",
      "Training step  1176  of  100000  with loss  10.863160133361816\n",
      "Training step  1177  of  100000  with loss  9.937665939331055\n",
      "Training step  1178  of  100000  with loss  9.870782852172852\n",
      "Training step  1179  of  100000  with loss  8.799722671508789\n",
      "Training step  1180  of  100000  with loss  9.928762435913086\n",
      "Training step  1181  of  100000  with loss  9.771068572998047\n",
      "Training step  1182  of  100000  with loss  10.432586669921875\n",
      "Training step  1183  of  100000  with loss  10.772377967834473\n",
      "Training step  1184  of  100000  with loss  9.768616676330566\n",
      "Training step  1185  of  100000  with loss  10.675065994262695\n",
      "Training step  1186  of  100000  with loss  10.52990436553955\n",
      "Training step  1187  of  100000  with loss  9.529325485229492\n",
      "Training step  1188  of  100000  with loss  9.236173629760742\n",
      "Training step  1189  of  100000  with loss  10.263830184936523\n",
      "Training step  1190  of  100000  with loss  10.197454452514648\n",
      "Training step  1191  of  100000  with loss  10.730369567871094\n",
      "Training step  1192  of  100000  with loss  9.894947052001953\n",
      "Training step  1193  of  100000  with loss  9.01007080078125\n",
      "Training step  1194  of  100000  with loss  11.293808937072754\n",
      "Training step  1195  of  100000  with loss  9.934993743896484\n",
      "Training step  1196  of  100000  with loss  10.203739166259766\n",
      "Training step  1197  of  100000  with loss  10.39036750793457\n",
      "Training step  1198  of  100000  with loss  10.92483139038086\n",
      "Training step  1199  of  100000  with loss  10.187864303588867\n",
      "Training step  1200  of  100000  with loss  9.975939750671387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1201  of  100000  with loss  9.438664436340332\n",
      "Training step  1202  of  100000  with loss  8.737749099731445\n",
      "Training step  1203  of  100000  with loss  10.353971481323242\n",
      "Training step  1204  of  100000  with loss  9.956851959228516\n",
      "Training step  1205  of  100000  with loss  10.563131332397461\n",
      "Training step  1206  of  100000  with loss  9.616144180297852\n",
      "Training step  1207  of  100000  with loss  9.233903884887695\n",
      "Training step  1208  of  100000  with loss  10.07118034362793\n",
      "Training step  1209  of  100000  with loss  11.402105331420898\n",
      "Training step  1210  of  100000  with loss  8.230213165283203\n",
      "Training step  1211  of  100000  with loss  10.295969009399414\n",
      "Training step  1212  of  100000  with loss  9.260503768920898\n",
      "Training step  1213  of  100000  with loss  9.040962219238281\n",
      "Training step  1214  of  100000  with loss  9.190876960754395\n",
      "Training step  1215  of  100000  with loss  10.085220336914062\n",
      "Training step  1216  of  100000  with loss  10.234811782836914\n",
      "Training step  1217  of  100000  with loss  9.290252685546875\n",
      "Training step  1218  of  100000  with loss  11.444247245788574\n",
      "Training step  1219  of  100000  with loss  9.769889831542969\n",
      "Training step  1220  of  100000  with loss  10.543621063232422\n",
      "Training step  1221  of  100000  with loss  11.20461368560791\n",
      "Training step  1222  of  100000  with loss  9.670204162597656\n",
      "Training step  1223  of  100000  with loss  10.26784610748291\n",
      "Training step  1224  of  100000  with loss  10.179536819458008\n",
      "Training step  1225  of  100000  with loss  9.103790283203125\n",
      "Training step  1226  of  100000  with loss  9.857781410217285\n",
      "Training step  1227  of  100000  with loss  9.29653549194336\n",
      "Training step  1228  of  100000  with loss  8.877936363220215\n",
      "Training step  1229  of  100000  with loss  9.814841270446777\n",
      "Training step  1230  of  100000  with loss  9.881568908691406\n",
      "Training step  1231  of  100000  with loss  10.245960235595703\n",
      "Training step  1232  of  100000  with loss  9.792859077453613\n",
      "Training step  1233  of  100000  with loss  9.888484001159668\n",
      "Training step  1234  of  100000  with loss  10.04913330078125\n",
      "Training step  1235  of  100000  with loss  12.038715362548828\n",
      "Training step  1236  of  100000  with loss  10.081350326538086\n",
      "Training step  1237  of  100000  with loss  10.959019660949707\n",
      "Training step  1238  of  100000  with loss  11.825016021728516\n",
      "Training step  1239  of  100000  with loss  9.81653881072998\n",
      "Training step  1240  of  100000  with loss  10.55268383026123\n",
      "Training step  1241  of  100000  with loss  8.629262924194336\n",
      "Training step  1242  of  100000  with loss  10.347137451171875\n",
      "Training step  1243  of  100000  with loss  10.0577392578125\n",
      "Training step  1244  of  100000  with loss  9.06723403930664\n",
      "Training step  1245  of  100000  with loss  11.039243698120117\n",
      "Training step  1246  of  100000  with loss  9.461997032165527\n",
      "Training step  1247  of  100000  with loss  9.755350112915039\n",
      "Training step  1248  of  100000  with loss  10.11727523803711\n",
      "Training step  1249  of  100000  with loss  9.448541641235352\n",
      "Training step  1250  of  100000  with loss  10.023969650268555\n",
      "Training step  1251  of  100000  with loss  10.496849060058594\n",
      "Training step  1252  of  100000  with loss  9.99965763092041\n",
      "Training step  1253  of  100000  with loss  9.112998962402344\n",
      "Training step  1254  of  100000  with loss  9.960481643676758\n",
      "Training step  1255  of  100000  with loss  10.880315780639648\n",
      "Training step  1256  of  100000  with loss  10.578336715698242\n",
      "Training step  1257  of  100000  with loss  9.1985445022583\n",
      "Training step  1258  of  100000  with loss  10.418009757995605\n",
      "Training step  1259  of  100000  with loss  10.280980110168457\n",
      "Training step  1260  of  100000  with loss  9.408862113952637\n",
      "Training step  1261  of  100000  with loss  9.288602828979492\n",
      "Training step  1262  of  100000  with loss  10.329201698303223\n",
      "Training step  1263  of  100000  with loss  8.87952995300293\n",
      "Training step  1264  of  100000  with loss  12.001839637756348\n",
      "Training step  1265  of  100000  with loss  10.668390274047852\n",
      "Training step  1266  of  100000  with loss  11.264164924621582\n",
      "Training step  1267  of  100000  with loss  10.05571174621582\n",
      "Training step  1268  of  100000  with loss  9.785411834716797\n",
      "Training step  1269  of  100000  with loss  8.92463207244873\n",
      "Training step  1270  of  100000  with loss  9.72890853881836\n",
      "Training step  1271  of  100000  with loss  9.852884292602539\n",
      "Training step  1272  of  100000  with loss  12.179259300231934\n",
      "Training step  1273  of  100000  with loss  9.924097061157227\n",
      "Training step  1274  of  100000  with loss  11.106620788574219\n",
      "Training step  1275  of  100000  with loss  10.153385162353516\n",
      "Training step  1276  of  100000  with loss  9.755121231079102\n",
      "Training step  1277  of  100000  with loss  10.267318725585938\n",
      "Training step  1278  of  100000  with loss  10.15281867980957\n",
      "Training step  1279  of  100000  with loss  8.777050018310547\n",
      "Training step  1280  of  100000  with loss  9.909791946411133\n",
      "Training step  1281  of  100000  with loss  10.15951156616211\n",
      "Training step  1282  of  100000  with loss  9.578794479370117\n",
      "Training step  1283  of  100000  with loss  11.468620300292969\n",
      "Training step  1284  of  100000  with loss  9.73754596710205\n",
      "Training step  1285  of  100000  with loss  10.131566047668457\n",
      "Training step  1286  of  100000  with loss  10.240265846252441\n",
      "Training step  1287  of  100000  with loss  11.804240226745605\n",
      "Training step  1288  of  100000  with loss  9.995595932006836\n",
      "Training step  1289  of  100000  with loss  9.134862899780273\n",
      "Training step  1290  of  100000  with loss  10.588785171508789\n",
      "Training step  1291  of  100000  with loss  9.741689682006836\n",
      "Training step  1292  of  100000  with loss  10.236763000488281\n",
      "Training step  1293  of  100000  with loss  8.580205917358398\n",
      "Training step  1294  of  100000  with loss  10.227128028869629\n",
      "Training step  1295  of  100000  with loss  10.553897857666016\n",
      "Training step  1296  of  100000  with loss  11.94236946105957\n",
      "Training step  1297  of  100000  with loss  10.316960334777832\n",
      "Training step  1298  of  100000  with loss  9.448713302612305\n",
      "Training step  1299  of  100000  with loss  10.726949691772461\n",
      "Training step  1300  of  100000  with loss  10.953495025634766\n",
      "Training step  1301  of  100000  with loss  10.168220520019531\n",
      "Training step  1302  of  100000  with loss  8.789782524108887\n",
      "Training step  1303  of  100000  with loss  10.270373344421387\n",
      "Training step  1304  of  100000  with loss  11.207249641418457\n",
      "Training step  1305  of  100000  with loss  9.68250560760498\n",
      "Training step  1306  of  100000  with loss  8.553632736206055\n",
      "Training step  1307  of  100000  with loss  11.279722213745117\n",
      "Training step  1308  of  100000  with loss  10.194629669189453\n",
      "Training step  1309  of  100000  with loss  11.38994026184082\n",
      "Training step  1310  of  100000  with loss  10.545537948608398\n",
      "Training step  1311  of  100000  with loss  10.669965744018555\n",
      "Training step  1312  of  100000  with loss  9.390172958374023\n",
      "Training step  1313  of  100000  with loss  10.899372100830078\n",
      "Training step  1314  of  100000  with loss  11.607195854187012\n",
      "Training step  1315  of  100000  with loss  10.673063278198242\n",
      "Training step  1316  of  100000  with loss  9.145809173583984\n",
      "Training step  1317  of  100000  with loss  8.770731925964355\n",
      "Training step  1318  of  100000  with loss  9.567207336425781\n",
      "Training step  1319  of  100000  with loss  10.032020568847656\n",
      "Training step  1320  of  100000  with loss  9.920806884765625\n",
      "Training step  1321  of  100000  with loss  10.091715812683105\n",
      "Training step  1322  of  100000  with loss  12.236349105834961\n",
      "Training step  1323  of  100000  with loss  10.670099258422852\n",
      "Training step  1324  of  100000  with loss  9.323771476745605\n",
      "Training step  1325  of  100000  with loss  9.32899284362793\n",
      "Training step  1326  of  100000  with loss  8.70598316192627\n",
      "Training step  1327  of  100000  with loss  9.875738143920898\n",
      "Training step  1328  of  100000  with loss  8.890695571899414\n",
      "Training step  1329  of  100000  with loss  10.9999418258667\n",
      "Training step  1330  of  100000  with loss  10.64891529083252\n",
      "Training step  1331  of  100000  with loss  10.151628494262695\n",
      "Training step  1332  of  100000  with loss  9.939983367919922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1333  of  100000  with loss  9.832599639892578\n",
      "Training step  1334  of  100000  with loss  12.350212097167969\n",
      "Training step  1335  of  100000  with loss  10.788240432739258\n",
      "Training step  1336  of  100000  with loss  9.244074821472168\n",
      "Training step  1337  of  100000  with loss  8.244083404541016\n",
      "Training step  1338  of  100000  with loss  10.204262733459473\n",
      "Training step  1339  of  100000  with loss  9.1154146194458\n",
      "Training step  1340  of  100000  with loss  11.619287490844727\n",
      "Training step  1341  of  100000  with loss  10.847317695617676\n",
      "Training step  1342  of  100000  with loss  9.71383285522461\n",
      "Training step  1343  of  100000  with loss  9.66036319732666\n",
      "Training step  1344  of  100000  with loss  10.264787673950195\n",
      "Training step  1345  of  100000  with loss  9.911123275756836\n",
      "Training step  1346  of  100000  with loss  10.58442211151123\n",
      "Training step  1347  of  100000  with loss  10.881440162658691\n",
      "Training step  1348  of  100000  with loss  10.74838638305664\n",
      "Training step  1349  of  100000  with loss  11.059762001037598\n",
      "Training step  1350  of  100000  with loss  10.691167831420898\n",
      "Training step  1351  of  100000  with loss  9.813986778259277\n",
      "Training step  1352  of  100000  with loss  10.961697578430176\n",
      "Training step  1353  of  100000  with loss  11.353179931640625\n",
      "Training step  1354  of  100000  with loss  9.729111671447754\n",
      "Training step  1355  of  100000  with loss  9.258110046386719\n",
      "Training step  1356  of  100000  with loss  12.737335205078125\n",
      "Training step  1357  of  100000  with loss  9.733014106750488\n",
      "Training step  1358  of  100000  with loss  9.186118125915527\n",
      "Training step  1359  of  100000  with loss  9.45831298828125\n",
      "Training step  1360  of  100000  with loss  10.726601600646973\n",
      "Training step  1361  of  100000  with loss  10.998180389404297\n",
      "Training step  1362  of  100000  with loss  9.734247207641602\n",
      "Training step  1363  of  100000  with loss  11.777185440063477\n",
      "Training step  1364  of  100000  with loss  10.373064041137695\n",
      "Training step  1365  of  100000  with loss  8.842716217041016\n",
      "Training step  1366  of  100000  with loss  9.611352920532227\n",
      "Training step  1367  of  100000  with loss  9.961679458618164\n",
      "Training step  1368  of  100000  with loss  9.31478500366211\n",
      "Training step  1369  of  100000  with loss  9.100371360778809\n",
      "Training step  1370  of  100000  with loss  11.730354309082031\n",
      "Training step  1371  of  100000  with loss  9.482951164245605\n",
      "Training step  1372  of  100000  with loss  11.602432250976562\n",
      "Training step  1373  of  100000  with loss  10.00289535522461\n",
      "Training step  1374  of  100000  with loss  10.057687759399414\n",
      "Training step  1375  of  100000  with loss  9.494879722595215\n",
      "Training step  1376  of  100000  with loss  10.483667373657227\n",
      "Training step  1377  of  100000  with loss  10.737665176391602\n",
      "Training step  1378  of  100000  with loss  9.929216384887695\n",
      "Training step  1379  of  100000  with loss  10.22937297821045\n",
      "Training step  1380  of  100000  with loss  9.539048194885254\n",
      "Training step  1381  of  100000  with loss  9.827383041381836\n",
      "Training step  1382  of  100000  with loss  9.020444869995117\n",
      "Training step  1383  of  100000  with loss  9.718301773071289\n",
      "Training step  1384  of  100000  with loss  12.583456993103027\n",
      "Training step  1385  of  100000  with loss  11.688699722290039\n",
      "Training step  1386  of  100000  with loss  10.376441955566406\n",
      "Training step  1387  of  100000  with loss  10.827239990234375\n",
      "Training step  1388  of  100000  with loss  9.268440246582031\n",
      "Training step  1389  of  100000  with loss  9.206605911254883\n",
      "Training step  1390  of  100000  with loss  11.026567459106445\n",
      "Training step  1391  of  100000  with loss  9.528498649597168\n",
      "Training step  1392  of  100000  with loss  10.606956481933594\n",
      "Training step  1393  of  100000  with loss  9.737905502319336\n",
      "Training step  1394  of  100000  with loss  10.391128540039062\n",
      "Training step  1395  of  100000  with loss  10.883785247802734\n",
      "Training step  1396  of  100000  with loss  10.461734771728516\n",
      "Training step  1397  of  100000  with loss  8.986556053161621\n",
      "Training step  1398  of  100000  with loss  8.51330280303955\n",
      "Training step  1399  of  100000  with loss  10.468950271606445\n",
      "Training step  1400  of  100000  with loss  9.872909545898438\n",
      "Training step  1401  of  100000  with loss  11.906086921691895\n",
      "Training step  1402  of  100000  with loss  9.447123527526855\n",
      "Training step  1403  of  100000  with loss  9.479909896850586\n",
      "Training step  1404  of  100000  with loss  9.086996078491211\n",
      "Training step  1405  of  100000  with loss  9.75463581085205\n",
      "Training step  1406  of  100000  with loss  10.102839469909668\n",
      "Training step  1407  of  100000  with loss  9.007987022399902\n",
      "Training step  1408  of  100000  with loss  10.6607027053833\n",
      "Training step  1409  of  100000  with loss  8.089048385620117\n",
      "Training step  1410  of  100000  with loss  10.25602912902832\n",
      "Training step  1411  of  100000  with loss  10.795395851135254\n",
      "Training step  1412  of  100000  with loss  11.439071655273438\n",
      "Training step  1413  of  100000  with loss  8.336122512817383\n",
      "Training step  1414  of  100000  with loss  9.441731452941895\n",
      "Training step  1415  of  100000  with loss  10.069812774658203\n",
      "Training step  1416  of  100000  with loss  9.170860290527344\n",
      "Training step  1417  of  100000  with loss  9.379280090332031\n",
      "Training step  1418  of  100000  with loss  8.928679466247559\n",
      "Training step  1419  of  100000  with loss  9.114928245544434\n",
      "Training step  1420  of  100000  with loss  10.21828842163086\n",
      "Training step  1421  of  100000  with loss  10.719745635986328\n",
      "Training step  1422  of  100000  with loss  9.99483871459961\n",
      "Training step  1423  of  100000  with loss  10.203908920288086\n",
      "Training step  1424  of  100000  with loss  9.587092399597168\n",
      "Training step  1425  of  100000  with loss  10.604990005493164\n",
      "Training step  1426  of  100000  with loss  10.490950584411621\n",
      "Training step  1427  of  100000  with loss  9.627747535705566\n",
      "Training step  1428  of  100000  with loss  10.648067474365234\n",
      "Training step  1429  of  100000  with loss  10.161931037902832\n",
      "Training step  1430  of  100000  with loss  9.730308532714844\n",
      "Training step  1431  of  100000  with loss  8.886509895324707\n",
      "Training step  1432  of  100000  with loss  8.848621368408203\n",
      "Training step  1433  of  100000  with loss  9.568381309509277\n",
      "Training step  1434  of  100000  with loss  9.571737289428711\n",
      "Training step  1435  of  100000  with loss  9.42089557647705\n",
      "Training step  1436  of  100000  with loss  10.398963928222656\n",
      "Training step  1437  of  100000  with loss  10.989702224731445\n",
      "Training step  1438  of  100000  with loss  10.009220123291016\n",
      "Training step  1439  of  100000  with loss  11.205415725708008\n",
      "Training step  1440  of  100000  with loss  9.727864265441895\n",
      "Training step  1441  of  100000  with loss  8.889873504638672\n",
      "Training step  1442  of  100000  with loss  10.281229019165039\n",
      "Training step  1443  of  100000  with loss  8.868589401245117\n",
      "Training step  1444  of  100000  with loss  9.05418586730957\n",
      "Training step  1445  of  100000  with loss  10.784181594848633\n",
      "Training step  1446  of  100000  with loss  10.332452774047852\n",
      "Training step  1447  of  100000  with loss  9.690667152404785\n",
      "Training step  1448  of  100000  with loss  9.31794548034668\n",
      "Training step  1449  of  100000  with loss  12.496394157409668\n",
      "Training step  1450  of  100000  with loss  9.500259399414062\n",
      "Training step  1451  of  100000  with loss  9.577386856079102\n",
      "Training step  1452  of  100000  with loss  8.528566360473633\n",
      "Training step  1453  of  100000  with loss  8.84161376953125\n",
      "Training step  1454  of  100000  with loss  9.57841968536377\n",
      "Training step  1455  of  100000  with loss  9.760818481445312\n",
      "Training step  1456  of  100000  with loss  9.524341583251953\n",
      "Training step  1457  of  100000  with loss  8.579793930053711\n",
      "Training step  1458  of  100000  with loss  11.448664665222168\n",
      "Training step  1459  of  100000  with loss  8.790386199951172\n",
      "Training step  1460  of  100000  with loss  9.184595108032227\n",
      "Training step  1461  of  100000  with loss  10.036003112792969\n",
      "Training step  1462  of  100000  with loss  9.871447563171387\n",
      "Training step  1463  of  100000  with loss  10.93701171875\n",
      "Training step  1464  of  100000  with loss  10.773686408996582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1465  of  100000  with loss  11.290472030639648\n",
      "Training step  1466  of  100000  with loss  9.39109992980957\n",
      "Training step  1467  of  100000  with loss  9.440616607666016\n",
      "Training step  1468  of  100000  with loss  10.930614471435547\n",
      "Training step  1469  of  100000  with loss  10.651166915893555\n",
      "Training step  1470  of  100000  with loss  10.241800308227539\n",
      "Training step  1471  of  100000  with loss  9.838181495666504\n",
      "Training step  1472  of  100000  with loss  9.722604751586914\n",
      "Training step  1473  of  100000  with loss  8.943838119506836\n",
      "Training step  1474  of  100000  with loss  10.139010429382324\n",
      "Training step  1475  of  100000  with loss  9.380897521972656\n",
      "Training step  1476  of  100000  with loss  10.626897811889648\n",
      "Training step  1477  of  100000  with loss  9.005207061767578\n",
      "Training step  1478  of  100000  with loss  10.223298072814941\n",
      "Training step  1479  of  100000  with loss  11.31484603881836\n",
      "Training step  1480  of  100000  with loss  10.800505638122559\n",
      "Training step  1481  of  100000  with loss  8.515802383422852\n",
      "Training step  1482  of  100000  with loss  10.420125961303711\n",
      "Training step  1483  of  100000  with loss  9.126765251159668\n",
      "Training step  1484  of  100000  with loss  12.05140495300293\n",
      "Training step  1485  of  100000  with loss  10.095903396606445\n",
      "Training step  1486  of  100000  with loss  8.650371551513672\n",
      "Training step  1487  of  100000  with loss  9.481705665588379\n",
      "Training step  1488  of  100000  with loss  9.750981330871582\n",
      "Training step  1489  of  100000  with loss  8.809173583984375\n",
      "Training step  1490  of  100000  with loss  9.3362398147583\n",
      "Training step  1491  of  100000  with loss  9.949383735656738\n",
      "Training step  1492  of  100000  with loss  9.552221298217773\n",
      "Training step  1493  of  100000  with loss  9.706798553466797\n",
      "Training step  1494  of  100000  with loss  9.933242797851562\n",
      "Training step  1495  of  100000  with loss  11.242658615112305\n",
      "Training step  1496  of  100000  with loss  9.893672943115234\n",
      "Training step  1497  of  100000  with loss  10.869691848754883\n",
      "Training step  1498  of  100000  with loss  9.153791427612305\n",
      "Training step  1499  of  100000  with loss  10.146525382995605\n",
      "Training step  1500  of  100000  with loss  9.744308471679688\n",
      "Training step  1501  of  100000  with loss  9.329326629638672\n",
      "Training step  1502  of  100000  with loss  10.885660171508789\n",
      "Training step  1503  of  100000  with loss  8.18991756439209\n",
      "Training step  1504  of  100000  with loss  10.594216346740723\n",
      "Training step  1505  of  100000  with loss  11.207557678222656\n",
      "Training step  1506  of  100000  with loss  10.255287170410156\n",
      "Training step  1507  of  100000  with loss  10.566400527954102\n",
      "Training step  1508  of  100000  with loss  9.592612266540527\n",
      "Training step  1509  of  100000  with loss  9.842662811279297\n",
      "Training step  1510  of  100000  with loss  9.609184265136719\n",
      "Training step  1511  of  100000  with loss  10.194511413574219\n",
      "Training step  1512  of  100000  with loss  9.561426162719727\n",
      "Training step  1513  of  100000  with loss  8.990732192993164\n",
      "Training step  1514  of  100000  with loss  9.597460746765137\n",
      "Training step  1515  of  100000  with loss  11.670705795288086\n",
      "Training step  1516  of  100000  with loss  9.159948348999023\n",
      "Training step  1517  of  100000  with loss  9.856202125549316\n",
      "Training step  1518  of  100000  with loss  11.227363586425781\n",
      "Training step  1519  of  100000  with loss  9.752837181091309\n",
      "Training step  1520  of  100000  with loss  9.690040588378906\n",
      "Training step  1521  of  100000  with loss  10.244215965270996\n",
      "Training step  1522  of  100000  with loss  9.258955001831055\n",
      "Training step  1523  of  100000  with loss  10.390031814575195\n",
      "Training step  1524  of  100000  with loss  10.076133728027344\n",
      "Training step  1525  of  100000  with loss  9.26439094543457\n",
      "Training step  1526  of  100000  with loss  11.653942108154297\n",
      "Training step  1527  of  100000  with loss  10.299880981445312\n",
      "Training step  1528  of  100000  with loss  9.079140663146973\n",
      "Training step  1529  of  100000  with loss  9.248088836669922\n",
      "Training step  1530  of  100000  with loss  10.723258972167969\n",
      "Training step  1531  of  100000  with loss  8.64826774597168\n",
      "Training step  1532  of  100000  with loss  9.992436408996582\n",
      "Training step  1533  of  100000  with loss  9.355274200439453\n",
      "Training step  1534  of  100000  with loss  9.015542984008789\n",
      "Training step  1535  of  100000  with loss  11.544748306274414\n",
      "Training step  1536  of  100000  with loss  9.831768989562988\n",
      "Training step  1537  of  100000  with loss  8.878332138061523\n",
      "Training step  1538  of  100000  with loss  10.517902374267578\n",
      "Training step  1539  of  100000  with loss  9.150810241699219\n",
      "Training step  1540  of  100000  with loss  10.197360038757324\n",
      "Training step  1541  of  100000  with loss  10.379470825195312\n",
      "Training step  1542  of  100000  with loss  9.632530212402344\n",
      "Training step  1543  of  100000  with loss  10.719664573669434\n",
      "Training step  1544  of  100000  with loss  8.842220306396484\n",
      "Training step  1545  of  100000  with loss  10.513145446777344\n",
      "Training step  1546  of  100000  with loss  9.98742389678955\n",
      "Training step  1547  of  100000  with loss  10.61933422088623\n",
      "Training step  1548  of  100000  with loss  9.757835388183594\n",
      "Training step  1549  of  100000  with loss  10.645238876342773\n",
      "Training step  1550  of  100000  with loss  9.032452583312988\n",
      "Training step  1551  of  100000  with loss  9.856331825256348\n",
      "Training step  1552  of  100000  with loss  9.821209907531738\n",
      "Training step  1553  of  100000  with loss  9.93600082397461\n",
      "Training step  1554  of  100000  with loss  9.135082244873047\n",
      "Training step  1555  of  100000  with loss  11.704681396484375\n",
      "Training step  1556  of  100000  with loss  9.140716552734375\n",
      "Training step  1557  of  100000  with loss  11.099233627319336\n",
      "Training step  1558  of  100000  with loss  10.311392784118652\n",
      "Training step  1559  of  100000  with loss  10.657757759094238\n",
      "Training step  1560  of  100000  with loss  9.183769226074219\n",
      "Training step  1561  of  100000  with loss  9.992151260375977\n",
      "Training step  1562  of  100000  with loss  9.373323440551758\n",
      "Training step  1563  of  100000  with loss  8.701202392578125\n",
      "Training step  1564  of  100000  with loss  9.768077850341797\n",
      "Training step  1565  of  100000  with loss  8.807065963745117\n",
      "Training step  1566  of  100000  with loss  9.63154125213623\n",
      "Training step  1567  of  100000  with loss  8.765039443969727\n",
      "Training step  1568  of  100000  with loss  9.591121673583984\n",
      "Training step  1569  of  100000  with loss  11.266274452209473\n",
      "Training step  1570  of  100000  with loss  9.289022445678711\n",
      "Training step  1571  of  100000  with loss  9.336894035339355\n",
      "Training step  1572  of  100000  with loss  9.770780563354492\n",
      "Training step  1573  of  100000  with loss  9.63315486907959\n",
      "Training step  1574  of  100000  with loss  10.21923828125\n",
      "Training step  1575  of  100000  with loss  9.910078048706055\n",
      "Training step  1576  of  100000  with loss  10.063858985900879\n",
      "Training step  1577  of  100000  with loss  9.916252136230469\n",
      "Training step  1578  of  100000  with loss  10.572078704833984\n",
      "Training step  1579  of  100000  with loss  8.517892837524414\n",
      "Training step  1580  of  100000  with loss  9.82851505279541\n",
      "Training step  1581  of  100000  with loss  9.17945671081543\n",
      "Training step  1582  of  100000  with loss  10.876565933227539\n",
      "Training step  1583  of  100000  with loss  10.084744453430176\n",
      "Training step  1584  of  100000  with loss  10.198058128356934\n",
      "Training step  1585  of  100000  with loss  8.970186233520508\n",
      "Training step  1586  of  100000  with loss  9.849905967712402\n",
      "Training step  1587  of  100000  with loss  11.308215141296387\n",
      "Training step  1588  of  100000  with loss  9.575460433959961\n",
      "Training step  1589  of  100000  with loss  10.165756225585938\n",
      "Training step  1590  of  100000  with loss  9.319267272949219\n",
      "Training step  1591  of  100000  with loss  9.289274215698242\n",
      "Training step  1592  of  100000  with loss  10.025690078735352\n",
      "Training step  1593  of  100000  with loss  10.444581031799316\n",
      "Training step  1594  of  100000  with loss  11.438563346862793\n",
      "Training step  1595  of  100000  with loss  9.2068452835083\n",
      "Training step  1596  of  100000  with loss  11.015483856201172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1597  of  100000  with loss  9.854409217834473\n",
      "Training step  1598  of  100000  with loss  9.599207878112793\n",
      "Training step  1599  of  100000  with loss  9.163622856140137\n",
      "Training step  1600  of  100000  with loss  9.931680679321289\n",
      "Training step  1601  of  100000  with loss  9.924969673156738\n",
      "Training step  1602  of  100000  with loss  10.488971710205078\n",
      "Training step  1603  of  100000  with loss  10.06971549987793\n",
      "Training step  1604  of  100000  with loss  10.959171295166016\n",
      "Training step  1605  of  100000  with loss  9.108104705810547\n",
      "Training step  1606  of  100000  with loss  10.269367218017578\n",
      "Training step  1607  of  100000  with loss  9.131341934204102\n",
      "Training step  1608  of  100000  with loss  9.316754341125488\n",
      "Training step  1609  of  100000  with loss  10.103466033935547\n",
      "Training step  1610  of  100000  with loss  8.548162460327148\n",
      "Training step  1611  of  100000  with loss  10.966985702514648\n",
      "Training step  1612  of  100000  with loss  9.425647735595703\n",
      "Training step  1613  of  100000  with loss  11.000445365905762\n",
      "Training step  1614  of  100000  with loss  9.886116027832031\n",
      "Training step  1615  of  100000  with loss  9.85031509399414\n",
      "Training step  1616  of  100000  with loss  10.277432441711426\n",
      "Training step  1617  of  100000  with loss  10.981202125549316\n",
      "Training step  1618  of  100000  with loss  10.800237655639648\n",
      "Training step  1619  of  100000  with loss  10.306464195251465\n",
      "Training step  1620  of  100000  with loss  9.674057006835938\n",
      "Training step  1621  of  100000  with loss  8.932765007019043\n",
      "Training step  1622  of  100000  with loss  10.346253395080566\n",
      "Training step  1623  of  100000  with loss  9.308363914489746\n",
      "Training step  1624  of  100000  with loss  10.40814208984375\n",
      "Training step  1625  of  100000  with loss  10.149178504943848\n",
      "Training step  1626  of  100000  with loss  10.077550888061523\n",
      "Training step  1627  of  100000  with loss  10.52821159362793\n",
      "Training step  1628  of  100000  with loss  10.84322738647461\n",
      "Training step  1629  of  100000  with loss  9.526668548583984\n",
      "Training step  1630  of  100000  with loss  10.285174369812012\n",
      "Training step  1631  of  100000  with loss  10.326303482055664\n",
      "Training step  1632  of  100000  with loss  8.687399864196777\n",
      "Training step  1633  of  100000  with loss  9.839508056640625\n",
      "Training step  1634  of  100000  with loss  9.990412712097168\n",
      "Training step  1635  of  100000  with loss  10.925447463989258\n",
      "Training step  1636  of  100000  with loss  8.886252403259277\n",
      "Training step  1637  of  100000  with loss  9.769187927246094\n",
      "Training step  1638  of  100000  with loss  10.172922134399414\n",
      "Training step  1639  of  100000  with loss  9.499364852905273\n",
      "Training step  1640  of  100000  with loss  9.680765151977539\n",
      "Training step  1641  of  100000  with loss  10.482461929321289\n",
      "Training step  1642  of  100000  with loss  10.86217212677002\n",
      "Training step  1643  of  100000  with loss  11.72983169555664\n",
      "Training step  1644  of  100000  with loss  9.634297370910645\n",
      "Training step  1645  of  100000  with loss  9.58482551574707\n",
      "Training step  1646  of  100000  with loss  9.695642471313477\n",
      "Training step  1647  of  100000  with loss  9.844446182250977\n",
      "Training step  1648  of  100000  with loss  9.242044448852539\n",
      "Training step  1649  of  100000  with loss  10.02691650390625\n",
      "Training step  1650  of  100000  with loss  10.012399673461914\n",
      "Training step  1651  of  100000  with loss  8.736433982849121\n",
      "Training step  1652  of  100000  with loss  9.631494522094727\n",
      "Training step  1653  of  100000  with loss  8.993183135986328\n",
      "Training step  1654  of  100000  with loss  8.681079864501953\n",
      "Training step  1655  of  100000  with loss  10.717949867248535\n",
      "Training step  1656  of  100000  with loss  12.394847869873047\n",
      "Training step  1657  of  100000  with loss  9.821054458618164\n",
      "Training step  1658  of  100000  with loss  10.389930725097656\n",
      "Training step  1659  of  100000  with loss  10.352540969848633\n",
      "Training step  1660  of  100000  with loss  9.339241981506348\n",
      "Training step  1661  of  100000  with loss  9.569215774536133\n",
      "Training step  1662  of  100000  with loss  10.692587852478027\n",
      "Training step  1663  of  100000  with loss  11.047828674316406\n",
      "Training step  1664  of  100000  with loss  9.803918838500977\n",
      "Training step  1665  of  100000  with loss  9.828293800354004\n",
      "Training step  1666  of  100000  with loss  10.327000617980957\n",
      "Training step  1667  of  100000  with loss  10.566319465637207\n",
      "Training step  1668  of  100000  with loss  10.60583209991455\n",
      "Training step  1669  of  100000  with loss  9.209077835083008\n",
      "Training step  1670  of  100000  with loss  9.799089431762695\n",
      "Training step  1671  of  100000  with loss  9.80758285522461\n",
      "Training step  1672  of  100000  with loss  8.683452606201172\n",
      "Training step  1673  of  100000  with loss  10.946022033691406\n",
      "Training step  1674  of  100000  with loss  10.046881675720215\n",
      "Training step  1675  of  100000  with loss  11.268854141235352\n",
      "Training step  1676  of  100000  with loss  11.712158203125\n",
      "Training step  1677  of  100000  with loss  9.904894828796387\n",
      "Training step  1678  of  100000  with loss  8.433337211608887\n",
      "Training step  1679  of  100000  with loss  9.712446212768555\n",
      "Training step  1680  of  100000  with loss  10.28956127166748\n",
      "Training step  1681  of  100000  with loss  10.012107849121094\n",
      "Training step  1682  of  100000  with loss  9.657083511352539\n",
      "Training step  1683  of  100000  with loss  10.10049057006836\n",
      "Training step  1684  of  100000  with loss  9.107501983642578\n",
      "Training step  1685  of  100000  with loss  9.928996086120605\n",
      "Training step  1686  of  100000  with loss  10.332847595214844\n",
      "Training step  1687  of  100000  with loss  12.005531311035156\n",
      "Training step  1688  of  100000  with loss  9.693746566772461\n",
      "Training step  1689  of  100000  with loss  10.634514808654785\n",
      "Training step  1690  of  100000  with loss  9.225584983825684\n",
      "Training step  1691  of  100000  with loss  9.068479537963867\n",
      "Training step  1692  of  100000  with loss  11.532690048217773\n",
      "Training step  1693  of  100000  with loss  8.791004180908203\n",
      "Training step  1694  of  100000  with loss  9.363117218017578\n",
      "Training step  1695  of  100000  with loss  9.972713470458984\n",
      "Training step  1696  of  100000  with loss  8.997540473937988\n",
      "Training step  1697  of  100000  with loss  9.741103172302246\n",
      "Training step  1698  of  100000  with loss  10.022308349609375\n",
      "Training step  1699  of  100000  with loss  9.629505157470703\n",
      "Training step  1700  of  100000  with loss  11.435262680053711\n",
      "Training step  1701  of  100000  with loss  11.84182357788086\n",
      "Training step  1702  of  100000  with loss  8.580789566040039\n",
      "Training step  1703  of  100000  with loss  11.945919036865234\n",
      "Training step  1704  of  100000  with loss  9.632482528686523\n",
      "Training step  1705  of  100000  with loss  11.591381072998047\n",
      "Training step  1706  of  100000  with loss  9.795884132385254\n",
      "Training step  1707  of  100000  with loss  9.754247665405273\n",
      "Training step  1708  of  100000  with loss  10.493935585021973\n",
      "Training step  1709  of  100000  with loss  10.186805725097656\n",
      "Training step  1710  of  100000  with loss  9.486875534057617\n",
      "Training step  1711  of  100000  with loss  10.187936782836914\n",
      "Training step  1712  of  100000  with loss  11.492958068847656\n",
      "Training step  1713  of  100000  with loss  10.537105560302734\n",
      "Training step  1714  of  100000  with loss  10.876686096191406\n",
      "Training step  1715  of  100000  with loss  9.817045211791992\n",
      "Training step  1716  of  100000  with loss  10.533792495727539\n",
      "Training step  1717  of  100000  with loss  10.183403968811035\n",
      "Training step  1718  of  100000  with loss  9.795661926269531\n",
      "Training step  1719  of  100000  with loss  11.655508041381836\n",
      "Training step  1720  of  100000  with loss  9.95046615600586\n",
      "Training step  1721  of  100000  with loss  9.978506088256836\n",
      "Training step  1722  of  100000  with loss  10.602123260498047\n",
      "Training step  1723  of  100000  with loss  9.928472518920898\n",
      "Training step  1724  of  100000  with loss  9.330061912536621\n",
      "Training step  1725  of  100000  with loss  10.169254302978516\n",
      "Training step  1726  of  100000  with loss  9.831539154052734\n",
      "Training step  1727  of  100000  with loss  11.002195358276367\n",
      "Training step  1728  of  100000  with loss  11.86154556274414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1729  of  100000  with loss  10.38242244720459\n",
      "Training step  1730  of  100000  with loss  9.535258293151855\n",
      "Training step  1731  of  100000  with loss  10.373870849609375\n",
      "Training step  1732  of  100000  with loss  10.475692749023438\n",
      "Training step  1733  of  100000  with loss  9.51242733001709\n",
      "Training step  1734  of  100000  with loss  10.70690631866455\n",
      "Training step  1735  of  100000  with loss  9.968262672424316\n",
      "Training step  1736  of  100000  with loss  10.190937042236328\n",
      "Training step  1737  of  100000  with loss  10.823352813720703\n",
      "Training step  1738  of  100000  with loss  10.506851196289062\n",
      "Training step  1739  of  100000  with loss  8.36275577545166\n",
      "Training step  1740  of  100000  with loss  9.68276596069336\n",
      "Training step  1741  of  100000  with loss  9.868327140808105\n",
      "Training step  1742  of  100000  with loss  9.189035415649414\n",
      "Training step  1743  of  100000  with loss  8.484745025634766\n",
      "Training step  1744  of  100000  with loss  9.586827278137207\n",
      "Training step  1745  of  100000  with loss  11.208379745483398\n",
      "Training step  1746  of  100000  with loss  11.47480583190918\n",
      "Training step  1747  of  100000  with loss  10.142969131469727\n",
      "Training step  1748  of  100000  with loss  10.991124153137207\n",
      "Training step  1749  of  100000  with loss  8.860897064208984\n",
      "Training step  1750  of  100000  with loss  9.506891250610352\n",
      "Training step  1751  of  100000  with loss  9.33491039276123\n",
      "Training step  1752  of  100000  with loss  9.200994491577148\n",
      "Training step  1753  of  100000  with loss  12.8213529586792\n",
      "Training step  1754  of  100000  with loss  10.378689765930176\n",
      "Training step  1755  of  100000  with loss  9.062761306762695\n",
      "Training step  1756  of  100000  with loss  9.605652809143066\n",
      "Training step  1757  of  100000  with loss  10.091390609741211\n",
      "Training step  1758  of  100000  with loss  10.034916877746582\n",
      "Training step  1759  of  100000  with loss  9.351959228515625\n",
      "Training step  1760  of  100000  with loss  9.7935791015625\n",
      "Training step  1761  of  100000  with loss  10.190267562866211\n",
      "Training step  1762  of  100000  with loss  9.557538032531738\n",
      "Training step  1763  of  100000  with loss  8.707342147827148\n",
      "Training step  1764  of  100000  with loss  9.59619426727295\n",
      "Training step  1765  of  100000  with loss  10.295279502868652\n",
      "Training step  1766  of  100000  with loss  11.241445541381836\n",
      "Training step  1767  of  100000  with loss  9.656450271606445\n",
      "Training step  1768  of  100000  with loss  9.561302185058594\n",
      "Training step  1769  of  100000  with loss  8.605491638183594\n",
      "Training step  1770  of  100000  with loss  9.023694038391113\n",
      "Training step  1771  of  100000  with loss  9.726570129394531\n",
      "Training step  1772  of  100000  with loss  11.474471092224121\n",
      "Training step  1773  of  100000  with loss  10.121845245361328\n",
      "Training step  1774  of  100000  with loss  9.356878280639648\n",
      "Training step  1775  of  100000  with loss  11.062219619750977\n",
      "Training step  1776  of  100000  with loss  10.353623390197754\n",
      "Training step  1777  of  100000  with loss  11.067742347717285\n",
      "Training step  1778  of  100000  with loss  10.737646102905273\n",
      "Training step  1779  of  100000  with loss  9.201530456542969\n",
      "Training step  1780  of  100000  with loss  9.32891845703125\n",
      "Training step  1781  of  100000  with loss  10.504146575927734\n",
      "Training step  1782  of  100000  with loss  10.21141529083252\n",
      "Training step  1783  of  100000  with loss  9.495500564575195\n",
      "Training step  1784  of  100000  with loss  10.24134635925293\n",
      "Training step  1785  of  100000  with loss  10.255714416503906\n",
      "Training step  1786  of  100000  with loss  9.750144958496094\n",
      "Training step  1787  of  100000  with loss  9.685401916503906\n",
      "Training step  1788  of  100000  with loss  10.326830863952637\n",
      "Training step  1789  of  100000  with loss  9.072322845458984\n",
      "Training step  1790  of  100000  with loss  9.9789400100708\n",
      "Training step  1791  of  100000  with loss  10.040939331054688\n",
      "Training step  1792  of  100000  with loss  9.218912124633789\n",
      "Training step  1793  of  100000  with loss  10.27772331237793\n",
      "Training step  1794  of  100000  with loss  9.27160358428955\n",
      "Training step  1795  of  100000  with loss  10.318120956420898\n",
      "Training step  1796  of  100000  with loss  10.426105499267578\n",
      "Training step  1797  of  100000  with loss  10.098819732666016\n",
      "Training step  1798  of  100000  with loss  9.552788734436035\n",
      "Training step  1799  of  100000  with loss  10.789411544799805\n",
      "Training step  1800  of  100000  with loss  9.524385452270508\n",
      "Training step  1801  of  100000  with loss  10.331871032714844\n",
      "Training step  1802  of  100000  with loss  11.48570442199707\n",
      "Training step  1803  of  100000  with loss  9.380277633666992\n",
      "Training step  1804  of  100000  with loss  10.271295547485352\n",
      "Training step  1805  of  100000  with loss  9.954742431640625\n",
      "Training step  1806  of  100000  with loss  11.562516212463379\n",
      "Training step  1807  of  100000  with loss  10.714484214782715\n",
      "Training step  1808  of  100000  with loss  9.740204811096191\n",
      "Training step  1809  of  100000  with loss  10.963408470153809\n",
      "Training step  1810  of  100000  with loss  10.65516471862793\n",
      "Training step  1811  of  100000  with loss  10.121784210205078\n",
      "Training step  1812  of  100000  with loss  10.921785354614258\n",
      "Training step  1813  of  100000  with loss  9.453238487243652\n",
      "Training step  1814  of  100000  with loss  9.331809997558594\n",
      "Training step  1815  of  100000  with loss  10.38846206665039\n",
      "Training step  1816  of  100000  with loss  9.366920471191406\n",
      "Training step  1817  of  100000  with loss  8.667318344116211\n",
      "Training step  1818  of  100000  with loss  10.442573547363281\n",
      "Training step  1819  of  100000  with loss  9.706345558166504\n",
      "Training step  1820  of  100000  with loss  8.418506622314453\n",
      "Training step  1821  of  100000  with loss  11.584002494812012\n",
      "Training step  1822  of  100000  with loss  10.489419937133789\n",
      "Training step  1823  of  100000  with loss  8.742030143737793\n",
      "Training step  1824  of  100000  with loss  9.261417388916016\n",
      "Training step  1825  of  100000  with loss  10.91724967956543\n",
      "Training step  1826  of  100000  with loss  8.790454864501953\n",
      "Training step  1827  of  100000  with loss  8.473743438720703\n",
      "Training step  1828  of  100000  with loss  9.812393188476562\n",
      "Training step  1829  of  100000  with loss  10.538274765014648\n",
      "Training step  1830  of  100000  with loss  9.479524612426758\n",
      "Training step  1831  of  100000  with loss  10.817079544067383\n",
      "Training step  1832  of  100000  with loss  9.710220336914062\n",
      "Training step  1833  of  100000  with loss  9.388422012329102\n",
      "Training step  1834  of  100000  with loss  9.186416625976562\n",
      "Training step  1835  of  100000  with loss  9.38794994354248\n",
      "Training step  1836  of  100000  with loss  10.760660171508789\n",
      "Training step  1837  of  100000  with loss  9.070749282836914\n",
      "Training step  1838  of  100000  with loss  11.638949394226074\n",
      "Training step  1839  of  100000  with loss  9.495782852172852\n",
      "Training step  1840  of  100000  with loss  9.133058547973633\n",
      "Training step  1841  of  100000  with loss  8.939831733703613\n",
      "Training step  1842  of  100000  with loss  9.468912124633789\n",
      "Training step  1843  of  100000  with loss  10.079875946044922\n",
      "Training step  1844  of  100000  with loss  10.585954666137695\n",
      "Training step  1845  of  100000  with loss  10.551502227783203\n",
      "Training step  1846  of  100000  with loss  9.492429733276367\n",
      "Training step  1847  of  100000  with loss  10.478445053100586\n",
      "Training step  1848  of  100000  with loss  9.924083709716797\n",
      "Training step  1849  of  100000  with loss  9.522703170776367\n",
      "Training step  1850  of  100000  with loss  10.377771377563477\n",
      "Training step  1851  of  100000  with loss  11.557747840881348\n",
      "Training step  1852  of  100000  with loss  9.45490550994873\n",
      "Training step  1853  of  100000  with loss  9.964664459228516\n",
      "Training step  1854  of  100000  with loss  12.723575592041016\n",
      "Training step  1855  of  100000  with loss  9.789820671081543\n",
      "Training step  1856  of  100000  with loss  10.984540939331055\n",
      "Training step  1857  of  100000  with loss  10.463167190551758\n",
      "Training step  1858  of  100000  with loss  8.656850814819336\n",
      "Training step  1859  of  100000  with loss  9.934744834899902\n",
      "Training step  1860  of  100000  with loss  9.863422393798828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1861  of  100000  with loss  9.828180313110352\n",
      "Training step  1862  of  100000  with loss  11.992514610290527\n",
      "Training step  1863  of  100000  with loss  9.422506332397461\n",
      "Training step  1864  of  100000  with loss  10.990720748901367\n",
      "Training step  1865  of  100000  with loss  11.474275588989258\n",
      "Training step  1866  of  100000  with loss  11.343774795532227\n",
      "Training step  1867  of  100000  with loss  10.938549041748047\n",
      "Training step  1868  of  100000  with loss  8.67776870727539\n",
      "Training step  1869  of  100000  with loss  9.037781715393066\n",
      "Training step  1870  of  100000  with loss  10.963388442993164\n",
      "Training step  1871  of  100000  with loss  9.85810375213623\n",
      "Training step  1872  of  100000  with loss  9.802003860473633\n",
      "Training step  1873  of  100000  with loss  9.089869499206543\n",
      "Training step  1874  of  100000  with loss  10.180785179138184\n",
      "Training step  1875  of  100000  with loss  10.810888290405273\n",
      "Training step  1876  of  100000  with loss  9.962428092956543\n",
      "Training step  1877  of  100000  with loss  10.25674819946289\n",
      "Training step  1878  of  100000  with loss  9.436759948730469\n",
      "Training step  1879  of  100000  with loss  9.326024055480957\n",
      "Training step  1880  of  100000  with loss  10.050910949707031\n",
      "Training step  1881  of  100000  with loss  9.611160278320312\n",
      "Training step  1882  of  100000  with loss  10.312435150146484\n",
      "Training step  1883  of  100000  with loss  10.029711723327637\n",
      "Training step  1884  of  100000  with loss  9.827974319458008\n",
      "Training step  1885  of  100000  with loss  10.247652053833008\n",
      "Training step  1886  of  100000  with loss  10.410696983337402\n",
      "Training step  1887  of  100000  with loss  9.275932312011719\n",
      "Training step  1888  of  100000  with loss  9.830833435058594\n",
      "Training step  1889  of  100000  with loss  9.636222839355469\n",
      "Training step  1890  of  100000  with loss  9.650142669677734\n",
      "Training step  1891  of  100000  with loss  10.445045471191406\n",
      "Training step  1892  of  100000  with loss  9.692745208740234\n",
      "Training step  1893  of  100000  with loss  10.551116943359375\n",
      "Training step  1894  of  100000  with loss  10.192814826965332\n",
      "Training step  1895  of  100000  with loss  11.834236145019531\n",
      "Training step  1896  of  100000  with loss  9.33834457397461\n",
      "Training step  1897  of  100000  with loss  9.509232521057129\n",
      "Training step  1898  of  100000  with loss  9.675052642822266\n",
      "Training step  1899  of  100000  with loss  9.421314239501953\n",
      "Training step  1900  of  100000  with loss  9.771123886108398\n",
      "Training step  1901  of  100000  with loss  9.671411514282227\n",
      "Training step  1902  of  100000  with loss  11.02933120727539\n",
      "Training step  1903  of  100000  with loss  10.133454322814941\n",
      "Training step  1904  of  100000  with loss  11.253397941589355\n",
      "Training step  1905  of  100000  with loss  9.348817825317383\n",
      "Training step  1906  of  100000  with loss  10.285625457763672\n",
      "Training step  1907  of  100000  with loss  9.51333236694336\n",
      "Training step  1908  of  100000  with loss  10.866243362426758\n",
      "Training step  1909  of  100000  with loss  9.728129386901855\n",
      "Training step  1910  of  100000  with loss  9.285598754882812\n",
      "Training step  1911  of  100000  with loss  9.872798919677734\n",
      "Training step  1912  of  100000  with loss  10.15516185760498\n",
      "Training step  1913  of  100000  with loss  9.881610870361328\n",
      "Training step  1914  of  100000  with loss  11.615177154541016\n",
      "Training step  1915  of  100000  with loss  10.172789573669434\n",
      "Training step  1916  of  100000  with loss  10.16504955291748\n",
      "Training step  1917  of  100000  with loss  11.565496444702148\n",
      "Training step  1918  of  100000  with loss  10.080001831054688\n",
      "Training step  1919  of  100000  with loss  10.618670463562012\n",
      "Training step  1920  of  100000  with loss  10.326620101928711\n",
      "Training step  1921  of  100000  with loss  9.336938858032227\n",
      "Training step  1922  of  100000  with loss  10.586528778076172\n",
      "Training step  1923  of  100000  with loss  10.744998931884766\n",
      "Training step  1924  of  100000  with loss  9.271234512329102\n",
      "Training step  1925  of  100000  with loss  9.657405853271484\n",
      "Training step  1926  of  100000  with loss  10.788061141967773\n",
      "Training step  1927  of  100000  with loss  9.870744705200195\n",
      "Training step  1928  of  100000  with loss  10.170382499694824\n",
      "Training step  1929  of  100000  with loss  9.710749626159668\n",
      "Training step  1930  of  100000  with loss  10.150790214538574\n",
      "Training step  1931  of  100000  with loss  10.414997100830078\n",
      "Training step  1932  of  100000  with loss  8.683096885681152\n",
      "Training step  1933  of  100000  with loss  9.212019920349121\n",
      "Training step  1934  of  100000  with loss  11.493645668029785\n",
      "Training step  1935  of  100000  with loss  9.214255332946777\n",
      "Training step  1936  of  100000  with loss  10.67263412475586\n",
      "Training step  1937  of  100000  with loss  10.429977416992188\n",
      "Training step  1938  of  100000  with loss  10.78260612487793\n",
      "Training step  1939  of  100000  with loss  9.97500228881836\n",
      "Training step  1940  of  100000  with loss  10.879570960998535\n",
      "Training step  1941  of  100000  with loss  9.561692237854004\n",
      "Training step  1942  of  100000  with loss  10.997041702270508\n",
      "Training step  1943  of  100000  with loss  9.79233455657959\n",
      "Training step  1944  of  100000  with loss  11.265884399414062\n",
      "Training step  1945  of  100000  with loss  9.56450080871582\n",
      "Training step  1946  of  100000  with loss  9.678421020507812\n",
      "Training step  1947  of  100000  with loss  8.733135223388672\n",
      "Training step  1948  of  100000  with loss  9.407074928283691\n",
      "Training step  1949  of  100000  with loss  10.614479064941406\n",
      "Training step  1950  of  100000  with loss  9.457709312438965\n",
      "Training step  1951  of  100000  with loss  9.78265380859375\n",
      "Training step  1952  of  100000  with loss  9.601625442504883\n",
      "Training step  1953  of  100000  with loss  9.824325561523438\n",
      "Training step  1954  of  100000  with loss  10.314491271972656\n",
      "Training step  1955  of  100000  with loss  10.104972839355469\n",
      "Training step  1956  of  100000  with loss  10.412649154663086\n",
      "Training step  1957  of  100000  with loss  8.246992111206055\n",
      "Training step  1958  of  100000  with loss  9.301374435424805\n",
      "Training step  1959  of  100000  with loss  11.294378280639648\n",
      "Training step  1960  of  100000  with loss  9.920723915100098\n",
      "Training step  1961  of  100000  with loss  10.0472412109375\n",
      "Training step  1962  of  100000  with loss  9.008858680725098\n",
      "Training step  1963  of  100000  with loss  10.641022682189941\n",
      "Training step  1964  of  100000  with loss  8.84127140045166\n",
      "Training step  1965  of  100000  with loss  8.53222370147705\n",
      "Training step  1966  of  100000  with loss  9.404342651367188\n",
      "Training step  1967  of  100000  with loss  9.74903678894043\n",
      "Training step  1968  of  100000  with loss  10.491528511047363\n",
      "Training step  1969  of  100000  with loss  9.226656913757324\n",
      "Training step  1970  of  100000  with loss  10.104762077331543\n",
      "Training step  1971  of  100000  with loss  9.796926498413086\n",
      "Training step  1972  of  100000  with loss  12.034832000732422\n",
      "Training step  1973  of  100000  with loss  9.845998764038086\n",
      "Training step  1974  of  100000  with loss  10.028234481811523\n",
      "Training step  1975  of  100000  with loss  9.98817253112793\n",
      "Training step  1976  of  100000  with loss  10.380510330200195\n",
      "Training step  1977  of  100000  with loss  10.59257698059082\n",
      "Training step  1978  of  100000  with loss  9.052156448364258\n",
      "Training step  1979  of  100000  with loss  10.104259490966797\n",
      "Training step  1980  of  100000  with loss  9.496016502380371\n",
      "Training step  1981  of  100000  with loss  8.970267295837402\n",
      "Training step  1982  of  100000  with loss  10.01065731048584\n",
      "Training step  1983  of  100000  with loss  9.267730712890625\n",
      "Training step  1984  of  100000  with loss  9.812034606933594\n",
      "Training step  1985  of  100000  with loss  9.290691375732422\n",
      "Training step  1986  of  100000  with loss  10.337509155273438\n",
      "Training step  1987  of  100000  with loss  9.722551345825195\n",
      "Training step  1988  of  100000  with loss  10.655084609985352\n",
      "Training step  1989  of  100000  with loss  9.313600540161133\n",
      "Training step  1990  of  100000  with loss  9.897893905639648\n",
      "Training step  1991  of  100000  with loss  8.92214584350586\n",
      "Training step  1992  of  100000  with loss  9.907295227050781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  1993  of  100000  with loss  9.134332656860352\n",
      "Training step  1994  of  100000  with loss  10.180421829223633\n",
      "Training step  1995  of  100000  with loss  10.994050025939941\n",
      "Training step  1996  of  100000  with loss  10.685760498046875\n",
      "Training step  1997  of  100000  with loss  10.809305191040039\n",
      "Training step  1998  of  100000  with loss  9.189127922058105\n",
      "Training step  1999  of  100000  with loss  8.878080368041992\n",
      "Training step  2000  of  100000  with loss  10.258079528808594\n",
      "Training step  2001  of  100000  with loss  9.49839973449707\n",
      "Training step  2002  of  100000  with loss  12.005971908569336\n",
      "Training step  2003  of  100000  with loss  11.42575454711914\n",
      "Training step  2004  of  100000  with loss  9.150556564331055\n",
      "Training step  2005  of  100000  with loss  9.940969467163086\n",
      "Training step  2006  of  100000  with loss  9.17266845703125\n",
      "Training step  2007  of  100000  with loss  9.66523551940918\n",
      "Training step  2008  of  100000  with loss  9.949214935302734\n",
      "Training step  2009  of  100000  with loss  11.807591438293457\n",
      "Training step  2010  of  100000  with loss  9.621589660644531\n",
      "Training step  2011  of  100000  with loss  9.999671936035156\n",
      "Training step  2012  of  100000  with loss  11.077581405639648\n",
      "Training step  2013  of  100000  with loss  9.411581039428711\n",
      "Training step  2014  of  100000  with loss  10.201154708862305\n",
      "Training step  2015  of  100000  with loss  9.635324478149414\n",
      "Training step  2016  of  100000  with loss  9.834548950195312\n",
      "Training step  2017  of  100000  with loss  10.168274879455566\n",
      "Training step  2018  of  100000  with loss  9.34408187866211\n",
      "Training step  2019  of  100000  with loss  10.637249946594238\n",
      "Training step  2020  of  100000  with loss  9.925671577453613\n",
      "Training step  2021  of  100000  with loss  10.245309829711914\n",
      "Training step  2022  of  100000  with loss  9.184307098388672\n",
      "Training step  2023  of  100000  with loss  9.342367172241211\n",
      "Training step  2024  of  100000  with loss  9.933602333068848\n",
      "Training step  2025  of  100000  with loss  11.127830505371094\n",
      "Training step  2026  of  100000  with loss  10.954008102416992\n",
      "Training step  2027  of  100000  with loss  10.971552848815918\n",
      "Training step  2028  of  100000  with loss  10.096080780029297\n",
      "Training step  2029  of  100000  with loss  9.533720016479492\n",
      "Training step  2030  of  100000  with loss  9.357975959777832\n",
      "Training step  2031  of  100000  with loss  10.937801361083984\n",
      "Training step  2032  of  100000  with loss  9.705303192138672\n",
      "Training step  2033  of  100000  with loss  11.154422760009766\n",
      "Training step  2034  of  100000  with loss  9.585229873657227\n",
      "Training step  2035  of  100000  with loss  9.913108825683594\n",
      "Training step  2036  of  100000  with loss  11.02263069152832\n",
      "Training step  2037  of  100000  with loss  10.507100105285645\n",
      "Training step  2038  of  100000  with loss  9.943107604980469\n",
      "Training step  2039  of  100000  with loss  10.580816268920898\n",
      "Training step  2040  of  100000  with loss  9.412644386291504\n",
      "Training step  2041  of  100000  with loss  9.423100471496582\n",
      "Training step  2042  of  100000  with loss  9.843363761901855\n",
      "Training step  2043  of  100000  with loss  11.194172859191895\n",
      "Training step  2044  of  100000  with loss  9.965571403503418\n",
      "Training step  2045  of  100000  with loss  11.173105239868164\n",
      "Training step  2046  of  100000  with loss  9.28466796875\n",
      "Training step  2047  of  100000  with loss  9.47067928314209\n",
      "Training step  2048  of  100000  with loss  8.646828651428223\n",
      "Training step  2049  of  100000  with loss  11.167917251586914\n",
      "Training step  2050  of  100000  with loss  9.513655662536621\n",
      "Training step  2051  of  100000  with loss  11.532770156860352\n",
      "Training step  2052  of  100000  with loss  10.272659301757812\n",
      "Training step  2053  of  100000  with loss  9.596494674682617\n",
      "Training step  2054  of  100000  with loss  10.005267143249512\n",
      "Training step  2055  of  100000  with loss  9.737190246582031\n",
      "Training step  2056  of  100000  with loss  9.613997459411621\n",
      "Training step  2057  of  100000  with loss  9.59561538696289\n",
      "Training step  2058  of  100000  with loss  9.565214157104492\n",
      "Training step  2059  of  100000  with loss  9.975313186645508\n",
      "Training step  2060  of  100000  with loss  11.200592041015625\n",
      "Training step  2061  of  100000  with loss  10.27252197265625\n",
      "Training step  2062  of  100000  with loss  9.46013069152832\n",
      "Training step  2063  of  100000  with loss  9.954278945922852\n",
      "Training step  2064  of  100000  with loss  9.868085861206055\n",
      "Training step  2065  of  100000  with loss  9.96377944946289\n",
      "Training step  2066  of  100000  with loss  8.701776504516602\n",
      "Training step  2067  of  100000  with loss  9.594435691833496\n",
      "Training step  2068  of  100000  with loss  9.914608001708984\n",
      "Training step  2069  of  100000  with loss  10.447844505310059\n",
      "Training step  2070  of  100000  with loss  10.659873962402344\n",
      "Training step  2071  of  100000  with loss  10.009615898132324\n",
      "Training step  2072  of  100000  with loss  9.872753143310547\n",
      "Training step  2073  of  100000  with loss  10.464810371398926\n",
      "Training step  2074  of  100000  with loss  9.442394256591797\n",
      "Training step  2075  of  100000  with loss  9.901163101196289\n",
      "Training step  2076  of  100000  with loss  9.817594528198242\n",
      "Training step  2077  of  100000  with loss  9.562514305114746\n",
      "Training step  2078  of  100000  with loss  9.59869384765625\n",
      "Training step  2079  of  100000  with loss  10.753063201904297\n",
      "Training step  2080  of  100000  with loss  9.974759101867676\n",
      "Training step  2081  of  100000  with loss  8.521411895751953\n",
      "Training step  2082  of  100000  with loss  9.463449478149414\n",
      "Training step  2083  of  100000  with loss  12.11594009399414\n",
      "Training step  2084  of  100000  with loss  11.685997009277344\n",
      "Training step  2085  of  100000  with loss  9.281219482421875\n",
      "Training step  2086  of  100000  with loss  10.039130210876465\n",
      "Training step  2087  of  100000  with loss  8.68399715423584\n",
      "Training step  2088  of  100000  with loss  10.060286521911621\n",
      "Training step  2089  of  100000  with loss  9.523458480834961\n",
      "Training step  2090  of  100000  with loss  9.568689346313477\n",
      "Training step  2091  of  100000  with loss  10.027387619018555\n",
      "Training step  2092  of  100000  with loss  10.12158203125\n",
      "Training step  2093  of  100000  with loss  11.499072074890137\n",
      "Training step  2094  of  100000  with loss  10.752826690673828\n",
      "Training step  2095  of  100000  with loss  9.53145980834961\n",
      "Training step  2096  of  100000  with loss  9.487568855285645\n",
      "Training step  2097  of  100000  with loss  9.632549285888672\n",
      "Training step  2098  of  100000  with loss  9.815448760986328\n",
      "Training step  2099  of  100000  with loss  10.15689754486084\n",
      "Training step  2100  of  100000  with loss  9.781021118164062\n",
      "Training step  2101  of  100000  with loss  10.886052131652832\n",
      "Training step  2102  of  100000  with loss  9.879804611206055\n",
      "Training step  2103  of  100000  with loss  9.321868896484375\n",
      "Training step  2104  of  100000  with loss  11.365032196044922\n",
      "Training step  2105  of  100000  with loss  11.025567054748535\n",
      "Training step  2106  of  100000  with loss  10.05416488647461\n",
      "Training step  2107  of  100000  with loss  10.357803344726562\n",
      "Training step  2108  of  100000  with loss  11.346287727355957\n",
      "Training step  2109  of  100000  with loss  11.276066780090332\n",
      "Training step  2110  of  100000  with loss  8.898252487182617\n",
      "Training step  2111  of  100000  with loss  10.650555610656738\n",
      "Training step  2112  of  100000  with loss  10.67696762084961\n",
      "Training step  2113  of  100000  with loss  11.176227569580078\n",
      "Training step  2114  of  100000  with loss  9.668856620788574\n",
      "Training step  2115  of  100000  with loss  10.24736499786377\n",
      "Training step  2116  of  100000  with loss  9.996637344360352\n",
      "Training step  2117  of  100000  with loss  9.748395919799805\n",
      "Training step  2118  of  100000  with loss  10.728617668151855\n",
      "Training step  2119  of  100000  with loss  10.172455787658691\n",
      "Training step  2120  of  100000  with loss  10.384405136108398\n",
      "Training step  2121  of  100000  with loss  9.823026657104492\n",
      "Training step  2122  of  100000  with loss  10.515205383300781\n",
      "Training step  2123  of  100000  with loss  9.60214900970459\n",
      "Training step  2124  of  100000  with loss  8.096015930175781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2125  of  100000  with loss  10.462780952453613\n",
      "Training step  2126  of  100000  with loss  10.192129135131836\n",
      "Training step  2127  of  100000  with loss  10.148613929748535\n",
      "Training step  2128  of  100000  with loss  9.548295974731445\n",
      "Training step  2129  of  100000  with loss  9.57331371307373\n",
      "Training step  2130  of  100000  with loss  10.686178207397461\n",
      "Training step  2131  of  100000  with loss  9.517662048339844\n",
      "Training step  2132  of  100000  with loss  10.805882453918457\n",
      "Training step  2133  of  100000  with loss  8.604825019836426\n",
      "Training step  2134  of  100000  with loss  10.20588493347168\n",
      "Training step  2135  of  100000  with loss  10.592533111572266\n",
      "Training step  2136  of  100000  with loss  9.828925132751465\n",
      "Training step  2137  of  100000  with loss  9.117841720581055\n",
      "Training step  2138  of  100000  with loss  10.108902931213379\n",
      "Training step  2139  of  100000  with loss  10.172651290893555\n",
      "Training step  2140  of  100000  with loss  11.611135482788086\n",
      "Training step  2141  of  100000  with loss  10.223306655883789\n",
      "Training step  2142  of  100000  with loss  9.417003631591797\n",
      "Training step  2143  of  100000  with loss  10.824777603149414\n",
      "Training step  2144  of  100000  with loss  12.107405662536621\n",
      "Training step  2145  of  100000  with loss  8.225183486938477\n",
      "Training step  2146  of  100000  with loss  8.784793853759766\n",
      "Training step  2147  of  100000  with loss  9.799735069274902\n",
      "Training step  2148  of  100000  with loss  10.18724536895752\n",
      "Training step  2149  of  100000  with loss  9.592242240905762\n",
      "Training step  2150  of  100000  with loss  9.147825241088867\n",
      "Training step  2151  of  100000  with loss  9.956823348999023\n",
      "Training step  2152  of  100000  with loss  10.29544734954834\n",
      "Training step  2153  of  100000  with loss  9.017427444458008\n",
      "Training step  2154  of  100000  with loss  11.397472381591797\n",
      "Training step  2155  of  100000  with loss  10.008707046508789\n",
      "Training step  2156  of  100000  with loss  9.982759475708008\n",
      "Training step  2157  of  100000  with loss  10.100618362426758\n",
      "Training step  2158  of  100000  with loss  10.697761535644531\n",
      "Training step  2159  of  100000  with loss  10.539190292358398\n",
      "Training step  2160  of  100000  with loss  9.209307670593262\n",
      "Training step  2161  of  100000  with loss  10.104883193969727\n",
      "Training step  2162  of  100000  with loss  8.16844367980957\n",
      "Training step  2163  of  100000  with loss  11.505764961242676\n",
      "Training step  2164  of  100000  with loss  9.289085388183594\n",
      "Training step  2165  of  100000  with loss  10.127222061157227\n",
      "Training step  2166  of  100000  with loss  8.788334846496582\n",
      "Training step  2167  of  100000  with loss  9.482949256896973\n",
      "Training step  2168  of  100000  with loss  9.997444152832031\n",
      "Training step  2169  of  100000  with loss  9.921218872070312\n",
      "Training step  2170  of  100000  with loss  10.049588203430176\n",
      "Training step  2171  of  100000  with loss  9.532526016235352\n",
      "Training step  2172  of  100000  with loss  9.056989669799805\n",
      "Training step  2173  of  100000  with loss  10.0590238571167\n",
      "Training step  2174  of  100000  with loss  9.531396865844727\n",
      "Training step  2175  of  100000  with loss  9.88812255859375\n",
      "Training step  2176  of  100000  with loss  10.674107551574707\n",
      "Training step  2177  of  100000  with loss  9.851930618286133\n",
      "Training step  2178  of  100000  with loss  10.63694953918457\n",
      "Training step  2179  of  100000  with loss  9.713558197021484\n",
      "Training step  2180  of  100000  with loss  10.18644905090332\n",
      "Training step  2181  of  100000  with loss  10.829533576965332\n",
      "Training step  2182  of  100000  with loss  10.839197158813477\n",
      "Training step  2183  of  100000  with loss  9.899860382080078\n",
      "Training step  2184  of  100000  with loss  9.913555145263672\n",
      "Training step  2185  of  100000  with loss  9.990243911743164\n",
      "Training step  2186  of  100000  with loss  9.698812484741211\n",
      "Training step  2187  of  100000  with loss  10.462444305419922\n",
      "Training step  2188  of  100000  with loss  8.929805755615234\n",
      "Training step  2189  of  100000  with loss  10.087443351745605\n",
      "Training step  2190  of  100000  with loss  9.923296928405762\n",
      "Training step  2191  of  100000  with loss  10.08683967590332\n",
      "Training step  2192  of  100000  with loss  9.70456600189209\n",
      "Training step  2193  of  100000  with loss  10.741876602172852\n",
      "Training step  2194  of  100000  with loss  10.118864059448242\n",
      "Training step  2195  of  100000  with loss  9.110769271850586\n",
      "Training step  2196  of  100000  with loss  9.54548454284668\n",
      "Training step  2197  of  100000  with loss  10.77066421508789\n",
      "Training step  2198  of  100000  with loss  9.72570514678955\n",
      "Training step  2199  of  100000  with loss  10.698283195495605\n",
      "Training step  2200  of  100000  with loss  9.790793418884277\n",
      "Training step  2201  of  100000  with loss  9.936013221740723\n",
      "Training step  2202  of  100000  with loss  10.293402671813965\n",
      "Training step  2203  of  100000  with loss  9.689741134643555\n",
      "Training step  2204  of  100000  with loss  11.475080490112305\n",
      "Training step  2205  of  100000  with loss  13.199258804321289\n",
      "Training step  2206  of  100000  with loss  11.091980934143066\n",
      "Training step  2207  of  100000  with loss  10.569778442382812\n",
      "Training step  2208  of  100000  with loss  10.580694198608398\n",
      "Training step  2209  of  100000  with loss  10.467334747314453\n",
      "Training step  2210  of  100000  with loss  11.626336097717285\n",
      "Training step  2211  of  100000  with loss  9.83176040649414\n",
      "Training step  2212  of  100000  with loss  9.053308486938477\n",
      "Training step  2213  of  100000  with loss  9.020889282226562\n",
      "Training step  2214  of  100000  with loss  11.543412208557129\n",
      "Training step  2215  of  100000  with loss  9.243701934814453\n",
      "Training step  2216  of  100000  with loss  10.905914306640625\n",
      "Training step  2217  of  100000  with loss  9.620423316955566\n",
      "Training step  2218  of  100000  with loss  11.828697204589844\n",
      "Training step  2219  of  100000  with loss  10.893027305603027\n",
      "Training step  2220  of  100000  with loss  9.880827903747559\n",
      "Training step  2221  of  100000  with loss  9.25210952758789\n",
      "Training step  2222  of  100000  with loss  9.790626525878906\n",
      "Training step  2223  of  100000  with loss  10.0926513671875\n",
      "Training step  2224  of  100000  with loss  9.384841918945312\n",
      "Training step  2225  of  100000  with loss  10.304956436157227\n",
      "Training step  2226  of  100000  with loss  9.336860656738281\n",
      "Training step  2227  of  100000  with loss  10.02819538116455\n",
      "Training step  2228  of  100000  with loss  9.824888229370117\n",
      "Training step  2229  of  100000  with loss  8.80746841430664\n",
      "Training step  2230  of  100000  with loss  9.45722770690918\n",
      "Training step  2231  of  100000  with loss  10.6044921875\n",
      "Training step  2232  of  100000  with loss  10.060937881469727\n",
      "Training step  2233  of  100000  with loss  8.812355041503906\n",
      "Training step  2234  of  100000  with loss  10.776825904846191\n",
      "Training step  2235  of  100000  with loss  9.202469825744629\n",
      "Training step  2236  of  100000  with loss  10.461616516113281\n",
      "Training step  2237  of  100000  with loss  9.416589736938477\n",
      "Training step  2238  of  100000  with loss  10.131616592407227\n",
      "Training step  2239  of  100000  with loss  9.931150436401367\n",
      "Training step  2240  of  100000  with loss  10.756115913391113\n",
      "Training step  2241  of  100000  with loss  9.929616928100586\n",
      "Training step  2242  of  100000  with loss  9.367387771606445\n",
      "Training step  2243  of  100000  with loss  9.076326370239258\n",
      "Training step  2244  of  100000  with loss  10.029102325439453\n",
      "Training step  2245  of  100000  with loss  9.509954452514648\n",
      "Training step  2246  of  100000  with loss  9.584891319274902\n",
      "Training step  2247  of  100000  with loss  9.664226531982422\n",
      "Training step  2248  of  100000  with loss  12.357873916625977\n",
      "Training step  2249  of  100000  with loss  9.440668106079102\n",
      "Training step  2250  of  100000  with loss  11.676616668701172\n",
      "Training step  2251  of  100000  with loss  9.318428039550781\n",
      "Training step  2252  of  100000  with loss  11.002665519714355\n",
      "Training step  2253  of  100000  with loss  9.781010627746582\n",
      "Training step  2254  of  100000  with loss  9.469001770019531\n",
      "Training step  2255  of  100000  with loss  9.707122802734375\n",
      "Training step  2256  of  100000  with loss  11.154662132263184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2257  of  100000  with loss  9.363273620605469\n",
      "Training step  2258  of  100000  with loss  10.654796600341797\n",
      "Training step  2259  of  100000  with loss  11.427907943725586\n",
      "Training step  2260  of  100000  with loss  8.420756340026855\n",
      "Training step  2261  of  100000  with loss  10.899827003479004\n",
      "Training step  2262  of  100000  with loss  9.023780822753906\n",
      "Training step  2263  of  100000  with loss  9.290668487548828\n",
      "Training step  2264  of  100000  with loss  9.601836204528809\n",
      "Training step  2265  of  100000  with loss  10.301136016845703\n",
      "Training step  2266  of  100000  with loss  10.570608139038086\n",
      "Training step  2267  of  100000  with loss  9.92878532409668\n",
      "Training step  2268  of  100000  with loss  9.898361206054688\n",
      "Training step  2269  of  100000  with loss  9.925590515136719\n",
      "Training step  2270  of  100000  with loss  11.396530151367188\n",
      "Training step  2271  of  100000  with loss  11.396578788757324\n",
      "Training step  2272  of  100000  with loss  9.475818634033203\n",
      "Training step  2273  of  100000  with loss  12.60859203338623\n",
      "Training step  2274  of  100000  with loss  10.52311897277832\n",
      "Training step  2275  of  100000  with loss  11.093709945678711\n",
      "Training step  2276  of  100000  with loss  9.255716323852539\n",
      "Training step  2277  of  100000  with loss  9.75167465209961\n",
      "Training step  2278  of  100000  with loss  11.111397743225098\n",
      "Training step  2279  of  100000  with loss  9.523749351501465\n",
      "Training step  2280  of  100000  with loss  9.846907615661621\n",
      "Training step  2281  of  100000  with loss  9.14741325378418\n",
      "Training step  2282  of  100000  with loss  10.057851791381836\n",
      "Training step  2283  of  100000  with loss  10.169703483581543\n",
      "Training step  2284  of  100000  with loss  10.181242942810059\n",
      "Training step  2285  of  100000  with loss  11.129941940307617\n",
      "Training step  2286  of  100000  with loss  11.739997863769531\n",
      "Training step  2287  of  100000  with loss  10.607465744018555\n",
      "Training step  2288  of  100000  with loss  9.919909477233887\n",
      "Training step  2289  of  100000  with loss  10.19045639038086\n",
      "Training step  2290  of  100000  with loss  9.286544799804688\n",
      "Training step  2291  of  100000  with loss  9.938791275024414\n",
      "Training step  2292  of  100000  with loss  10.66169261932373\n",
      "Training step  2293  of  100000  with loss  10.32429313659668\n",
      "Training step  2294  of  100000  with loss  10.874417304992676\n",
      "Training step  2295  of  100000  with loss  11.271976470947266\n",
      "Training step  2296  of  100000  with loss  10.198476791381836\n",
      "Training step  2297  of  100000  with loss  9.859307289123535\n",
      "Training step  2298  of  100000  with loss  10.745458602905273\n",
      "Training step  2299  of  100000  with loss  9.910942077636719\n",
      "Training step  2300  of  100000  with loss  9.961365699768066\n",
      "Training step  2301  of  100000  with loss  9.712092399597168\n",
      "Training step  2302  of  100000  with loss  9.816527366638184\n",
      "Training step  2303  of  100000  with loss  9.752126693725586\n",
      "Training step  2304  of  100000  with loss  9.898927688598633\n",
      "Training step  2305  of  100000  with loss  8.734245300292969\n",
      "Training step  2306  of  100000  with loss  9.927730560302734\n",
      "Training step  2307  of  100000  with loss  9.826038360595703\n",
      "Training step  2308  of  100000  with loss  9.485681533813477\n",
      "Training step  2309  of  100000  with loss  9.069210052490234\n",
      "Training step  2310  of  100000  with loss  9.692756652832031\n",
      "Training step  2311  of  100000  with loss  10.589685440063477\n",
      "Training step  2312  of  100000  with loss  9.428038597106934\n",
      "Training step  2313  of  100000  with loss  9.90264892578125\n",
      "Training step  2314  of  100000  with loss  10.089208602905273\n",
      "Training step  2315  of  100000  with loss  10.024272918701172\n",
      "Training step  2316  of  100000  with loss  9.863418579101562\n",
      "Training step  2317  of  100000  with loss  9.500749588012695\n",
      "Training step  2318  of  100000  with loss  10.376192092895508\n",
      "Training step  2319  of  100000  with loss  9.811532020568848\n",
      "Training step  2320  of  100000  with loss  9.652426719665527\n",
      "Training step  2321  of  100000  with loss  9.240740776062012\n",
      "Training step  2322  of  100000  with loss  9.77076530456543\n",
      "Training step  2323  of  100000  with loss  9.504819869995117\n",
      "Training step  2324  of  100000  with loss  9.369653701782227\n",
      "Training step  2325  of  100000  with loss  10.168356895446777\n",
      "Training step  2326  of  100000  with loss  10.830836296081543\n",
      "Training step  2327  of  100000  with loss  8.889339447021484\n",
      "Training step  2328  of  100000  with loss  10.411184310913086\n",
      "Training step  2329  of  100000  with loss  9.707101821899414\n",
      "Training step  2330  of  100000  with loss  10.049006462097168\n",
      "Training step  2331  of  100000  with loss  11.302152633666992\n",
      "Training step  2332  of  100000  with loss  8.905803680419922\n",
      "Training step  2333  of  100000  with loss  9.41508674621582\n",
      "Training step  2334  of  100000  with loss  10.966989517211914\n",
      "Training step  2335  of  100000  with loss  10.707810401916504\n",
      "Training step  2336  of  100000  with loss  10.838478088378906\n",
      "Training step  2337  of  100000  with loss  8.489194869995117\n",
      "Training step  2338  of  100000  with loss  9.448263168334961\n",
      "Training step  2339  of  100000  with loss  10.435730934143066\n",
      "Training step  2340  of  100000  with loss  11.447690963745117\n",
      "Training step  2341  of  100000  with loss  9.132390975952148\n",
      "Training step  2342  of  100000  with loss  8.888077735900879\n",
      "Training step  2343  of  100000  with loss  10.39869499206543\n",
      "Training step  2344  of  100000  with loss  10.028448104858398\n",
      "Training step  2345  of  100000  with loss  10.337369918823242\n",
      "Training step  2346  of  100000  with loss  9.956399917602539\n",
      "Training step  2347  of  100000  with loss  10.661317825317383\n",
      "Training step  2348  of  100000  with loss  11.169443130493164\n",
      "Training step  2349  of  100000  with loss  10.28510856628418\n",
      "Training step  2350  of  100000  with loss  10.994913101196289\n",
      "Training step  2351  of  100000  with loss  9.747024536132812\n",
      "Training step  2352  of  100000  with loss  9.601922988891602\n",
      "Training step  2353  of  100000  with loss  10.097122192382812\n",
      "Training step  2354  of  100000  with loss  8.960798263549805\n",
      "Training step  2355  of  100000  with loss  12.549775123596191\n",
      "Training step  2356  of  100000  with loss  10.254461288452148\n",
      "Training step  2357  of  100000  with loss  10.391059875488281\n",
      "Training step  2358  of  100000  with loss  11.042957305908203\n",
      "Training step  2359  of  100000  with loss  10.550403594970703\n",
      "Training step  2360  of  100000  with loss  9.611529350280762\n",
      "Training step  2361  of  100000  with loss  9.219229698181152\n",
      "Training step  2362  of  100000  with loss  10.72653865814209\n",
      "Training step  2363  of  100000  with loss  9.29539966583252\n",
      "Training step  2364  of  100000  with loss  10.531537055969238\n",
      "Training step  2365  of  100000  with loss  8.988775253295898\n",
      "Training step  2366  of  100000  with loss  10.072019577026367\n",
      "Training step  2367  of  100000  with loss  9.515673637390137\n",
      "Training step  2368  of  100000  with loss  9.750062942504883\n",
      "Training step  2369  of  100000  with loss  8.646255493164062\n",
      "Training step  2370  of  100000  with loss  9.361461639404297\n",
      "Training step  2371  of  100000  with loss  9.834541320800781\n",
      "Training step  2372  of  100000  with loss  8.970661163330078\n",
      "Training step  2373  of  100000  with loss  10.076193809509277\n",
      "Training step  2374  of  100000  with loss  10.607254028320312\n",
      "Training step  2375  of  100000  with loss  9.63691520690918\n",
      "Training step  2376  of  100000  with loss  11.443729400634766\n",
      "Training step  2377  of  100000  with loss  9.73745346069336\n",
      "Training step  2378  of  100000  with loss  10.21678352355957\n",
      "Training step  2379  of  100000  with loss  10.61014175415039\n",
      "Training step  2380  of  100000  with loss  10.100269317626953\n",
      "Training step  2381  of  100000  with loss  9.068347930908203\n",
      "Training step  2382  of  100000  with loss  9.305557250976562\n",
      "Training step  2383  of  100000  with loss  10.357851028442383\n",
      "Training step  2384  of  100000  with loss  9.477895736694336\n",
      "Training step  2385  of  100000  with loss  9.760178565979004\n",
      "Training step  2386  of  100000  with loss  10.279354095458984\n",
      "Training step  2387  of  100000  with loss  9.914438247680664\n",
      "Training step  2388  of  100000  with loss  9.514670372009277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2389  of  100000  with loss  9.278514862060547\n",
      "Training step  2390  of  100000  with loss  8.541534423828125\n",
      "Training step  2391  of  100000  with loss  12.45215892791748\n",
      "Training step  2392  of  100000  with loss  10.532448768615723\n",
      "Training step  2393  of  100000  with loss  9.96391487121582\n",
      "Training step  2394  of  100000  with loss  9.449951171875\n",
      "Training step  2395  of  100000  with loss  10.178070068359375\n",
      "Training step  2396  of  100000  with loss  10.362874984741211\n",
      "Training step  2397  of  100000  with loss  9.756099700927734\n",
      "Training step  2398  of  100000  with loss  9.350133895874023\n",
      "Training step  2399  of  100000  with loss  9.537585258483887\n",
      "Training step  2400  of  100000  with loss  8.081594467163086\n",
      "Training step  2401  of  100000  with loss  10.943229675292969\n",
      "Training step  2402  of  100000  with loss  10.525371551513672\n",
      "Training step  2403  of  100000  with loss  9.842269897460938\n",
      "Training step  2404  of  100000  with loss  9.710362434387207\n",
      "Training step  2405  of  100000  with loss  10.339903831481934\n",
      "Training step  2406  of  100000  with loss  9.122827529907227\n",
      "Training step  2407  of  100000  with loss  11.087471961975098\n",
      "Training step  2408  of  100000  with loss  10.010421752929688\n",
      "Training step  2409  of  100000  with loss  9.328093528747559\n",
      "Training step  2410  of  100000  with loss  9.228415489196777\n",
      "Training step  2411  of  100000  with loss  9.791730880737305\n",
      "Training step  2412  of  100000  with loss  9.876002311706543\n",
      "Training step  2413  of  100000  with loss  9.629219055175781\n",
      "Training step  2414  of  100000  with loss  11.187423706054688\n",
      "Training step  2415  of  100000  with loss  10.09679126739502\n",
      "Training step  2416  of  100000  with loss  11.330774307250977\n",
      "Training step  2417  of  100000  with loss  9.825428009033203\n",
      "Training step  2418  of  100000  with loss  9.242613792419434\n",
      "Training step  2419  of  100000  with loss  10.020540237426758\n",
      "Training step  2420  of  100000  with loss  11.644336700439453\n",
      "Training step  2421  of  100000  with loss  9.990968704223633\n",
      "Training step  2422  of  100000  with loss  10.692401885986328\n",
      "Training step  2423  of  100000  with loss  10.100278854370117\n",
      "Training step  2424  of  100000  with loss  10.752946853637695\n",
      "Training step  2425  of  100000  with loss  9.44538402557373\n",
      "Training step  2426  of  100000  with loss  10.274742126464844\n",
      "Training step  2427  of  100000  with loss  9.64765739440918\n",
      "Training step  2428  of  100000  with loss  10.339332580566406\n",
      "Training step  2429  of  100000  with loss  10.56385326385498\n",
      "Training step  2430  of  100000  with loss  10.928483963012695\n",
      "Training step  2431  of  100000  with loss  9.121950149536133\n",
      "Training step  2432  of  100000  with loss  9.568414688110352\n",
      "Training step  2433  of  100000  with loss  8.976015090942383\n",
      "Training step  2434  of  100000  with loss  11.644404411315918\n",
      "Training step  2435  of  100000  with loss  11.192273139953613\n",
      "Training step  2436  of  100000  with loss  10.551708221435547\n",
      "Training step  2437  of  100000  with loss  10.066567420959473\n",
      "Training step  2438  of  100000  with loss  10.308561325073242\n",
      "Training step  2439  of  100000  with loss  10.028949737548828\n",
      "Training step  2440  of  100000  with loss  11.169364929199219\n",
      "Training step  2441  of  100000  with loss  8.819226264953613\n",
      "Training step  2442  of  100000  with loss  9.70433235168457\n",
      "Training step  2443  of  100000  with loss  8.584239959716797\n",
      "Training step  2444  of  100000  with loss  9.498418807983398\n",
      "Training step  2445  of  100000  with loss  8.679401397705078\n",
      "Training step  2446  of  100000  with loss  9.131457328796387\n",
      "Training step  2447  of  100000  with loss  12.872701644897461\n",
      "Training step  2448  of  100000  with loss  10.247358322143555\n",
      "Training step  2449  of  100000  with loss  9.654601097106934\n",
      "Training step  2450  of  100000  with loss  10.207855224609375\n",
      "Training step  2451  of  100000  with loss  9.147063255310059\n",
      "Training step  2452  of  100000  with loss  9.794883728027344\n",
      "Training step  2453  of  100000  with loss  10.766847610473633\n",
      "Training step  2454  of  100000  with loss  10.112533569335938\n",
      "Training step  2455  of  100000  with loss  10.665221214294434\n",
      "Training step  2456  of  100000  with loss  8.59709358215332\n",
      "Training step  2457  of  100000  with loss  8.757152557373047\n",
      "Training step  2458  of  100000  with loss  10.251026153564453\n",
      "Training step  2459  of  100000  with loss  10.62824821472168\n",
      "Training step  2460  of  100000  with loss  10.528769493103027\n",
      "Training step  2461  of  100000  with loss  10.279545783996582\n",
      "Training step  2462  of  100000  with loss  10.371545791625977\n",
      "Training step  2463  of  100000  with loss  9.635133743286133\n",
      "Training step  2464  of  100000  with loss  11.01562786102295\n",
      "Training step  2465  of  100000  with loss  9.200601577758789\n",
      "Training step  2466  of  100000  with loss  10.638275146484375\n",
      "Training step  2467  of  100000  with loss  10.799056053161621\n",
      "Training step  2468  of  100000  with loss  11.336053848266602\n",
      "Training step  2469  of  100000  with loss  9.47083854675293\n",
      "Training step  2470  of  100000  with loss  9.401859283447266\n",
      "Training step  2471  of  100000  with loss  10.010464668273926\n",
      "Training step  2472  of  100000  with loss  9.621767044067383\n",
      "Training step  2473  of  100000  with loss  9.88449478149414\n",
      "Training step  2474  of  100000  with loss  8.915889739990234\n",
      "Training step  2475  of  100000  with loss  11.6681547164917\n",
      "Training step  2476  of  100000  with loss  8.745168685913086\n",
      "Training step  2477  of  100000  with loss  10.322922706604004\n",
      "Training step  2478  of  100000  with loss  9.570408821105957\n",
      "Training step  2479  of  100000  with loss  11.266256332397461\n",
      "Training step  2480  of  100000  with loss  10.176677703857422\n",
      "Training step  2481  of  100000  with loss  10.19734001159668\n",
      "Training step  2482  of  100000  with loss  9.304372787475586\n",
      "Training step  2483  of  100000  with loss  9.009415626525879\n",
      "Training step  2484  of  100000  with loss  8.345218658447266\n",
      "Training step  2485  of  100000  with loss  9.811634063720703\n",
      "Training step  2486  of  100000  with loss  9.659253120422363\n",
      "Training step  2487  of  100000  with loss  9.238520622253418\n",
      "Training step  2488  of  100000  with loss  10.086602210998535\n",
      "Training step  2489  of  100000  with loss  11.098880767822266\n",
      "Training step  2490  of  100000  with loss  11.2254056930542\n",
      "Training step  2491  of  100000  with loss  9.771846771240234\n",
      "Training step  2492  of  100000  with loss  9.660993576049805\n",
      "Training step  2493  of  100000  with loss  10.896577835083008\n",
      "Training step  2494  of  100000  with loss  11.473388671875\n",
      "Training step  2495  of  100000  with loss  11.214948654174805\n",
      "Training step  2496  of  100000  with loss  9.891462326049805\n",
      "Training step  2497  of  100000  with loss  10.25961971282959\n",
      "Training step  2498  of  100000  with loss  10.94222640991211\n",
      "Training step  2499  of  100000  with loss  10.323465347290039\n",
      "Training step  2500  of  100000  with loss  10.965446472167969\n",
      "Training step  2501  of  100000  with loss  10.057373046875\n",
      "Training step  2502  of  100000  with loss  10.175348281860352\n",
      "Training step  2503  of  100000  with loss  9.416584014892578\n",
      "Training step  2504  of  100000  with loss  10.409392356872559\n",
      "Training step  2505  of  100000  with loss  11.076096534729004\n",
      "Training step  2506  of  100000  with loss  8.60223388671875\n",
      "Training step  2507  of  100000  with loss  10.17619514465332\n",
      "Training step  2508  of  100000  with loss  9.010796546936035\n",
      "Training step  2509  of  100000  with loss  11.322640419006348\n",
      "Training step  2510  of  100000  with loss  9.0698823928833\n",
      "Training step  2511  of  100000  with loss  9.225088119506836\n",
      "Training step  2512  of  100000  with loss  10.79885196685791\n",
      "Training step  2513  of  100000  with loss  9.415273666381836\n",
      "Training step  2514  of  100000  with loss  9.512064933776855\n",
      "Training step  2515  of  100000  with loss  10.976613998413086\n",
      "Training step  2516  of  100000  with loss  8.435091972351074\n",
      "Training step  2517  of  100000  with loss  10.300036430358887\n",
      "Training step  2518  of  100000  with loss  9.25989055633545\n",
      "Training step  2519  of  100000  with loss  9.813079833984375\n",
      "Training step  2520  of  100000  with loss  10.41558837890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2521  of  100000  with loss  10.367958068847656\n",
      "Training step  2522  of  100000  with loss  9.999611854553223\n",
      "Training step  2523  of  100000  with loss  9.498835563659668\n",
      "Training step  2524  of  100000  with loss  9.568574905395508\n",
      "Training step  2525  of  100000  with loss  8.986056327819824\n",
      "Training step  2526  of  100000  with loss  11.546232223510742\n",
      "Training step  2527  of  100000  with loss  10.161827087402344\n",
      "Training step  2528  of  100000  with loss  9.639612197875977\n",
      "Training step  2529  of  100000  with loss  9.035565376281738\n",
      "Training step  2530  of  100000  with loss  10.942142486572266\n",
      "Training step  2531  of  100000  with loss  8.644111633300781\n",
      "Training step  2532  of  100000  with loss  10.202930450439453\n",
      "Training step  2533  of  100000  with loss  9.776071548461914\n",
      "Training step  2534  of  100000  with loss  9.367645263671875\n",
      "Training step  2535  of  100000  with loss  9.07113265991211\n",
      "Training step  2536  of  100000  with loss  10.437878608703613\n",
      "Training step  2537  of  100000  with loss  10.093706130981445\n",
      "Training step  2538  of  100000  with loss  9.215507507324219\n",
      "Training step  2539  of  100000  with loss  8.90843391418457\n",
      "Training step  2540  of  100000  with loss  12.184123992919922\n",
      "Training step  2541  of  100000  with loss  9.417938232421875\n",
      "Training step  2542  of  100000  with loss  10.989433288574219\n",
      "Training step  2543  of  100000  with loss  11.354482650756836\n",
      "Training step  2544  of  100000  with loss  11.567798614501953\n",
      "Training step  2545  of  100000  with loss  9.944319725036621\n",
      "Training step  2546  of  100000  with loss  9.024091720581055\n",
      "Training step  2547  of  100000  with loss  9.413200378417969\n",
      "Training step  2548  of  100000  with loss  8.956666946411133\n",
      "Training step  2549  of  100000  with loss  9.35433578491211\n",
      "Training step  2550  of  100000  with loss  9.631601333618164\n",
      "Training step  2551  of  100000  with loss  9.268842697143555\n",
      "Training step  2552  of  100000  with loss  8.715839385986328\n",
      "Training step  2553  of  100000  with loss  9.573524475097656\n",
      "Training step  2554  of  100000  with loss  9.606451988220215\n",
      "Training step  2555  of  100000  with loss  11.152382850646973\n",
      "Training step  2556  of  100000  with loss  10.244869232177734\n",
      "Training step  2557  of  100000  with loss  9.824199676513672\n",
      "Training step  2558  of  100000  with loss  9.547503471374512\n",
      "Training step  2559  of  100000  with loss  8.898645401000977\n",
      "Training step  2560  of  100000  with loss  11.175664901733398\n",
      "Training step  2561  of  100000  with loss  9.112231254577637\n",
      "Training step  2562  of  100000  with loss  9.131739616394043\n",
      "Training step  2563  of  100000  with loss  10.55168342590332\n",
      "Training step  2564  of  100000  with loss  9.919090270996094\n",
      "Training step  2565  of  100000  with loss  9.766390800476074\n",
      "Training step  2566  of  100000  with loss  9.718074798583984\n",
      "Training step  2567  of  100000  with loss  9.588844299316406\n",
      "Training step  2568  of  100000  with loss  10.270601272583008\n",
      "Training step  2569  of  100000  with loss  8.372499465942383\n",
      "Training step  2570  of  100000  with loss  10.198456764221191\n",
      "Training step  2571  of  100000  with loss  10.840845108032227\n",
      "Training step  2572  of  100000  with loss  9.72097396850586\n",
      "Training step  2573  of  100000  with loss  9.420077323913574\n",
      "Training step  2574  of  100000  with loss  9.280503273010254\n",
      "Training step  2575  of  100000  with loss  9.35759162902832\n",
      "Training step  2576  of  100000  with loss  10.216949462890625\n",
      "Training step  2577  of  100000  with loss  9.19300365447998\n",
      "Training step  2578  of  100000  with loss  11.326438903808594\n",
      "Training step  2579  of  100000  with loss  9.370518684387207\n",
      "Training step  2580  of  100000  with loss  9.987793922424316\n",
      "Training step  2581  of  100000  with loss  9.575614929199219\n",
      "Training step  2582  of  100000  with loss  10.004219055175781\n",
      "Training step  2583  of  100000  with loss  9.681581497192383\n",
      "Training step  2584  of  100000  with loss  9.75332260131836\n",
      "Training step  2585  of  100000  with loss  10.878705024719238\n",
      "Training step  2586  of  100000  with loss  10.739511489868164\n",
      "Training step  2587  of  100000  with loss  9.512319564819336\n",
      "Training step  2588  of  100000  with loss  11.091890335083008\n",
      "Training step  2589  of  100000  with loss  10.126626968383789\n",
      "Training step  2590  of  100000  with loss  9.68929672241211\n",
      "Training step  2591  of  100000  with loss  10.718452453613281\n",
      "Training step  2592  of  100000  with loss  11.004024505615234\n",
      "Training step  2593  of  100000  with loss  9.969308853149414\n",
      "Training step  2594  of  100000  with loss  9.209545135498047\n",
      "Training step  2595  of  100000  with loss  8.479722023010254\n",
      "Training step  2596  of  100000  with loss  10.588027000427246\n",
      "Training step  2597  of  100000  with loss  11.00477123260498\n",
      "Training step  2598  of  100000  with loss  10.635091781616211\n",
      "Training step  2599  of  100000  with loss  11.817989349365234\n",
      "Training step  2600  of  100000  with loss  9.099763870239258\n",
      "Training step  2601  of  100000  with loss  10.379722595214844\n",
      "Training step  2602  of  100000  with loss  10.021871566772461\n",
      "Training step  2603  of  100000  with loss  10.259284973144531\n",
      "Training step  2604  of  100000  with loss  10.793732643127441\n",
      "Training step  2605  of  100000  with loss  9.147727012634277\n",
      "Training step  2606  of  100000  with loss  9.93817138671875\n",
      "Training step  2607  of  100000  with loss  9.279080390930176\n",
      "Training step  2608  of  100000  with loss  12.281280517578125\n",
      "Training step  2609  of  100000  with loss  10.29104995727539\n",
      "Training step  2610  of  100000  with loss  10.290410995483398\n",
      "Training step  2611  of  100000  with loss  9.708322525024414\n",
      "Training step  2612  of  100000  with loss  10.89261245727539\n",
      "Training step  2613  of  100000  with loss  9.590038299560547\n",
      "Training step  2614  of  100000  with loss  11.55252456665039\n",
      "Training step  2615  of  100000  with loss  9.71845817565918\n",
      "Training step  2616  of  100000  with loss  10.834415435791016\n",
      "Training step  2617  of  100000  with loss  10.768341064453125\n",
      "Training step  2618  of  100000  with loss  9.093321800231934\n",
      "Training step  2619  of  100000  with loss  9.722921371459961\n",
      "Training step  2620  of  100000  with loss  9.28773307800293\n",
      "Training step  2621  of  100000  with loss  9.97396469116211\n",
      "Training step  2622  of  100000  with loss  9.65145492553711\n",
      "Training step  2623  of  100000  with loss  9.229913711547852\n",
      "Training step  2624  of  100000  with loss  10.816218376159668\n",
      "Training step  2625  of  100000  with loss  10.798784255981445\n",
      "Training step  2626  of  100000  with loss  11.139434814453125\n",
      "Training step  2627  of  100000  with loss  9.976369857788086\n",
      "Training step  2628  of  100000  with loss  9.561602592468262\n",
      "Training step  2629  of  100000  with loss  10.453798294067383\n",
      "Training step  2630  of  100000  with loss  9.189716339111328\n",
      "Training step  2631  of  100000  with loss  11.708343505859375\n",
      "Training step  2632  of  100000  with loss  10.254334449768066\n",
      "Training step  2633  of  100000  with loss  10.683839797973633\n",
      "Training step  2634  of  100000  with loss  10.014031410217285\n",
      "Training step  2635  of  100000  with loss  13.37189769744873\n",
      "Training step  2636  of  100000  with loss  10.103321075439453\n",
      "Training step  2637  of  100000  with loss  11.045110702514648\n",
      "Training step  2638  of  100000  with loss  11.201602935791016\n",
      "Training step  2639  of  100000  with loss  10.102445602416992\n",
      "Training step  2640  of  100000  with loss  11.126777648925781\n",
      "Training step  2641  of  100000  with loss  10.052726745605469\n",
      "Training step  2642  of  100000  with loss  11.040109634399414\n",
      "Training step  2643  of  100000  with loss  10.117387771606445\n",
      "Training step  2644  of  100000  with loss  10.195226669311523\n",
      "Training step  2645  of  100000  with loss  11.386144638061523\n",
      "Training step  2646  of  100000  with loss  10.66578483581543\n",
      "Training step  2647  of  100000  with loss  10.006994247436523\n",
      "Training step  2648  of  100000  with loss  10.346357345581055\n",
      "Training step  2649  of  100000  with loss  9.537185668945312\n",
      "Training step  2650  of  100000  with loss  10.133208274841309\n",
      "Training step  2651  of  100000  with loss  8.763833999633789\n",
      "Training step  2652  of  100000  with loss  9.309398651123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2653  of  100000  with loss  9.761381149291992\n",
      "Training step  2654  of  100000  with loss  9.487570762634277\n",
      "Training step  2655  of  100000  with loss  9.970118522644043\n",
      "Training step  2656  of  100000  with loss  9.33284854888916\n",
      "Training step  2657  of  100000  with loss  9.056184768676758\n",
      "Training step  2658  of  100000  with loss  9.374284744262695\n",
      "Training step  2659  of  100000  with loss  8.854677200317383\n",
      "Training step  2660  of  100000  with loss  9.611400604248047\n",
      "Training step  2661  of  100000  with loss  11.978490829467773\n",
      "Training step  2662  of  100000  with loss  10.308004379272461\n",
      "Training step  2663  of  100000  with loss  10.30601692199707\n",
      "Training step  2664  of  100000  with loss  9.745338439941406\n",
      "Training step  2665  of  100000  with loss  9.02379322052002\n",
      "Training step  2666  of  100000  with loss  10.335434913635254\n",
      "Training step  2667  of  100000  with loss  9.726335525512695\n",
      "Training step  2668  of  100000  with loss  9.555225372314453\n",
      "Training step  2669  of  100000  with loss  9.530329704284668\n",
      "Training step  2670  of  100000  with loss  10.113384246826172\n",
      "Training step  2671  of  100000  with loss  9.613972663879395\n",
      "Training step  2672  of  100000  with loss  9.245261192321777\n",
      "Training step  2673  of  100000  with loss  8.996726989746094\n",
      "Training step  2674  of  100000  with loss  11.177817344665527\n",
      "Training step  2675  of  100000  with loss  9.149280548095703\n",
      "Training step  2676  of  100000  with loss  9.083096504211426\n",
      "Training step  2677  of  100000  with loss  9.570594787597656\n",
      "Training step  2678  of  100000  with loss  10.079330444335938\n",
      "Training step  2679  of  100000  with loss  10.01114273071289\n",
      "Training step  2680  of  100000  with loss  9.742509841918945\n",
      "Training step  2681  of  100000  with loss  9.904885292053223\n",
      "Training step  2682  of  100000  with loss  9.18297290802002\n",
      "Training step  2683  of  100000  with loss  9.983074188232422\n",
      "Training step  2684  of  100000  with loss  10.269988059997559\n",
      "Training step  2685  of  100000  with loss  9.44636058807373\n",
      "Training step  2686  of  100000  with loss  10.884224891662598\n",
      "Training step  2687  of  100000  with loss  8.813944816589355\n",
      "Training step  2688  of  100000  with loss  10.265876770019531\n",
      "Training step  2689  of  100000  with loss  9.108734130859375\n",
      "Training step  2690  of  100000  with loss  10.981559753417969\n",
      "Training step  2691  of  100000  with loss  10.395551681518555\n",
      "Training step  2692  of  100000  with loss  9.849527359008789\n",
      "Training step  2693  of  100000  with loss  9.375846862792969\n",
      "Training step  2694  of  100000  with loss  10.91792106628418\n",
      "Training step  2695  of  100000  with loss  11.0673828125\n",
      "Training step  2696  of  100000  with loss  11.117718696594238\n",
      "Training step  2697  of  100000  with loss  10.175110816955566\n",
      "Training step  2698  of  100000  with loss  9.445574760437012\n",
      "Training step  2699  of  100000  with loss  9.794605255126953\n",
      "Training step  2700  of  100000  with loss  11.229429244995117\n",
      "Training step  2701  of  100000  with loss  8.867633819580078\n",
      "Training step  2702  of  100000  with loss  10.91702651977539\n",
      "Training step  2703  of  100000  with loss  8.749622344970703\n",
      "Training step  2704  of  100000  with loss  10.651535034179688\n",
      "Training step  2705  of  100000  with loss  9.857976913452148\n",
      "Training step  2706  of  100000  with loss  12.139049530029297\n",
      "Training step  2707  of  100000  with loss  9.792316436767578\n",
      "Training step  2708  of  100000  with loss  11.687461853027344\n",
      "Training step  2709  of  100000  with loss  9.5628080368042\n",
      "Training step  2710  of  100000  with loss  10.276705741882324\n",
      "Training step  2711  of  100000  with loss  10.845178604125977\n",
      "Training step  2712  of  100000  with loss  10.345726013183594\n",
      "Training step  2713  of  100000  with loss  9.584259033203125\n",
      "Training step  2714  of  100000  with loss  8.811220169067383\n",
      "Training step  2715  of  100000  with loss  8.504803657531738\n",
      "Training step  2716  of  100000  with loss  9.597900390625\n",
      "Training step  2717  of  100000  with loss  9.470142364501953\n",
      "Training step  2718  of  100000  with loss  10.33018684387207\n",
      "Training step  2719  of  100000  with loss  10.704278945922852\n",
      "Training step  2720  of  100000  with loss  8.145137786865234\n",
      "Training step  2721  of  100000  with loss  10.722261428833008\n",
      "Training step  2722  of  100000  with loss  10.547746658325195\n",
      "Training step  2723  of  100000  with loss  9.608854293823242\n",
      "Training step  2724  of  100000  with loss  10.432214736938477\n",
      "Training step  2725  of  100000  with loss  9.292911529541016\n",
      "Training step  2726  of  100000  with loss  10.16779899597168\n",
      "Training step  2727  of  100000  with loss  9.624073028564453\n",
      "Training step  2728  of  100000  with loss  10.588066101074219\n",
      "Training step  2729  of  100000  with loss  11.80589485168457\n",
      "Training step  2730  of  100000  with loss  9.364343643188477\n",
      "Training step  2731  of  100000  with loss  9.50545883178711\n",
      "Training step  2732  of  100000  with loss  10.0283203125\n",
      "Training step  2733  of  100000  with loss  10.277429580688477\n",
      "Training step  2734  of  100000  with loss  10.195202827453613\n",
      "Training step  2735  of  100000  with loss  8.723526954650879\n",
      "Training step  2736  of  100000  with loss  10.235204696655273\n",
      "Training step  2737  of  100000  with loss  9.639638900756836\n",
      "Training step  2738  of  100000  with loss  8.825003623962402\n",
      "Training step  2739  of  100000  with loss  9.415674209594727\n",
      "Training step  2740  of  100000  with loss  9.763134002685547\n",
      "Training step  2741  of  100000  with loss  10.305745124816895\n",
      "Training step  2742  of  100000  with loss  11.530241012573242\n",
      "Training step  2743  of  100000  with loss  10.649286270141602\n",
      "Training step  2744  of  100000  with loss  9.66711711883545\n",
      "Training step  2745  of  100000  with loss  9.29623031616211\n",
      "Training step  2746  of  100000  with loss  10.522220611572266\n",
      "Training step  2747  of  100000  with loss  9.106756210327148\n",
      "Training step  2748  of  100000  with loss  10.294395446777344\n",
      "Training step  2749  of  100000  with loss  10.133645057678223\n",
      "Training step  2750  of  100000  with loss  10.566095352172852\n",
      "Training step  2751  of  100000  with loss  10.32753849029541\n",
      "Training step  2752  of  100000  with loss  10.475727081298828\n",
      "Training step  2753  of  100000  with loss  10.12783432006836\n",
      "Training step  2754  of  100000  with loss  9.614511489868164\n",
      "Training step  2755  of  100000  with loss  10.662895202636719\n",
      "Training step  2756  of  100000  with loss  10.098332405090332\n",
      "Training step  2757  of  100000  with loss  11.332670211791992\n",
      "Training step  2758  of  100000  with loss  10.527568817138672\n",
      "Training step  2759  of  100000  with loss  9.828742980957031\n",
      "Training step  2760  of  100000  with loss  9.687253952026367\n",
      "Training step  2761  of  100000  with loss  9.732687950134277\n",
      "Training step  2762  of  100000  with loss  10.993949890136719\n",
      "Training step  2763  of  100000  with loss  9.17422866821289\n",
      "Training step  2764  of  100000  with loss  9.690130233764648\n",
      "Training step  2765  of  100000  with loss  9.544286727905273\n",
      "Training step  2766  of  100000  with loss  9.025378227233887\n",
      "Training step  2767  of  100000  with loss  9.615330696105957\n",
      "Training step  2768  of  100000  with loss  10.930134773254395\n",
      "Training step  2769  of  100000  with loss  8.457032203674316\n",
      "Training step  2770  of  100000  with loss  10.017160415649414\n",
      "Training step  2771  of  100000  with loss  10.21652889251709\n",
      "Training step  2772  of  100000  with loss  10.187885284423828\n",
      "Training step  2773  of  100000  with loss  9.413010597229004\n",
      "Training step  2774  of  100000  with loss  11.512432098388672\n",
      "Training step  2775  of  100000  with loss  10.14061164855957\n",
      "Training step  2776  of  100000  with loss  9.63784408569336\n",
      "Training step  2777  of  100000  with loss  10.329761505126953\n",
      "Training step  2778  of  100000  with loss  9.36249828338623\n",
      "Training step  2779  of  100000  with loss  9.483403205871582\n",
      "Training step  2780  of  100000  with loss  9.081042289733887\n",
      "Training step  2781  of  100000  with loss  9.963165283203125\n",
      "Training step  2782  of  100000  with loss  9.186665534973145\n",
      "Training step  2783  of  100000  with loss  9.466787338256836\n",
      "Training step  2784  of  100000  with loss  10.70768928527832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2785  of  100000  with loss  10.890630722045898\n",
      "Training step  2786  of  100000  with loss  10.796147346496582\n",
      "Training step  2787  of  100000  with loss  10.839139938354492\n",
      "Training step  2788  of  100000  with loss  10.121820449829102\n",
      "Training step  2789  of  100000  with loss  10.285015106201172\n",
      "Training step  2790  of  100000  with loss  8.042564392089844\n",
      "Training step  2791  of  100000  with loss  9.551652908325195\n",
      "Training step  2792  of  100000  with loss  9.175086975097656\n",
      "Training step  2793  of  100000  with loss  9.614058494567871\n",
      "Training step  2794  of  100000  with loss  10.594329833984375\n",
      "Training step  2795  of  100000  with loss  10.930215835571289\n",
      "Training step  2796  of  100000  with loss  9.402719497680664\n",
      "Training step  2797  of  100000  with loss  9.456818580627441\n",
      "Training step  2798  of  100000  with loss  8.434368133544922\n",
      "Training step  2799  of  100000  with loss  8.751279830932617\n",
      "Training step  2800  of  100000  with loss  9.257944107055664\n",
      "Training step  2801  of  100000  with loss  9.818113327026367\n",
      "Training step  2802  of  100000  with loss  9.929656982421875\n",
      "Training step  2803  of  100000  with loss  10.906759262084961\n",
      "Training step  2804  of  100000  with loss  10.208341598510742\n",
      "Training step  2805  of  100000  with loss  9.286574363708496\n",
      "Training step  2806  of  100000  with loss  11.476923942565918\n",
      "Training step  2807  of  100000  with loss  10.567876815795898\n",
      "Training step  2808  of  100000  with loss  10.254793167114258\n",
      "Training step  2809  of  100000  with loss  9.70974349975586\n",
      "Training step  2810  of  100000  with loss  8.709749221801758\n",
      "Training step  2811  of  100000  with loss  9.133745193481445\n",
      "Training step  2812  of  100000  with loss  9.170943260192871\n",
      "Training step  2813  of  100000  with loss  9.857200622558594\n",
      "Training step  2814  of  100000  with loss  10.740010261535645\n",
      "Training step  2815  of  100000  with loss  10.580948829650879\n",
      "Training step  2816  of  100000  with loss  10.470486640930176\n",
      "Training step  2817  of  100000  with loss  9.909836769104004\n",
      "Training step  2818  of  100000  with loss  9.385377883911133\n",
      "Training step  2819  of  100000  with loss  9.815755844116211\n",
      "Training step  2820  of  100000  with loss  9.978667259216309\n",
      "Training step  2821  of  100000  with loss  11.845362663269043\n",
      "Training step  2822  of  100000  with loss  9.41369915008545\n",
      "Training step  2823  of  100000  with loss  10.663505554199219\n",
      "Training step  2824  of  100000  with loss  10.733181953430176\n",
      "Training step  2825  of  100000  with loss  9.630383491516113\n",
      "Training step  2826  of  100000  with loss  9.29099178314209\n",
      "Training step  2827  of  100000  with loss  10.96550178527832\n",
      "Training step  2828  of  100000  with loss  10.933023452758789\n",
      "Training step  2829  of  100000  with loss  10.240171432495117\n",
      "Training step  2830  of  100000  with loss  9.731124877929688\n",
      "Training step  2831  of  100000  with loss  9.958343505859375\n",
      "Training step  2832  of  100000  with loss  9.574447631835938\n",
      "Training step  2833  of  100000  with loss  9.347821235656738\n",
      "Training step  2834  of  100000  with loss  10.050867080688477\n",
      "Training step  2835  of  100000  with loss  9.95070743560791\n",
      "Training step  2836  of  100000  with loss  9.697600364685059\n",
      "Training step  2837  of  100000  with loss  9.935478210449219\n",
      "Training step  2838  of  100000  with loss  10.098567008972168\n",
      "Training step  2839  of  100000  with loss  9.620899200439453\n",
      "Training step  2840  of  100000  with loss  11.1012601852417\n",
      "Training step  2841  of  100000  with loss  10.485010147094727\n",
      "Training step  2842  of  100000  with loss  9.528863906860352\n",
      "Training step  2843  of  100000  with loss  11.110002517700195\n",
      "Training step  2844  of  100000  with loss  9.759590148925781\n",
      "Training step  2845  of  100000  with loss  10.559225082397461\n",
      "Training step  2846  of  100000  with loss  10.977254867553711\n",
      "Training step  2847  of  100000  with loss  9.874704360961914\n",
      "Training step  2848  of  100000  with loss  10.321971893310547\n",
      "Training step  2849  of  100000  with loss  9.56441879272461\n",
      "Training step  2850  of  100000  with loss  9.966249465942383\n",
      "Training step  2851  of  100000  with loss  11.181524276733398\n",
      "Training step  2852  of  100000  with loss  10.695823669433594\n",
      "Training step  2853  of  100000  with loss  12.029857635498047\n",
      "Training step  2854  of  100000  with loss  9.74797534942627\n",
      "Training step  2855  of  100000  with loss  10.077529907226562\n",
      "Training step  2856  of  100000  with loss  10.19293212890625\n",
      "Training step  2857  of  100000  with loss  10.250779151916504\n",
      "Training step  2858  of  100000  with loss  9.259721755981445\n",
      "Training step  2859  of  100000  with loss  9.955814361572266\n",
      "Training step  2860  of  100000  with loss  9.510688781738281\n",
      "Training step  2861  of  100000  with loss  9.68675422668457\n",
      "Training step  2862  of  100000  with loss  10.937494277954102\n",
      "Training step  2863  of  100000  with loss  11.241846084594727\n",
      "Training step  2864  of  100000  with loss  9.670238494873047\n",
      "Training step  2865  of  100000  with loss  9.05117416381836\n",
      "Training step  2866  of  100000  with loss  9.56403636932373\n",
      "Training step  2867  of  100000  with loss  10.700754165649414\n",
      "Training step  2868  of  100000  with loss  10.035457611083984\n",
      "Training step  2869  of  100000  with loss  8.320846557617188\n",
      "Training step  2870  of  100000  with loss  10.537690162658691\n",
      "Training step  2871  of  100000  with loss  9.521493911743164\n",
      "Training step  2872  of  100000  with loss  10.052447319030762\n",
      "Training step  2873  of  100000  with loss  11.83679485321045\n",
      "Training step  2874  of  100000  with loss  11.072924613952637\n",
      "Training step  2875  of  100000  with loss  10.779157638549805\n",
      "Training step  2876  of  100000  with loss  10.406935691833496\n",
      "Training step  2877  of  100000  with loss  9.355133056640625\n",
      "Training step  2878  of  100000  with loss  10.120142936706543\n",
      "Training step  2879  of  100000  with loss  9.09480094909668\n",
      "Training step  2880  of  100000  with loss  9.27109432220459\n",
      "Training step  2881  of  100000  with loss  10.717279434204102\n",
      "Training step  2882  of  100000  with loss  8.991086959838867\n",
      "Training step  2883  of  100000  with loss  10.273445129394531\n",
      "Training step  2884  of  100000  with loss  9.401968955993652\n",
      "Training step  2885  of  100000  with loss  10.599305152893066\n",
      "Training step  2886  of  100000  with loss  10.49502944946289\n",
      "Training step  2887  of  100000  with loss  9.261425971984863\n",
      "Training step  2888  of  100000  with loss  10.331274032592773\n",
      "Training step  2889  of  100000  with loss  10.233329772949219\n",
      "Training step  2890  of  100000  with loss  8.91579818725586\n",
      "Training step  2891  of  100000  with loss  10.864177703857422\n",
      "Training step  2892  of  100000  with loss  10.433267593383789\n",
      "Training step  2893  of  100000  with loss  10.197031021118164\n",
      "Training step  2894  of  100000  with loss  10.850259780883789\n",
      "Training step  2895  of  100000  with loss  10.433588027954102\n",
      "Training step  2896  of  100000  with loss  9.942876815795898\n",
      "Training step  2897  of  100000  with loss  10.249889373779297\n",
      "Training step  2898  of  100000  with loss  11.03976821899414\n",
      "Training step  2899  of  100000  with loss  9.604378700256348\n",
      "Training step  2900  of  100000  with loss  11.31537914276123\n",
      "Training step  2901  of  100000  with loss  9.478897094726562\n",
      "Training step  2902  of  100000  with loss  10.002973556518555\n",
      "Training step  2903  of  100000  with loss  9.425464630126953\n",
      "Training step  2904  of  100000  with loss  9.378986358642578\n",
      "Training step  2905  of  100000  with loss  9.782751083374023\n",
      "Training step  2906  of  100000  with loss  10.748758316040039\n",
      "Training step  2907  of  100000  with loss  9.454573631286621\n",
      "Training step  2908  of  100000  with loss  11.137885093688965\n",
      "Training step  2909  of  100000  with loss  9.468657493591309\n",
      "Training step  2910  of  100000  with loss  8.548561096191406\n",
      "Training step  2911  of  100000  with loss  11.086669921875\n",
      "Training step  2912  of  100000  with loss  10.994600296020508\n",
      "Training step  2913  of  100000  with loss  10.93677806854248\n",
      "Training step  2914  of  100000  with loss  10.061522483825684\n",
      "Training step  2915  of  100000  with loss  9.620041847229004\n",
      "Training step  2916  of  100000  with loss  11.504006385803223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  2917  of  100000  with loss  9.969964027404785\n",
      "Training step  2918  of  100000  with loss  10.42405891418457\n",
      "Training step  2919  of  100000  with loss  9.739755630493164\n",
      "Training step  2920  of  100000  with loss  10.36500358581543\n",
      "Training step  2921  of  100000  with loss  11.331605911254883\n",
      "Training step  2922  of  100000  with loss  9.49802017211914\n",
      "Training step  2923  of  100000  with loss  8.762100219726562\n",
      "Training step  2924  of  100000  with loss  10.599405288696289\n",
      "Training step  2925  of  100000  with loss  10.181532859802246\n",
      "Training step  2926  of  100000  with loss  10.60942268371582\n",
      "Training step  2927  of  100000  with loss  10.857884407043457\n",
      "Training step  2928  of  100000  with loss  9.714317321777344\n",
      "Training step  2929  of  100000  with loss  9.326178550720215\n",
      "Training step  2930  of  100000  with loss  10.921817779541016\n",
      "Training step  2931  of  100000  with loss  9.7313232421875\n",
      "Training step  2932  of  100000  with loss  10.28352165222168\n",
      "Training step  2933  of  100000  with loss  11.932762145996094\n",
      "Training step  2934  of  100000  with loss  9.527835845947266\n",
      "Training step  2935  of  100000  with loss  12.189697265625\n",
      "Training step  2936  of  100000  with loss  8.838812828063965\n",
      "Training step  2937  of  100000  with loss  9.457042694091797\n",
      "Training step  2938  of  100000  with loss  9.680034637451172\n",
      "Training step  2939  of  100000  with loss  9.82476806640625\n",
      "Training step  2940  of  100000  with loss  9.180938720703125\n",
      "Training step  2941  of  100000  with loss  10.803140640258789\n",
      "Training step  2942  of  100000  with loss  9.178936958312988\n",
      "Training step  2943  of  100000  with loss  10.391565322875977\n",
      "Training step  2944  of  100000  with loss  10.433080673217773\n",
      "Training step  2945  of  100000  with loss  9.916507720947266\n",
      "Training step  2946  of  100000  with loss  8.602764129638672\n",
      "Training step  2947  of  100000  with loss  9.655216217041016\n",
      "Training step  2948  of  100000  with loss  12.085983276367188\n",
      "Training step  2949  of  100000  with loss  9.934289932250977\n",
      "Training step  2950  of  100000  with loss  11.747823715209961\n",
      "Training step  2951  of  100000  with loss  11.9061279296875\n",
      "Training step  2952  of  100000  with loss  9.127429008483887\n",
      "Training step  2953  of  100000  with loss  8.611719131469727\n",
      "Training step  2954  of  100000  with loss  10.640989303588867\n",
      "Training step  2955  of  100000  with loss  9.955402374267578\n",
      "Training step  2956  of  100000  with loss  11.071794509887695\n",
      "Training step  2957  of  100000  with loss  10.242563247680664\n",
      "Training step  2958  of  100000  with loss  9.600868225097656\n",
      "Training step  2959  of  100000  with loss  9.818632125854492\n",
      "Training step  2960  of  100000  with loss  9.439115524291992\n",
      "Training step  2961  of  100000  with loss  9.627691268920898\n",
      "Training step  2962  of  100000  with loss  10.296723365783691\n",
      "Training step  2963  of  100000  with loss  8.74765682220459\n",
      "Training step  2964  of  100000  with loss  9.578210830688477\n",
      "Training step  2965  of  100000  with loss  10.311290740966797\n",
      "Training step  2966  of  100000  with loss  10.350227355957031\n",
      "Training step  2967  of  100000  with loss  10.700045585632324\n",
      "Training step  2968  of  100000  with loss  10.4285306930542\n",
      "Training step  2969  of  100000  with loss  8.799215316772461\n",
      "Training step  2970  of  100000  with loss  10.104913711547852\n",
      "Training step  2971  of  100000  with loss  10.147370338439941\n",
      "Training step  2972  of  100000  with loss  8.827920913696289\n",
      "Training step  2973  of  100000  with loss  8.548727035522461\n",
      "Training step  2974  of  100000  with loss  9.376701354980469\n",
      "Training step  2975  of  100000  with loss  9.644862174987793\n",
      "Training step  2976  of  100000  with loss  9.622536659240723\n",
      "Training step  2977  of  100000  with loss  11.59765625\n",
      "Training step  2978  of  100000  with loss  10.928323745727539\n",
      "Training step  2979  of  100000  with loss  9.976837158203125\n",
      "Training step  2980  of  100000  with loss  10.847938537597656\n",
      "Training step  2981  of  100000  with loss  9.504420280456543\n",
      "Training step  2982  of  100000  with loss  10.519216537475586\n",
      "Training step  2983  of  100000  with loss  10.265867233276367\n",
      "Training step  2984  of  100000  with loss  8.814146041870117\n",
      "Training step  2985  of  100000  with loss  9.251611709594727\n",
      "Training step  2986  of  100000  with loss  8.676031112670898\n",
      "Training step  2987  of  100000  with loss  10.662358283996582\n",
      "Training step  2988  of  100000  with loss  10.624950408935547\n",
      "Training step  2989  of  100000  with loss  9.221660614013672\n",
      "Training step  2990  of  100000  with loss  11.734258651733398\n",
      "Training step  2991  of  100000  with loss  8.734321594238281\n",
      "Training step  2992  of  100000  with loss  9.55833625793457\n",
      "Training step  2993  of  100000  with loss  9.223508834838867\n",
      "Training step  2994  of  100000  with loss  10.049678802490234\n",
      "Training step  2995  of  100000  with loss  9.27558422088623\n",
      "Training step  2996  of  100000  with loss  9.203827857971191\n",
      "Training step  2997  of  100000  with loss  10.078454971313477\n",
      "Training step  2998  of  100000  with loss  8.727181434631348\n",
      "Training step  2999  of  100000  with loss  10.310163497924805\n",
      "Training step  3000  of  100000  with loss  11.183537483215332\n",
      "Training step  3001  of  100000  with loss  9.130536079406738\n",
      "Training step  3002  of  100000  with loss  10.592141151428223\n",
      "Training step  3003  of  100000  with loss  9.854605674743652\n",
      "Training step  3004  of  100000  with loss  10.524107933044434\n",
      "Training step  3005  of  100000  with loss  8.608406066894531\n",
      "Training step  3006  of  100000  with loss  9.203821182250977\n",
      "Training step  3007  of  100000  with loss  10.946531295776367\n",
      "Training step  3008  of  100000  with loss  10.45981216430664\n",
      "Training step  3009  of  100000  with loss  11.015617370605469\n",
      "Training step  3010  of  100000  with loss  8.719377517700195\n",
      "Training step  3011  of  100000  with loss  11.107678413391113\n",
      "Training step  3012  of  100000  with loss  9.703206062316895\n",
      "Training step  3013  of  100000  with loss  10.552386283874512\n",
      "Training step  3014  of  100000  with loss  10.675619125366211\n",
      "Training step  3015  of  100000  with loss  8.954181671142578\n",
      "Training step  3016  of  100000  with loss  11.180696487426758\n",
      "Training step  3017  of  100000  with loss  10.044278144836426\n",
      "Training step  3018  of  100000  with loss  9.908831596374512\n",
      "Training step  3019  of  100000  with loss  9.508671760559082\n",
      "Training step  3020  of  100000  with loss  11.613138198852539\n",
      "Training step  3021  of  100000  with loss  10.50037956237793\n",
      "Training step  3022  of  100000  with loss  9.755199432373047\n",
      "Training step  3023  of  100000  with loss  10.379997253417969\n",
      "Training step  3024  of  100000  with loss  9.567670822143555\n",
      "Training step  3025  of  100000  with loss  9.264833450317383\n",
      "Training step  3026  of  100000  with loss  9.095548629760742\n",
      "Training step  3027  of  100000  with loss  11.495271682739258\n",
      "Training step  3028  of  100000  with loss  9.393884658813477\n",
      "Training step  3029  of  100000  with loss  10.686899185180664\n",
      "Training step  3030  of  100000  with loss  12.1241455078125\n",
      "Training step  3031  of  100000  with loss  10.013765335083008\n",
      "Training step  3032  of  100000  with loss  8.874398231506348\n",
      "Training step  3033  of  100000  with loss  9.826045989990234\n",
      "Training step  3034  of  100000  with loss  11.166946411132812\n",
      "Training step  3035  of  100000  with loss  9.814075469970703\n",
      "Training step  3036  of  100000  with loss  10.095925331115723\n",
      "Training step  3037  of  100000  with loss  9.719947814941406\n",
      "Training step  3038  of  100000  with loss  11.171876907348633\n",
      "Training step  3039  of  100000  with loss  9.492855072021484\n",
      "Training step  3040  of  100000  with loss  10.509600639343262\n",
      "Training step  3041  of  100000  with loss  10.141124725341797\n",
      "Training step  3042  of  100000  with loss  9.035951614379883\n",
      "Training step  3043  of  100000  with loss  9.506477355957031\n",
      "Training step  3044  of  100000  with loss  9.068232536315918\n",
      "Training step  3045  of  100000  with loss  10.28237533569336\n",
      "Training step  3046  of  100000  with loss  9.793302536010742\n",
      "Training step  3047  of  100000  with loss  9.70025634765625\n",
      "Training step  3048  of  100000  with loss  10.965106964111328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3049  of  100000  with loss  10.91530990600586\n",
      "Training step  3050  of  100000  with loss  8.865935325622559\n",
      "Training step  3051  of  100000  with loss  9.784133911132812\n",
      "Training step  3052  of  100000  with loss  10.68459701538086\n",
      "Training step  3053  of  100000  with loss  10.128898620605469\n",
      "Training step  3054  of  100000  with loss  10.664283752441406\n",
      "Training step  3055  of  100000  with loss  10.544404983520508\n",
      "Training step  3056  of  100000  with loss  9.532716751098633\n",
      "Training step  3057  of  100000  with loss  10.248722076416016\n",
      "Training step  3058  of  100000  with loss  9.70502758026123\n",
      "Training step  3059  of  100000  with loss  10.153106689453125\n",
      "Training step  3060  of  100000  with loss  9.004687309265137\n",
      "Training step  3061  of  100000  with loss  9.649056434631348\n",
      "Training step  3062  of  100000  with loss  9.793960571289062\n",
      "Training step  3063  of  100000  with loss  9.413080215454102\n",
      "Training step  3064  of  100000  with loss  9.921834945678711\n",
      "Training step  3065  of  100000  with loss  9.844855308532715\n",
      "Training step  3066  of  100000  with loss  10.342572212219238\n",
      "Training step  3067  of  100000  with loss  8.923818588256836\n",
      "Training step  3068  of  100000  with loss  10.002293586730957\n",
      "Training step  3069  of  100000  with loss  8.67624568939209\n",
      "Training step  3070  of  100000  with loss  9.985212326049805\n",
      "Training step  3071  of  100000  with loss  10.100650787353516\n",
      "Training step  3072  of  100000  with loss  11.305624008178711\n",
      "Training step  3073  of  100000  with loss  9.628303527832031\n",
      "Training step  3074  of  100000  with loss  8.851384162902832\n",
      "Training step  3075  of  100000  with loss  11.538814544677734\n",
      "Training step  3076  of  100000  with loss  9.89090633392334\n",
      "Training step  3077  of  100000  with loss  11.226150512695312\n",
      "Training step  3078  of  100000  with loss  9.314834594726562\n",
      "Training step  3079  of  100000  with loss  10.75425910949707\n",
      "Training step  3080  of  100000  with loss  9.719562530517578\n",
      "Training step  3081  of  100000  with loss  9.927224159240723\n",
      "Training step  3082  of  100000  with loss  10.354850769042969\n",
      "Training step  3083  of  100000  with loss  9.830970764160156\n",
      "Training step  3084  of  100000  with loss  10.040417671203613\n",
      "Training step  3085  of  100000  with loss  10.090399742126465\n",
      "Training step  3086  of  100000  with loss  9.999639511108398\n",
      "Training step  3087  of  100000  with loss  9.93547248840332\n",
      "Training step  3088  of  100000  with loss  9.995716094970703\n",
      "Training step  3089  of  100000  with loss  9.295554161071777\n",
      "Training step  3090  of  100000  with loss  8.813859939575195\n",
      "Training step  3091  of  100000  with loss  8.682500839233398\n",
      "Training step  3092  of  100000  with loss  9.37167739868164\n",
      "Training step  3093  of  100000  with loss  11.116976737976074\n",
      "Training step  3094  of  100000  with loss  10.494644165039062\n",
      "Training step  3095  of  100000  with loss  9.349081993103027\n",
      "Training step  3096  of  100000  with loss  11.675830841064453\n",
      "Training step  3097  of  100000  with loss  8.975706100463867\n",
      "Training step  3098  of  100000  with loss  10.09288501739502\n",
      "Training step  3099  of  100000  with loss  9.062965393066406\n",
      "Training step  3100  of  100000  with loss  11.161898612976074\n",
      "Training step  3101  of  100000  with loss  9.670286178588867\n",
      "Training step  3102  of  100000  with loss  10.52102279663086\n",
      "Training step  3103  of  100000  with loss  10.677055358886719\n",
      "Training step  3104  of  100000  with loss  10.378412246704102\n",
      "Training step  3105  of  100000  with loss  9.958919525146484\n",
      "Training step  3106  of  100000  with loss  9.881802558898926\n",
      "Training step  3107  of  100000  with loss  10.36471939086914\n",
      "Training step  3108  of  100000  with loss  9.381393432617188\n",
      "Training step  3109  of  100000  with loss  10.118918418884277\n",
      "Training step  3110  of  100000  with loss  9.839731216430664\n",
      "Training step  3111  of  100000  with loss  8.89987850189209\n",
      "Training step  3112  of  100000  with loss  9.8265380859375\n",
      "Training step  3113  of  100000  with loss  9.617898941040039\n",
      "Training step  3114  of  100000  with loss  10.061063766479492\n",
      "Training step  3115  of  100000  with loss  9.728999137878418\n",
      "Training step  3116  of  100000  with loss  11.136396408081055\n",
      "Training step  3117  of  100000  with loss  10.039705276489258\n",
      "Training step  3118  of  100000  with loss  9.837494850158691\n",
      "Training step  3119  of  100000  with loss  8.85692024230957\n",
      "Training step  3120  of  100000  with loss  10.489086151123047\n",
      "Training step  3121  of  100000  with loss  8.948143005371094\n",
      "Training step  3122  of  100000  with loss  9.991744995117188\n",
      "Training step  3123  of  100000  with loss  9.938485145568848\n",
      "Training step  3124  of  100000  with loss  9.536803245544434\n",
      "Training step  3125  of  100000  with loss  10.357072830200195\n",
      "Training step  3126  of  100000  with loss  11.074737548828125\n",
      "Training step  3127  of  100000  with loss  11.263504028320312\n",
      "Training step  3128  of  100000  with loss  10.023260116577148\n",
      "Training step  3129  of  100000  with loss  9.344610214233398\n",
      "Training step  3130  of  100000  with loss  10.367098808288574\n",
      "Training step  3131  of  100000  with loss  10.200478553771973\n",
      "Training step  3132  of  100000  with loss  10.42540168762207\n",
      "Training step  3133  of  100000  with loss  9.55696964263916\n",
      "Training step  3134  of  100000  with loss  10.373208045959473\n",
      "Training step  3135  of  100000  with loss  9.696243286132812\n",
      "Training step  3136  of  100000  with loss  9.180737495422363\n",
      "Training step  3137  of  100000  with loss  9.815573692321777\n",
      "Training step  3138  of  100000  with loss  9.999415397644043\n",
      "Training step  3139  of  100000  with loss  11.30471420288086\n",
      "Training step  3140  of  100000  with loss  9.958444595336914\n",
      "Training step  3141  of  100000  with loss  9.021836280822754\n",
      "Training step  3142  of  100000  with loss  9.006677627563477\n",
      "Training step  3143  of  100000  with loss  9.469459533691406\n",
      "Training step  3144  of  100000  with loss  8.564390182495117\n",
      "Training step  3145  of  100000  with loss  10.005633354187012\n",
      "Training step  3146  of  100000  with loss  9.418428421020508\n",
      "Training step  3147  of  100000  with loss  9.496384620666504\n",
      "Training step  3148  of  100000  with loss  9.904142379760742\n",
      "Training step  3149  of  100000  with loss  9.536429405212402\n",
      "Training step  3150  of  100000  with loss  8.373832702636719\n",
      "Training step  3151  of  100000  with loss  10.1207857131958\n",
      "Training step  3152  of  100000  with loss  9.203155517578125\n",
      "Training step  3153  of  100000  with loss  10.638595581054688\n",
      "Training step  3154  of  100000  with loss  10.115703582763672\n",
      "Training step  3155  of  100000  with loss  9.670631408691406\n",
      "Training step  3156  of  100000  with loss  10.012235641479492\n",
      "Training step  3157  of  100000  with loss  10.993185997009277\n",
      "Training step  3158  of  100000  with loss  9.073736190795898\n",
      "Training step  3159  of  100000  with loss  8.136417388916016\n",
      "Training step  3160  of  100000  with loss  10.981307983398438\n",
      "Training step  3161  of  100000  with loss  10.955302238464355\n",
      "Training step  3162  of  100000  with loss  11.177456855773926\n",
      "Training step  3163  of  100000  with loss  10.391979217529297\n",
      "Training step  3164  of  100000  with loss  10.03139877319336\n",
      "Training step  3165  of  100000  with loss  9.099689483642578\n",
      "Training step  3166  of  100000  with loss  9.24356460571289\n",
      "Training step  3167  of  100000  with loss  12.022483825683594\n",
      "Training step  3168  of  100000  with loss  8.235325813293457\n",
      "Training step  3169  of  100000  with loss  9.378799438476562\n",
      "Training step  3170  of  100000  with loss  9.370122909545898\n",
      "Training step  3171  of  100000  with loss  11.052325248718262\n",
      "Training step  3172  of  100000  with loss  9.98232364654541\n",
      "Training step  3173  of  100000  with loss  10.185405731201172\n",
      "Training step  3174  of  100000  with loss  10.281972885131836\n",
      "Training step  3175  of  100000  with loss  10.229490280151367\n",
      "Training step  3176  of  100000  with loss  10.282958030700684\n",
      "Training step  3177  of  100000  with loss  9.839351654052734\n",
      "Training step  3178  of  100000  with loss  9.613248825073242\n",
      "Training step  3179  of  100000  with loss  10.858429908752441\n",
      "Training step  3180  of  100000  with loss  9.201555252075195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3181  of  100000  with loss  9.8892183303833\n",
      "Training step  3182  of  100000  with loss  9.969818115234375\n",
      "Training step  3183  of  100000  with loss  10.675642967224121\n",
      "Training step  3184  of  100000  with loss  9.34085464477539\n",
      "Training step  3185  of  100000  with loss  11.244318008422852\n",
      "Training step  3186  of  100000  with loss  10.684137344360352\n",
      "Training step  3187  of  100000  with loss  11.574919700622559\n",
      "Training step  3188  of  100000  with loss  9.985501289367676\n",
      "Training step  3189  of  100000  with loss  9.977524757385254\n",
      "Training step  3190  of  100000  with loss  11.684659957885742\n",
      "Training step  3191  of  100000  with loss  11.977429389953613\n",
      "Training step  3192  of  100000  with loss  9.799397468566895\n",
      "Training step  3193  of  100000  with loss  10.310285568237305\n",
      "Training step  3194  of  100000  with loss  9.32497501373291\n",
      "Training step  3195  of  100000  with loss  9.250008583068848\n",
      "Training step  3196  of  100000  with loss  10.646076202392578\n",
      "Training step  3197  of  100000  with loss  9.653501510620117\n",
      "Training step  3198  of  100000  with loss  9.171550750732422\n",
      "Training step  3199  of  100000  with loss  10.379995346069336\n",
      "Training step  3200  of  100000  with loss  8.574851989746094\n",
      "Training step  3201  of  100000  with loss  9.585454940795898\n",
      "Training step  3202  of  100000  with loss  9.616260528564453\n",
      "Training step  3203  of  100000  with loss  9.319219589233398\n",
      "Training step  3204  of  100000  with loss  10.527758598327637\n",
      "Training step  3205  of  100000  with loss  10.023698806762695\n",
      "Training step  3206  of  100000  with loss  11.046844482421875\n",
      "Training step  3207  of  100000  with loss  9.84066390991211\n",
      "Training step  3208  of  100000  with loss  10.770845413208008\n",
      "Training step  3209  of  100000  with loss  10.665332794189453\n",
      "Training step  3210  of  100000  with loss  10.303839683532715\n",
      "Training step  3211  of  100000  with loss  9.727134704589844\n",
      "Training step  3212  of  100000  with loss  10.097932815551758\n",
      "Training step  3213  of  100000  with loss  10.25736141204834\n",
      "Training step  3214  of  100000  with loss  9.965410232543945\n",
      "Training step  3215  of  100000  with loss  10.01690673828125\n",
      "Training step  3216  of  100000  with loss  9.189167022705078\n",
      "Training step  3217  of  100000  with loss  10.199636459350586\n",
      "Training step  3218  of  100000  with loss  9.908099174499512\n",
      "Training step  3219  of  100000  with loss  9.162395477294922\n",
      "Training step  3220  of  100000  with loss  9.925198554992676\n",
      "Training step  3221  of  100000  with loss  9.505363464355469\n",
      "Training step  3222  of  100000  with loss  10.950178146362305\n",
      "Training step  3223  of  100000  with loss  8.863971710205078\n",
      "Training step  3224  of  100000  with loss  9.155941009521484\n",
      "Training step  3225  of  100000  with loss  10.84289836883545\n",
      "Training step  3226  of  100000  with loss  10.344701766967773\n",
      "Training step  3227  of  100000  with loss  9.275907516479492\n",
      "Training step  3228  of  100000  with loss  9.048738479614258\n",
      "Training step  3229  of  100000  with loss  11.300865173339844\n",
      "Training step  3230  of  100000  with loss  9.874762535095215\n",
      "Training step  3231  of  100000  with loss  11.36140251159668\n",
      "Training step  3232  of  100000  with loss  10.0881986618042\n",
      "Training step  3233  of  100000  with loss  10.20236587524414\n",
      "Training step  3234  of  100000  with loss  9.334573745727539\n",
      "Training step  3235  of  100000  with loss  8.743143081665039\n",
      "Training step  3236  of  100000  with loss  10.719162940979004\n",
      "Training step  3237  of  100000  with loss  9.981839179992676\n",
      "Training step  3238  of  100000  with loss  10.241199493408203\n",
      "Training step  3239  of  100000  with loss  9.76358413696289\n",
      "Training step  3240  of  100000  with loss  10.80750560760498\n",
      "Training step  3241  of  100000  with loss  11.634971618652344\n",
      "Training step  3242  of  100000  with loss  9.488723754882812\n",
      "Training step  3243  of  100000  with loss  9.291866302490234\n",
      "Training step  3244  of  100000  with loss  10.36622428894043\n",
      "Training step  3245  of  100000  with loss  12.245631217956543\n",
      "Training step  3246  of  100000  with loss  11.21672534942627\n",
      "Training step  3247  of  100000  with loss  9.854555130004883\n",
      "Training step  3248  of  100000  with loss  9.839578628540039\n",
      "Training step  3249  of  100000  with loss  9.116968154907227\n",
      "Training step  3250  of  100000  with loss  9.300633430480957\n",
      "Training step  3251  of  100000  with loss  9.759624481201172\n",
      "Training step  3252  of  100000  with loss  10.394159317016602\n",
      "Training step  3253  of  100000  with loss  11.754011154174805\n",
      "Training step  3254  of  100000  with loss  10.962345123291016\n",
      "Training step  3255  of  100000  with loss  9.458974838256836\n",
      "Training step  3256  of  100000  with loss  9.49081039428711\n",
      "Training step  3257  of  100000  with loss  10.637361526489258\n",
      "Training step  3258  of  100000  with loss  10.549946784973145\n",
      "Training step  3259  of  100000  with loss  10.67717170715332\n",
      "Training step  3260  of  100000  with loss  11.035135269165039\n",
      "Training step  3261  of  100000  with loss  9.618032455444336\n",
      "Training step  3262  of  100000  with loss  9.596683502197266\n",
      "Training step  3263  of  100000  with loss  10.303062438964844\n",
      "Training step  3264  of  100000  with loss  9.380067825317383\n",
      "Training step  3265  of  100000  with loss  9.560239791870117\n",
      "Training step  3266  of  100000  with loss  9.680421829223633\n",
      "Training step  3267  of  100000  with loss  9.874265670776367\n",
      "Training step  3268  of  100000  with loss  9.88618278503418\n",
      "Training step  3269  of  100000  with loss  10.639060020446777\n",
      "Training step  3270  of  100000  with loss  8.953022003173828\n",
      "Training step  3271  of  100000  with loss  10.581303596496582\n",
      "Training step  3272  of  100000  with loss  10.973743438720703\n",
      "Training step  3273  of  100000  with loss  9.970865249633789\n",
      "Training step  3274  of  100000  with loss  10.299501419067383\n",
      "Training step  3275  of  100000  with loss  9.77606201171875\n",
      "Training step  3276  of  100000  with loss  8.980327606201172\n",
      "Training step  3277  of  100000  with loss  8.8041410446167\n",
      "Training step  3278  of  100000  with loss  11.440813064575195\n",
      "Training step  3279  of  100000  with loss  8.796831130981445\n",
      "Training step  3280  of  100000  with loss  9.267166137695312\n",
      "Training step  3281  of  100000  with loss  11.485857963562012\n",
      "Training step  3282  of  100000  with loss  10.029281616210938\n",
      "Training step  3283  of  100000  with loss  9.494516372680664\n",
      "Training step  3284  of  100000  with loss  10.38425350189209\n",
      "Training step  3285  of  100000  with loss  10.610248565673828\n",
      "Training step  3286  of  100000  with loss  9.770532608032227\n",
      "Training step  3287  of  100000  with loss  10.677902221679688\n",
      "Training step  3288  of  100000  with loss  9.19108772277832\n",
      "Training step  3289  of  100000  with loss  11.119549751281738\n",
      "Training step  3290  of  100000  with loss  12.406404495239258\n",
      "Training step  3291  of  100000  with loss  10.391589164733887\n",
      "Training step  3292  of  100000  with loss  8.966073036193848\n",
      "Training step  3293  of  100000  with loss  10.017112731933594\n",
      "Training step  3294  of  100000  with loss  9.88724136352539\n",
      "Training step  3295  of  100000  with loss  8.921917915344238\n",
      "Training step  3296  of  100000  with loss  10.188735961914062\n",
      "Training step  3297  of  100000  with loss  9.933603286743164\n",
      "Training step  3298  of  100000  with loss  10.270520210266113\n",
      "Training step  3299  of  100000  with loss  8.873394012451172\n",
      "Training step  3300  of  100000  with loss  9.074317932128906\n",
      "Training step  3301  of  100000  with loss  10.003986358642578\n",
      "Training step  3302  of  100000  with loss  9.081958770751953\n",
      "Training step  3303  of  100000  with loss  10.862960815429688\n",
      "Training step  3304  of  100000  with loss  9.554841995239258\n",
      "Training step  3305  of  100000  with loss  10.412747383117676\n",
      "Training step  3306  of  100000  with loss  10.966917991638184\n",
      "Training step  3307  of  100000  with loss  10.424373626708984\n",
      "Training step  3308  of  100000  with loss  9.365044593811035\n",
      "Training step  3309  of  100000  with loss  9.42445182800293\n",
      "Training step  3310  of  100000  with loss  10.455615043640137\n",
      "Training step  3311  of  100000  with loss  12.386504173278809\n",
      "Training step  3312  of  100000  with loss  10.195291519165039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3313  of  100000  with loss  9.988823890686035\n",
      "Training step  3314  of  100000  with loss  8.901632308959961\n",
      "Training step  3315  of  100000  with loss  8.120858192443848\n",
      "Training step  3316  of  100000  with loss  9.267616271972656\n",
      "Training step  3317  of  100000  with loss  8.61875057220459\n",
      "Training step  3318  of  100000  with loss  9.327774047851562\n",
      "Training step  3319  of  100000  with loss  9.456277847290039\n",
      "Training step  3320  of  100000  with loss  10.30123519897461\n",
      "Training step  3321  of  100000  with loss  9.338744163513184\n",
      "Training step  3322  of  100000  with loss  9.215601921081543\n",
      "Training step  3323  of  100000  with loss  9.452301979064941\n",
      "Training step  3324  of  100000  with loss  8.786307334899902\n",
      "Training step  3325  of  100000  with loss  10.189471244812012\n",
      "Training step  3326  of  100000  with loss  10.751441955566406\n",
      "Training step  3327  of  100000  with loss  11.043191909790039\n",
      "Training step  3328  of  100000  with loss  9.369263648986816\n",
      "Training step  3329  of  100000  with loss  10.553995132446289\n",
      "Training step  3330  of  100000  with loss  10.341293334960938\n",
      "Training step  3331  of  100000  with loss  9.557655334472656\n",
      "Training step  3332  of  100000  with loss  8.933732986450195\n",
      "Training step  3333  of  100000  with loss  10.692474365234375\n",
      "Training step  3334  of  100000  with loss  11.545473098754883\n",
      "Training step  3335  of  100000  with loss  8.833024978637695\n",
      "Training step  3336  of  100000  with loss  10.986883163452148\n",
      "Training step  3337  of  100000  with loss  10.659961700439453\n",
      "Training step  3338  of  100000  with loss  9.510258674621582\n",
      "Training step  3339  of  100000  with loss  9.11607837677002\n",
      "Training step  3340  of  100000  with loss  11.065762519836426\n",
      "Training step  3341  of  100000  with loss  9.1162109375\n",
      "Training step  3342  of  100000  with loss  9.32089614868164\n",
      "Training step  3343  of  100000  with loss  9.909585952758789\n",
      "Training step  3344  of  100000  with loss  9.770670890808105\n",
      "Training step  3345  of  100000  with loss  9.962018966674805\n",
      "Training step  3346  of  100000  with loss  9.853168487548828\n",
      "Training step  3347  of  100000  with loss  9.465181350708008\n",
      "Training step  3348  of  100000  with loss  10.578944206237793\n",
      "Training step  3349  of  100000  with loss  9.86151123046875\n",
      "Training step  3350  of  100000  with loss  9.084747314453125\n",
      "Training step  3351  of  100000  with loss  9.77161693572998\n",
      "Training step  3352  of  100000  with loss  9.298286437988281\n",
      "Training step  3353  of  100000  with loss  10.06182861328125\n",
      "Training step  3354  of  100000  with loss  9.338908195495605\n",
      "Training step  3355  of  100000  with loss  9.596132278442383\n",
      "Training step  3356  of  100000  with loss  10.902215003967285\n",
      "Training step  3357  of  100000  with loss  10.866181373596191\n",
      "Training step  3358  of  100000  with loss  9.767387390136719\n",
      "Training step  3359  of  100000  with loss  9.126632690429688\n",
      "Training step  3360  of  100000  with loss  9.687973976135254\n",
      "Training step  3361  of  100000  with loss  9.62310791015625\n",
      "Training step  3362  of  100000  with loss  9.866758346557617\n",
      "Training step  3363  of  100000  with loss  11.91856861114502\n",
      "Training step  3364  of  100000  with loss  9.578926086425781\n",
      "Training step  3365  of  100000  with loss  9.506772994995117\n",
      "Training step  3366  of  100000  with loss  10.381538391113281\n",
      "Training step  3367  of  100000  with loss  9.802581787109375\n",
      "Training step  3368  of  100000  with loss  12.119205474853516\n",
      "Training step  3369  of  100000  with loss  9.465784072875977\n",
      "Training step  3370  of  100000  with loss  10.83588695526123\n",
      "Training step  3371  of  100000  with loss  9.987218856811523\n",
      "Training step  3372  of  100000  with loss  9.278526306152344\n",
      "Training step  3373  of  100000  with loss  9.429664611816406\n",
      "Training step  3374  of  100000  with loss  9.870138168334961\n",
      "Training step  3375  of  100000  with loss  10.312551498413086\n",
      "Training step  3376  of  100000  with loss  10.006452560424805\n",
      "Training step  3377  of  100000  with loss  10.527626037597656\n",
      "Training step  3378  of  100000  with loss  10.632564544677734\n",
      "Training step  3379  of  100000  with loss  8.63011646270752\n",
      "Training step  3380  of  100000  with loss  10.153946876525879\n",
      "Training step  3381  of  100000  with loss  8.875365257263184\n",
      "Training step  3382  of  100000  with loss  10.670232772827148\n",
      "Training step  3383  of  100000  with loss  9.994786262512207\n",
      "Training step  3384  of  100000  with loss  10.218729019165039\n",
      "Training step  3385  of  100000  with loss  9.860910415649414\n",
      "Training step  3386  of  100000  with loss  9.777491569519043\n",
      "Training step  3387  of  100000  with loss  9.22262954711914\n",
      "Training step  3388  of  100000  with loss  9.585958480834961\n",
      "Training step  3389  of  100000  with loss  10.09648323059082\n",
      "Training step  3390  of  100000  with loss  10.929622650146484\n",
      "Training step  3391  of  100000  with loss  9.058011054992676\n",
      "Training step  3392  of  100000  with loss  10.454802513122559\n",
      "Training step  3393  of  100000  with loss  9.441080093383789\n",
      "Training step  3394  of  100000  with loss  11.66008186340332\n",
      "Training step  3395  of  100000  with loss  9.75832462310791\n",
      "Training step  3396  of  100000  with loss  9.207107543945312\n",
      "Training step  3397  of  100000  with loss  8.981236457824707\n",
      "Training step  3398  of  100000  with loss  11.321369171142578\n",
      "Training step  3399  of  100000  with loss  9.245466232299805\n",
      "Training step  3400  of  100000  with loss  9.936031341552734\n",
      "Training step  3401  of  100000  with loss  8.816736221313477\n",
      "Training step  3402  of  100000  with loss  9.58424186706543\n",
      "Training step  3403  of  100000  with loss  9.259199142456055\n",
      "Training step  3404  of  100000  with loss  12.609169960021973\n",
      "Training step  3405  of  100000  with loss  9.86357593536377\n",
      "Training step  3406  of  100000  with loss  9.066720962524414\n",
      "Training step  3407  of  100000  with loss  9.114437103271484\n",
      "Training step  3408  of  100000  with loss  9.965601921081543\n",
      "Training step  3409  of  100000  with loss  11.485276222229004\n",
      "Training step  3410  of  100000  with loss  10.259437561035156\n",
      "Training step  3411  of  100000  with loss  10.161676406860352\n",
      "Training step  3412  of  100000  with loss  10.521263122558594\n",
      "Training step  3413  of  100000  with loss  11.235237121582031\n",
      "Training step  3414  of  100000  with loss  9.717366218566895\n",
      "Training step  3415  of  100000  with loss  10.847283363342285\n",
      "Training step  3416  of  100000  with loss  12.14565372467041\n",
      "Training step  3417  of  100000  with loss  10.301414489746094\n",
      "Training step  3418  of  100000  with loss  9.417648315429688\n",
      "Training step  3419  of  100000  with loss  9.848304748535156\n",
      "Training step  3420  of  100000  with loss  10.319788932800293\n",
      "Training step  3421  of  100000  with loss  9.4249849319458\n",
      "Training step  3422  of  100000  with loss  9.585651397705078\n",
      "Training step  3423  of  100000  with loss  10.22338581085205\n",
      "Training step  3424  of  100000  with loss  9.083402633666992\n",
      "Training step  3425  of  100000  with loss  11.331062316894531\n",
      "Training step  3426  of  100000  with loss  10.488826751708984\n",
      "Training step  3427  of  100000  with loss  10.41557788848877\n",
      "Training step  3428  of  100000  with loss  9.75870132446289\n",
      "Training step  3429  of  100000  with loss  10.992504119873047\n",
      "Training step  3430  of  100000  with loss  11.640050888061523\n",
      "Training step  3431  of  100000  with loss  9.34580135345459\n",
      "Training step  3432  of  100000  with loss  10.462303161621094\n",
      "Training step  3433  of  100000  with loss  11.781484603881836\n",
      "Training step  3434  of  100000  with loss  11.964853286743164\n",
      "Training step  3435  of  100000  with loss  9.486001968383789\n",
      "Training step  3436  of  100000  with loss  9.681392669677734\n",
      "Training step  3437  of  100000  with loss  9.840752601623535\n",
      "Training step  3438  of  100000  with loss  10.293046951293945\n",
      "Training step  3439  of  100000  with loss  9.892033576965332\n",
      "Training step  3440  of  100000  with loss  9.555113792419434\n",
      "Training step  3441  of  100000  with loss  9.37639045715332\n",
      "Training step  3442  of  100000  with loss  10.168733596801758\n",
      "Training step  3443  of  100000  with loss  9.06367015838623\n",
      "Training step  3444  of  100000  with loss  10.4539794921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3445  of  100000  with loss  9.501593589782715\n",
      "Training step  3446  of  100000  with loss  9.917070388793945\n",
      "Training step  3447  of  100000  with loss  10.812493324279785\n",
      "Training step  3448  of  100000  with loss  9.52442455291748\n",
      "Training step  3449  of  100000  with loss  8.557849884033203\n",
      "Training step  3450  of  100000  with loss  10.464603424072266\n",
      "Training step  3451  of  100000  with loss  10.089045524597168\n",
      "Training step  3452  of  100000  with loss  9.966117858886719\n",
      "Training step  3453  of  100000  with loss  11.077342987060547\n",
      "Training step  3454  of  100000  with loss  10.51248550415039\n",
      "Training step  3455  of  100000  with loss  10.606593132019043\n",
      "Training step  3456  of  100000  with loss  10.25108814239502\n",
      "Training step  3457  of  100000  with loss  9.163875579833984\n",
      "Training step  3458  of  100000  with loss  11.91806411743164\n",
      "Training step  3459  of  100000  with loss  8.540624618530273\n",
      "Training step  3460  of  100000  with loss  10.507732391357422\n",
      "Training step  3461  of  100000  with loss  9.455133438110352\n",
      "Training step  3462  of  100000  with loss  9.462484359741211\n",
      "Training step  3463  of  100000  with loss  8.995996475219727\n",
      "Training step  3464  of  100000  with loss  8.597393035888672\n",
      "Training step  3465  of  100000  with loss  11.820751190185547\n",
      "Training step  3466  of  100000  with loss  10.504568099975586\n",
      "Training step  3467  of  100000  with loss  8.809011459350586\n",
      "Training step  3468  of  100000  with loss  10.541115760803223\n",
      "Training step  3469  of  100000  with loss  10.358999252319336\n",
      "Training step  3470  of  100000  with loss  9.787972450256348\n",
      "Training step  3471  of  100000  with loss  10.028675079345703\n",
      "Training step  3472  of  100000  with loss  9.695273399353027\n",
      "Training step  3473  of  100000  with loss  9.687690734863281\n",
      "Training step  3474  of  100000  with loss  9.835692405700684\n",
      "Training step  3475  of  100000  with loss  10.787996292114258\n",
      "Training step  3476  of  100000  with loss  10.615313529968262\n",
      "Training step  3477  of  100000  with loss  9.997085571289062\n",
      "Training step  3478  of  100000  with loss  9.275777816772461\n",
      "Training step  3479  of  100000  with loss  10.050287246704102\n",
      "Training step  3480  of  100000  with loss  10.059836387634277\n",
      "Training step  3481  of  100000  with loss  9.09595012664795\n",
      "Training step  3482  of  100000  with loss  10.41137981414795\n",
      "Training step  3483  of  100000  with loss  11.260891914367676\n",
      "Training step  3484  of  100000  with loss  12.178486824035645\n",
      "Training step  3485  of  100000  with loss  9.072701454162598\n",
      "Training step  3486  of  100000  with loss  9.71536636352539\n",
      "Training step  3487  of  100000  with loss  9.656970977783203\n",
      "Training step  3488  of  100000  with loss  9.292218208312988\n",
      "Training step  3489  of  100000  with loss  11.111601829528809\n",
      "Training step  3490  of  100000  with loss  9.45338249206543\n",
      "Training step  3491  of  100000  with loss  9.379011154174805\n",
      "Training step  3492  of  100000  with loss  8.555179595947266\n",
      "Training step  3493  of  100000  with loss  10.837635040283203\n",
      "Training step  3494  of  100000  with loss  8.949193954467773\n",
      "Training step  3495  of  100000  with loss  9.087576866149902\n",
      "Training step  3496  of  100000  with loss  9.726216316223145\n",
      "Training step  3497  of  100000  with loss  9.087337493896484\n",
      "Training step  3498  of  100000  with loss  9.125860214233398\n",
      "Training step  3499  of  100000  with loss  9.076105117797852\n",
      "Training step  3500  of  100000  with loss  10.15329360961914\n",
      "Training step  3501  of  100000  with loss  9.35369873046875\n",
      "Training step  3502  of  100000  with loss  9.897270202636719\n",
      "Training step  3503  of  100000  with loss  9.919108390808105\n",
      "Training step  3504  of  100000  with loss  8.37533187866211\n",
      "Training step  3505  of  100000  with loss  9.639518737792969\n",
      "Training step  3506  of  100000  with loss  9.953978538513184\n",
      "Training step  3507  of  100000  with loss  9.589544296264648\n",
      "Training step  3508  of  100000  with loss  10.170340538024902\n",
      "Training step  3509  of  100000  with loss  10.64989948272705\n",
      "Training step  3510  of  100000  with loss  8.780059814453125\n",
      "Training step  3511  of  100000  with loss  9.334566116333008\n",
      "Training step  3512  of  100000  with loss  9.681354522705078\n",
      "Training step  3513  of  100000  with loss  11.371110916137695\n",
      "Training step  3514  of  100000  with loss  10.38484001159668\n",
      "Training step  3515  of  100000  with loss  9.615428924560547\n",
      "Training step  3516  of  100000  with loss  10.259103775024414\n",
      "Training step  3517  of  100000  with loss  9.09493350982666\n",
      "Training step  3518  of  100000  with loss  11.003063201904297\n",
      "Training step  3519  of  100000  with loss  9.732902526855469\n",
      "Training step  3520  of  100000  with loss  9.372781753540039\n",
      "Training step  3521  of  100000  with loss  10.252791404724121\n",
      "Training step  3522  of  100000  with loss  10.92786979675293\n",
      "Training step  3523  of  100000  with loss  9.39670181274414\n",
      "Training step  3524  of  100000  with loss  9.633723258972168\n",
      "Training step  3525  of  100000  with loss  10.06028938293457\n",
      "Training step  3526  of  100000  with loss  10.169943809509277\n",
      "Training step  3527  of  100000  with loss  10.450142860412598\n",
      "Training step  3528  of  100000  with loss  9.324756622314453\n",
      "Training step  3529  of  100000  with loss  10.242110252380371\n",
      "Training step  3530  of  100000  with loss  9.582552909851074\n",
      "Training step  3531  of  100000  with loss  10.294889450073242\n",
      "Training step  3532  of  100000  with loss  10.649288177490234\n",
      "Training step  3533  of  100000  with loss  9.491823196411133\n",
      "Training step  3534  of  100000  with loss  10.037872314453125\n",
      "Training step  3535  of  100000  with loss  10.935132026672363\n",
      "Training step  3536  of  100000  with loss  10.88368034362793\n",
      "Training step  3537  of  100000  with loss  10.841123580932617\n",
      "Training step  3538  of  100000  with loss  10.711532592773438\n",
      "Training step  3539  of  100000  with loss  10.631576538085938\n",
      "Training step  3540  of  100000  with loss  10.366142272949219\n",
      "Training step  3541  of  100000  with loss  10.003185272216797\n",
      "Training step  3542  of  100000  with loss  8.739518165588379\n",
      "Training step  3543  of  100000  with loss  9.194438934326172\n",
      "Training step  3544  of  100000  with loss  9.128824234008789\n",
      "Training step  3545  of  100000  with loss  9.608643531799316\n",
      "Training step  3546  of  100000  with loss  12.691614151000977\n",
      "Training step  3547  of  100000  with loss  9.85519027709961\n",
      "Training step  3548  of  100000  with loss  9.846548080444336\n",
      "Training step  3549  of  100000  with loss  9.771507263183594\n",
      "Training step  3550  of  100000  with loss  10.709554672241211\n",
      "Training step  3551  of  100000  with loss  8.709653854370117\n",
      "Training step  3552  of  100000  with loss  8.980627059936523\n",
      "Training step  3553  of  100000  with loss  10.767108917236328\n",
      "Training step  3554  of  100000  with loss  8.777132034301758\n",
      "Training step  3555  of  100000  with loss  9.392789840698242\n",
      "Training step  3556  of  100000  with loss  9.774152755737305\n",
      "Training step  3557  of  100000  with loss  9.711174011230469\n",
      "Training step  3558  of  100000  with loss  9.526738166809082\n",
      "Training step  3559  of  100000  with loss  10.620285034179688\n",
      "Training step  3560  of  100000  with loss  9.202890396118164\n",
      "Training step  3561  of  100000  with loss  9.821651458740234\n",
      "Training step  3562  of  100000  with loss  10.762496948242188\n",
      "Training step  3563  of  100000  with loss  8.928757667541504\n",
      "Training step  3564  of  100000  with loss  9.481531143188477\n",
      "Training step  3565  of  100000  with loss  8.969762802124023\n",
      "Training step  3566  of  100000  with loss  9.443580627441406\n",
      "Training step  3567  of  100000  with loss  8.823049545288086\n",
      "Training step  3568  of  100000  with loss  9.101056098937988\n",
      "Training step  3569  of  100000  with loss  10.560850143432617\n",
      "Training step  3570  of  100000  with loss  9.28004264831543\n",
      "Training step  3571  of  100000  with loss  8.811258316040039\n",
      "Training step  3572  of  100000  with loss  9.37373161315918\n",
      "Training step  3573  of  100000  with loss  10.156641960144043\n",
      "Training step  3574  of  100000  with loss  10.433699607849121\n",
      "Training step  3575  of  100000  with loss  9.129836082458496\n",
      "Training step  3576  of  100000  with loss  10.58328628540039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3577  of  100000  with loss  9.515833854675293\n",
      "Training step  3578  of  100000  with loss  10.856548309326172\n",
      "Training step  3579  of  100000  with loss  10.293048858642578\n",
      "Training step  3580  of  100000  with loss  10.536017417907715\n",
      "Training step  3581  of  100000  with loss  10.127586364746094\n",
      "Training step  3582  of  100000  with loss  10.274580001831055\n",
      "Training step  3583  of  100000  with loss  9.692499160766602\n",
      "Training step  3584  of  100000  with loss  10.410116195678711\n",
      "Training step  3585  of  100000  with loss  11.311595916748047\n",
      "Training step  3586  of  100000  with loss  10.525550842285156\n",
      "Training step  3587  of  100000  with loss  11.354341506958008\n",
      "Training step  3588  of  100000  with loss  9.470990180969238\n",
      "Training step  3589  of  100000  with loss  9.111504554748535\n",
      "Training step  3590  of  100000  with loss  10.382652282714844\n",
      "Training step  3591  of  100000  with loss  9.245660781860352\n",
      "Training step  3592  of  100000  with loss  10.524229049682617\n",
      "Training step  3593  of  100000  with loss  9.72775650024414\n",
      "Training step  3594  of  100000  with loss  9.73608684539795\n",
      "Training step  3595  of  100000  with loss  10.559144973754883\n",
      "Training step  3596  of  100000  with loss  10.728567123413086\n",
      "Training step  3597  of  100000  with loss  9.415299415588379\n",
      "Training step  3598  of  100000  with loss  11.023772239685059\n",
      "Training step  3599  of  100000  with loss  11.579444885253906\n",
      "Training step  3600  of  100000  with loss  9.907150268554688\n",
      "Training step  3601  of  100000  with loss  10.408876419067383\n",
      "Training step  3602  of  100000  with loss  9.926616668701172\n",
      "Training step  3603  of  100000  with loss  10.714605331420898\n",
      "Training step  3604  of  100000  with loss  8.879754066467285\n",
      "Training step  3605  of  100000  with loss  9.425910949707031\n",
      "Training step  3606  of  100000  with loss  10.923323631286621\n",
      "Training step  3607  of  100000  with loss  9.715967178344727\n",
      "Training step  3608  of  100000  with loss  9.284530639648438\n",
      "Training step  3609  of  100000  with loss  10.220745086669922\n",
      "Training step  3610  of  100000  with loss  9.478621482849121\n",
      "Training step  3611  of  100000  with loss  11.378459930419922\n",
      "Training step  3612  of  100000  with loss  10.209051132202148\n",
      "Training step  3613  of  100000  with loss  9.672279357910156\n",
      "Training step  3614  of  100000  with loss  12.333818435668945\n",
      "Training step  3615  of  100000  with loss  10.18840503692627\n",
      "Training step  3616  of  100000  with loss  10.667326927185059\n",
      "Training step  3617  of  100000  with loss  10.19272232055664\n",
      "Training step  3618  of  100000  with loss  9.599081993103027\n",
      "Training step  3619  of  100000  with loss  10.919137954711914\n",
      "Training step  3620  of  100000  with loss  9.371562957763672\n",
      "Training step  3621  of  100000  with loss  10.169448852539062\n",
      "Training step  3622  of  100000  with loss  9.747705459594727\n",
      "Training step  3623  of  100000  with loss  10.24329948425293\n",
      "Training step  3624  of  100000  with loss  10.495196342468262\n",
      "Training step  3625  of  100000  with loss  9.300596237182617\n",
      "Training step  3626  of  100000  with loss  9.811033248901367\n",
      "Training step  3627  of  100000  with loss  11.383275032043457\n",
      "Training step  3628  of  100000  with loss  9.187389373779297\n",
      "Training step  3629  of  100000  with loss  10.875846862792969\n",
      "Training step  3630  of  100000  with loss  9.192195892333984\n",
      "Training step  3631  of  100000  with loss  9.612525939941406\n",
      "Training step  3632  of  100000  with loss  8.761856079101562\n",
      "Training step  3633  of  100000  with loss  11.005489349365234\n",
      "Training step  3634  of  100000  with loss  9.590715408325195\n",
      "Training step  3635  of  100000  with loss  11.447978019714355\n",
      "Training step  3636  of  100000  with loss  9.433856964111328\n",
      "Training step  3637  of  100000  with loss  11.750404357910156\n",
      "Training step  3638  of  100000  with loss  9.918049812316895\n",
      "Training step  3639  of  100000  with loss  8.718416213989258\n",
      "Training step  3640  of  100000  with loss  8.845991134643555\n",
      "Training step  3641  of  100000  with loss  11.779518127441406\n",
      "Training step  3642  of  100000  with loss  8.664190292358398\n",
      "Training step  3643  of  100000  with loss  11.348376274108887\n",
      "Training step  3644  of  100000  with loss  10.050498962402344\n",
      "Training step  3645  of  100000  with loss  7.987323760986328\n",
      "Saving checkpoints\n",
      "Training step  3646  of  100000  with loss  9.169661521911621\n",
      "Training step  3647  of  100000  with loss  10.722286224365234\n",
      "Training step  3648  of  100000  with loss  9.675453186035156\n",
      "Training step  3649  of  100000  with loss  9.710262298583984\n",
      "Training step  3650  of  100000  with loss  10.550203323364258\n",
      "Training step  3651  of  100000  with loss  11.42228889465332\n",
      "Training step  3652  of  100000  with loss  9.045873641967773\n",
      "Training step  3653  of  100000  with loss  10.645145416259766\n",
      "Training step  3654  of  100000  with loss  8.85869026184082\n",
      "Training step  3655  of  100000  with loss  9.259909629821777\n",
      "Training step  3656  of  100000  with loss  10.105124473571777\n",
      "Training step  3657  of  100000  with loss  9.34986686706543\n",
      "Training step  3658  of  100000  with loss  10.475265502929688\n",
      "Training step  3659  of  100000  with loss  8.218246459960938\n",
      "Training step  3660  of  100000  with loss  9.01180362701416\n",
      "Training step  3661  of  100000  with loss  10.024165153503418\n",
      "Training step  3662  of  100000  with loss  8.9686918258667\n",
      "Training step  3663  of  100000  with loss  9.593658447265625\n",
      "Training step  3664  of  100000  with loss  9.497139930725098\n",
      "Training step  3665  of  100000  with loss  11.305472373962402\n",
      "Training step  3666  of  100000  with loss  9.486539840698242\n",
      "Training step  3667  of  100000  with loss  10.737223625183105\n",
      "Training step  3668  of  100000  with loss  10.133861541748047\n",
      "Training step  3669  of  100000  with loss  10.50036334991455\n",
      "Training step  3670  of  100000  with loss  10.275056838989258\n",
      "Training step  3671  of  100000  with loss  10.01739501953125\n",
      "Training step  3672  of  100000  with loss  10.515803337097168\n",
      "Training step  3673  of  100000  with loss  9.706119537353516\n",
      "Training step  3674  of  100000  with loss  9.107297897338867\n",
      "Training step  3675  of  100000  with loss  9.765680313110352\n",
      "Training step  3676  of  100000  with loss  11.574947357177734\n",
      "Training step  3677  of  100000  with loss  8.594310760498047\n",
      "Training step  3678  of  100000  with loss  9.969400405883789\n",
      "Training step  3679  of  100000  with loss  9.96160888671875\n",
      "Training step  3680  of  100000  with loss  9.215824127197266\n",
      "Training step  3681  of  100000  with loss  8.83814811706543\n",
      "Training step  3682  of  100000  with loss  10.160451889038086\n",
      "Training step  3683  of  100000  with loss  10.507549285888672\n",
      "Training step  3684  of  100000  with loss  10.33637809753418\n",
      "Training step  3685  of  100000  with loss  9.646137237548828\n",
      "Training step  3686  of  100000  with loss  10.365577697753906\n",
      "Training step  3687  of  100000  with loss  10.995677947998047\n",
      "Training step  3688  of  100000  with loss  10.155378341674805\n",
      "Training step  3689  of  100000  with loss  8.004964828491211\n",
      "Training step  3690  of  100000  with loss  10.575464248657227\n",
      "Training step  3691  of  100000  with loss  11.522542953491211\n",
      "Training step  3692  of  100000  with loss  11.409235954284668\n",
      "Training step  3693  of  100000  with loss  8.936951637268066\n",
      "Training step  3694  of  100000  with loss  9.955060005187988\n",
      "Training step  3695  of  100000  with loss  10.739897727966309\n",
      "Training step  3696  of  100000  with loss  9.289762496948242\n",
      "Training step  3697  of  100000  with loss  8.855015754699707\n",
      "Training step  3698  of  100000  with loss  9.143638610839844\n",
      "Training step  3699  of  100000  with loss  9.080350875854492\n",
      "Training step  3700  of  100000  with loss  9.5715913772583\n",
      "Training step  3701  of  100000  with loss  9.396217346191406\n",
      "Training step  3702  of  100000  with loss  11.137138366699219\n",
      "Training step  3703  of  100000  with loss  8.954675674438477\n",
      "Training step  3704  of  100000  with loss  10.497282028198242\n",
      "Training step  3705  of  100000  with loss  9.610591888427734\n",
      "Training step  3706  of  100000  with loss  8.84312915802002\n",
      "Training step  3707  of  100000  with loss  10.12942886352539\n",
      "Training step  3708  of  100000  with loss  8.73221206665039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3709  of  100000  with loss  8.866682052612305\n",
      "Training step  3710  of  100000  with loss  8.980927467346191\n",
      "Training step  3711  of  100000  with loss  9.768611907958984\n",
      "Training step  3712  of  100000  with loss  9.34766674041748\n",
      "Training step  3713  of  100000  with loss  9.344255447387695\n",
      "Training step  3714  of  100000  with loss  10.704448699951172\n",
      "Training step  3715  of  100000  with loss  8.669291496276855\n",
      "Training step  3716  of  100000  with loss  10.579963684082031\n",
      "Training step  3717  of  100000  with loss  10.304195404052734\n",
      "Training step  3718  of  100000  with loss  9.94727611541748\n",
      "Training step  3719  of  100000  with loss  10.902936935424805\n",
      "Training step  3720  of  100000  with loss  9.390077590942383\n",
      "Training step  3721  of  100000  with loss  10.917532920837402\n",
      "Training step  3722  of  100000  with loss  10.426664352416992\n",
      "Training step  3723  of  100000  with loss  8.854978561401367\n",
      "Training step  3724  of  100000  with loss  9.699342727661133\n",
      "Training step  3725  of  100000  with loss  11.159887313842773\n",
      "Training step  3726  of  100000  with loss  12.77459716796875\n",
      "Training step  3727  of  100000  with loss  9.96860408782959\n",
      "Training step  3728  of  100000  with loss  11.638799667358398\n",
      "Training step  3729  of  100000  with loss  9.721186637878418\n",
      "Training step  3730  of  100000  with loss  9.540559768676758\n",
      "Training step  3731  of  100000  with loss  9.486227035522461\n",
      "Training step  3732  of  100000  with loss  9.637670516967773\n",
      "Training step  3733  of  100000  with loss  8.167337417602539\n",
      "Training step  3734  of  100000  with loss  9.582483291625977\n",
      "Training step  3735  of  100000  with loss  9.88643741607666\n",
      "Training step  3736  of  100000  with loss  10.479961395263672\n",
      "Training step  3737  of  100000  with loss  9.826780319213867\n",
      "Training step  3738  of  100000  with loss  9.72568416595459\n",
      "Training step  3739  of  100000  with loss  9.647714614868164\n",
      "Training step  3740  of  100000  with loss  10.036745071411133\n",
      "Training step  3741  of  100000  with loss  8.377180099487305\n",
      "Training step  3742  of  100000  with loss  9.16927719116211\n",
      "Training step  3743  of  100000  with loss  9.310471534729004\n",
      "Training step  3744  of  100000  with loss  11.390039443969727\n",
      "Training step  3745  of  100000  with loss  10.988611221313477\n",
      "Training step  3746  of  100000  with loss  9.325925827026367\n",
      "Training step  3747  of  100000  with loss  9.672187805175781\n",
      "Training step  3748  of  100000  with loss  10.504009246826172\n",
      "Training step  3749  of  100000  with loss  9.684133529663086\n",
      "Training step  3750  of  100000  with loss  10.514508247375488\n",
      "Training step  3751  of  100000  with loss  9.593685150146484\n",
      "Training step  3752  of  100000  with loss  10.178701400756836\n",
      "Training step  3753  of  100000  with loss  10.195475578308105\n",
      "Training step  3754  of  100000  with loss  10.344088554382324\n",
      "Training step  3755  of  100000  with loss  10.132458686828613\n",
      "Training step  3756  of  100000  with loss  10.078295707702637\n",
      "Training step  3757  of  100000  with loss  9.903338432312012\n",
      "Training step  3758  of  100000  with loss  9.59017562866211\n",
      "Training step  3759  of  100000  with loss  10.305591583251953\n",
      "Training step  3760  of  100000  with loss  9.675775527954102\n",
      "Training step  3761  of  100000  with loss  9.516716957092285\n",
      "Training step  3762  of  100000  with loss  9.64522933959961\n",
      "Training step  3763  of  100000  with loss  10.619234085083008\n",
      "Training step  3764  of  100000  with loss  9.535806655883789\n",
      "Training step  3765  of  100000  with loss  11.233116149902344\n",
      "Training step  3766  of  100000  with loss  9.842605590820312\n",
      "Training step  3767  of  100000  with loss  10.30221176147461\n",
      "Training step  3768  of  100000  with loss  8.291853904724121\n",
      "Training step  3769  of  100000  with loss  9.151639938354492\n",
      "Training step  3770  of  100000  with loss  10.476247787475586\n",
      "Training step  3771  of  100000  with loss  9.857755661010742\n",
      "Training step  3772  of  100000  with loss  9.361288070678711\n",
      "Training step  3773  of  100000  with loss  9.792444229125977\n",
      "Training step  3774  of  100000  with loss  9.866713523864746\n",
      "Training step  3775  of  100000  with loss  8.719362258911133\n",
      "Training step  3776  of  100000  with loss  10.871307373046875\n",
      "Training step  3777  of  100000  with loss  10.077465057373047\n",
      "Training step  3778  of  100000  with loss  9.578659057617188\n",
      "Training step  3779  of  100000  with loss  8.989044189453125\n",
      "Training step  3780  of  100000  with loss  10.0926513671875\n",
      "Training step  3781  of  100000  with loss  9.882400512695312\n",
      "Training step  3782  of  100000  with loss  8.818333625793457\n",
      "Training step  3783  of  100000  with loss  10.424360275268555\n",
      "Training step  3784  of  100000  with loss  10.538013458251953\n",
      "Training step  3785  of  100000  with loss  9.875847816467285\n",
      "Training step  3786  of  100000  with loss  11.52913761138916\n",
      "Training step  3787  of  100000  with loss  8.938260078430176\n",
      "Training step  3788  of  100000  with loss  8.258525848388672\n",
      "Training step  3789  of  100000  with loss  11.064416885375977\n",
      "Training step  3790  of  100000  with loss  10.73080825805664\n",
      "Training step  3791  of  100000  with loss  8.73393440246582\n",
      "Training step  3792  of  100000  with loss  9.84341812133789\n",
      "Training step  3793  of  100000  with loss  9.491582870483398\n",
      "Training step  3794  of  100000  with loss  8.627813339233398\n",
      "Training step  3795  of  100000  with loss  8.801970481872559\n",
      "Training step  3796  of  100000  with loss  9.768928527832031\n",
      "Training step  3797  of  100000  with loss  10.403868675231934\n",
      "Training step  3798  of  100000  with loss  9.424918174743652\n",
      "Training step  3799  of  100000  with loss  8.459467887878418\n",
      "Training step  3800  of  100000  with loss  9.439347267150879\n",
      "Training step  3801  of  100000  with loss  10.266267776489258\n",
      "Training step  3802  of  100000  with loss  10.421958923339844\n",
      "Training step  3803  of  100000  with loss  9.13364028930664\n",
      "Training step  3804  of  100000  with loss  10.21259880065918\n",
      "Training step  3805  of  100000  with loss  10.598350524902344\n",
      "Training step  3806  of  100000  with loss  10.148796081542969\n",
      "Training step  3807  of  100000  with loss  10.42294692993164\n",
      "Training step  3808  of  100000  with loss  11.096916198730469\n",
      "Training step  3809  of  100000  with loss  11.5143404006958\n",
      "Training step  3810  of  100000  with loss  11.169851303100586\n",
      "Training step  3811  of  100000  with loss  8.697931289672852\n",
      "Training step  3812  of  100000  with loss  8.293458938598633\n",
      "Training step  3813  of  100000  with loss  10.138235092163086\n",
      "Training step  3814  of  100000  with loss  10.598758697509766\n",
      "Training step  3815  of  100000  with loss  11.421510696411133\n",
      "Training step  3816  of  100000  with loss  9.545336723327637\n",
      "Training step  3817  of  100000  with loss  10.667377471923828\n",
      "Training step  3818  of  100000  with loss  9.264185905456543\n",
      "Training step  3819  of  100000  with loss  10.103445053100586\n",
      "Training step  3820  of  100000  with loss  11.566837310791016\n",
      "Training step  3821  of  100000  with loss  10.339082717895508\n",
      "Training step  3822  of  100000  with loss  10.986559867858887\n",
      "Training step  3823  of  100000  with loss  9.18548583984375\n",
      "Training step  3824  of  100000  with loss  9.744897842407227\n",
      "Training step  3825  of  100000  with loss  12.238191604614258\n",
      "Training step  3826  of  100000  with loss  10.552602767944336\n",
      "Training step  3827  of  100000  with loss  9.651874542236328\n",
      "Training step  3828  of  100000  with loss  10.386695861816406\n",
      "Training step  3829  of  100000  with loss  8.578741073608398\n",
      "Training step  3830  of  100000  with loss  8.588451385498047\n",
      "Training step  3831  of  100000  with loss  10.658905029296875\n",
      "Training step  3832  of  100000  with loss  9.137242317199707\n",
      "Training step  3833  of  100000  with loss  9.380515098571777\n",
      "Training step  3834  of  100000  with loss  10.291725158691406\n",
      "Training step  3835  of  100000  with loss  9.551923751831055\n",
      "Training step  3836  of  100000  with loss  10.518891334533691\n",
      "Training step  3837  of  100000  with loss  9.48399829864502\n",
      "Training step  3838  of  100000  with loss  9.849919319152832\n",
      "Training step  3839  of  100000  with loss  9.123262405395508\n",
      "Training step  3840  of  100000  with loss  8.999164581298828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3841  of  100000  with loss  9.813129425048828\n",
      "Training step  3842  of  100000  with loss  9.73382568359375\n",
      "Training step  3843  of  100000  with loss  9.626909255981445\n",
      "Training step  3844  of  100000  with loss  10.089483261108398\n",
      "Training step  3845  of  100000  with loss  9.11217975616455\n",
      "Training step  3846  of  100000  with loss  11.225665092468262\n",
      "Training step  3847  of  100000  with loss  9.5316162109375\n",
      "Training step  3848  of  100000  with loss  11.813288688659668\n",
      "Training step  3849  of  100000  with loss  11.477408409118652\n",
      "Training step  3850  of  100000  with loss  10.346416473388672\n",
      "Training step  3851  of  100000  with loss  10.134814262390137\n",
      "Training step  3852  of  100000  with loss  9.545352935791016\n",
      "Training step  3853  of  100000  with loss  9.218894958496094\n",
      "Training step  3854  of  100000  with loss  11.235976219177246\n",
      "Training step  3855  of  100000  with loss  9.57670783996582\n",
      "Training step  3856  of  100000  with loss  9.839370727539062\n",
      "Training step  3857  of  100000  with loss  9.866926193237305\n",
      "Training step  3858  of  100000  with loss  9.34390640258789\n",
      "Training step  3859  of  100000  with loss  9.540776252746582\n",
      "Training step  3860  of  100000  with loss  9.553378105163574\n",
      "Training step  3861  of  100000  with loss  10.763225555419922\n",
      "Training step  3862  of  100000  with loss  10.968986511230469\n",
      "Training step  3863  of  100000  with loss  10.35344409942627\n",
      "Training step  3864  of  100000  with loss  9.153600692749023\n",
      "Training step  3865  of  100000  with loss  10.556051254272461\n",
      "Training step  3866  of  100000  with loss  9.41364860534668\n",
      "Training step  3867  of  100000  with loss  10.364561080932617\n",
      "Training step  3868  of  100000  with loss  10.357508659362793\n",
      "Training step  3869  of  100000  with loss  11.55819320678711\n",
      "Training step  3870  of  100000  with loss  9.18889045715332\n",
      "Training step  3871  of  100000  with loss  10.254682540893555\n",
      "Training step  3872  of  100000  with loss  9.419261932373047\n",
      "Training step  3873  of  100000  with loss  10.452836990356445\n",
      "Training step  3874  of  100000  with loss  10.497265815734863\n",
      "Training step  3875  of  100000  with loss  9.14332389831543\n",
      "Training step  3876  of  100000  with loss  9.00564193725586\n",
      "Training step  3877  of  100000  with loss  10.638883590698242\n",
      "Training step  3878  of  100000  with loss  8.99881649017334\n",
      "Training step  3879  of  100000  with loss  9.675092697143555\n",
      "Training step  3880  of  100000  with loss  9.904735565185547\n",
      "Training step  3881  of  100000  with loss  9.100852966308594\n",
      "Training step  3882  of  100000  with loss  9.053131103515625\n",
      "Training step  3883  of  100000  with loss  11.864761352539062\n",
      "Training step  3884  of  100000  with loss  9.188972473144531\n",
      "Training step  3885  of  100000  with loss  10.727167129516602\n",
      "Training step  3886  of  100000  with loss  10.520963668823242\n",
      "Training step  3887  of  100000  with loss  9.414552688598633\n",
      "Training step  3888  of  100000  with loss  11.302860260009766\n",
      "Training step  3889  of  100000  with loss  9.876042366027832\n",
      "Training step  3890  of  100000  with loss  10.448439598083496\n",
      "Training step  3891  of  100000  with loss  9.593328475952148\n",
      "Training step  3892  of  100000  with loss  9.106878280639648\n",
      "Training step  3893  of  100000  with loss  9.332335472106934\n",
      "Training step  3894  of  100000  with loss  11.162552833557129\n",
      "Training step  3895  of  100000  with loss  10.188518524169922\n",
      "Training step  3896  of  100000  with loss  10.116230010986328\n",
      "Training step  3897  of  100000  with loss  11.51050853729248\n",
      "Training step  3898  of  100000  with loss  9.731613159179688\n",
      "Training step  3899  of  100000  with loss  9.907575607299805\n",
      "Training step  3900  of  100000  with loss  9.864570617675781\n",
      "Training step  3901  of  100000  with loss  9.896724700927734\n",
      "Training step  3902  of  100000  with loss  9.056474685668945\n",
      "Training step  3903  of  100000  with loss  9.809610366821289\n",
      "Training step  3904  of  100000  with loss  10.698915481567383\n",
      "Training step  3905  of  100000  with loss  9.427499771118164\n",
      "Training step  3906  of  100000  with loss  9.533821105957031\n",
      "Training step  3907  of  100000  with loss  10.597942352294922\n",
      "Training step  3908  of  100000  with loss  9.90650749206543\n",
      "Training step  3909  of  100000  with loss  10.53237247467041\n",
      "Training step  3910  of  100000  with loss  9.775823593139648\n",
      "Training step  3911  of  100000  with loss  9.482962608337402\n",
      "Training step  3912  of  100000  with loss  11.771573066711426\n",
      "Training step  3913  of  100000  with loss  10.756260871887207\n",
      "Training step  3914  of  100000  with loss  9.996678352355957\n",
      "Training step  3915  of  100000  with loss  10.302388191223145\n",
      "Training step  3916  of  100000  with loss  8.365310668945312\n",
      "Training step  3917  of  100000  with loss  10.353364944458008\n",
      "Training step  3918  of  100000  with loss  9.318367958068848\n",
      "Training step  3919  of  100000  with loss  9.692322731018066\n",
      "Training step  3920  of  100000  with loss  9.591011047363281\n",
      "Training step  3921  of  100000  with loss  10.814629554748535\n",
      "Training step  3922  of  100000  with loss  9.510035514831543\n",
      "Training step  3923  of  100000  with loss  9.862419128417969\n",
      "Training step  3924  of  100000  with loss  10.352065086364746\n",
      "Training step  3925  of  100000  with loss  8.812074661254883\n",
      "Training step  3926  of  100000  with loss  10.627551078796387\n",
      "Training step  3927  of  100000  with loss  10.546630859375\n",
      "Training step  3928  of  100000  with loss  9.068811416625977\n",
      "Training step  3929  of  100000  with loss  11.050858497619629\n",
      "Training step  3930  of  100000  with loss  8.776458740234375\n",
      "Training step  3931  of  100000  with loss  10.116395950317383\n",
      "Training step  3932  of  100000  with loss  9.846820831298828\n",
      "Training step  3933  of  100000  with loss  10.509522438049316\n",
      "Training step  3934  of  100000  with loss  9.979316711425781\n",
      "Training step  3935  of  100000  with loss  10.650300979614258\n",
      "Training step  3936  of  100000  with loss  10.018178939819336\n",
      "Training step  3937  of  100000  with loss  9.325498580932617\n",
      "Training step  3938  of  100000  with loss  9.872572898864746\n",
      "Training step  3939  of  100000  with loss  10.553458213806152\n",
      "Training step  3940  of  100000  with loss  9.891880989074707\n",
      "Training step  3941  of  100000  with loss  10.525959968566895\n",
      "Training step  3942  of  100000  with loss  9.333988189697266\n",
      "Training step  3943  of  100000  with loss  10.100101470947266\n",
      "Training step  3944  of  100000  with loss  9.465970993041992\n",
      "Training step  3945  of  100000  with loss  10.075712203979492\n",
      "Training step  3946  of  100000  with loss  9.100610733032227\n",
      "Training step  3947  of  100000  with loss  9.714900970458984\n",
      "Training step  3948  of  100000  with loss  9.513285636901855\n",
      "Training step  3949  of  100000  with loss  9.510980606079102\n",
      "Training step  3950  of  100000  with loss  10.472535133361816\n",
      "Training step  3951  of  100000  with loss  9.175558090209961\n",
      "Training step  3952  of  100000  with loss  8.815001487731934\n",
      "Training step  3953  of  100000  with loss  9.643453598022461\n",
      "Training step  3954  of  100000  with loss  9.05569076538086\n",
      "Training step  3955  of  100000  with loss  10.14505672454834\n",
      "Training step  3956  of  100000  with loss  9.957337379455566\n",
      "Training step  3957  of  100000  with loss  10.021968841552734\n",
      "Training step  3958  of  100000  with loss  9.665454864501953\n",
      "Training step  3959  of  100000  with loss  9.537901878356934\n",
      "Training step  3960  of  100000  with loss  9.667699813842773\n",
      "Training step  3961  of  100000  with loss  10.37321949005127\n",
      "Training step  3962  of  100000  with loss  10.731361389160156\n",
      "Training step  3963  of  100000  with loss  9.000418663024902\n",
      "Training step  3964  of  100000  with loss  10.277118682861328\n",
      "Training step  3965  of  100000  with loss  10.15165901184082\n",
      "Training step  3966  of  100000  with loss  9.471839904785156\n",
      "Training step  3967  of  100000  with loss  10.444347381591797\n",
      "Training step  3968  of  100000  with loss  9.41392707824707\n",
      "Training step  3969  of  100000  with loss  10.162269592285156\n",
      "Training step  3970  of  100000  with loss  9.563273429870605\n",
      "Training step  3971  of  100000  with loss  11.0372314453125\n",
      "Training step  3972  of  100000  with loss  9.718350410461426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  3973  of  100000  with loss  10.761543273925781\n",
      "Training step  3974  of  100000  with loss  9.953968048095703\n",
      "Training step  3975  of  100000  with loss  10.029664993286133\n",
      "Training step  3976  of  100000  with loss  9.881660461425781\n",
      "Training step  3977  of  100000  with loss  9.723106384277344\n",
      "Training step  3978  of  100000  with loss  9.390901565551758\n",
      "Training step  3979  of  100000  with loss  9.912201881408691\n",
      "Training step  3980  of  100000  with loss  9.755597114562988\n",
      "Training step  3981  of  100000  with loss  9.094656944274902\n",
      "Training step  3982  of  100000  with loss  9.9744291305542\n",
      "Training step  3983  of  100000  with loss  11.205694198608398\n",
      "Training step  3984  of  100000  with loss  9.975200653076172\n",
      "Training step  3985  of  100000  with loss  10.78238296508789\n",
      "Training step  3986  of  100000  with loss  9.090963363647461\n",
      "Training step  3987  of  100000  with loss  11.188403129577637\n",
      "Training step  3988  of  100000  with loss  10.292749404907227\n",
      "Training step  3989  of  100000  with loss  8.843324661254883\n",
      "Training step  3990  of  100000  with loss  9.679630279541016\n",
      "Training step  3991  of  100000  with loss  10.928322792053223\n",
      "Training step  3992  of  100000  with loss  9.926689147949219\n",
      "Training step  3993  of  100000  with loss  10.253694534301758\n",
      "Training step  3994  of  100000  with loss  10.019706726074219\n",
      "Training step  3995  of  100000  with loss  11.681350708007812\n",
      "Training step  3996  of  100000  with loss  9.589397430419922\n",
      "Training step  3997  of  100000  with loss  9.79696273803711\n",
      "Training step  3998  of  100000  with loss  10.279253005981445\n",
      "Training step  3999  of  100000  with loss  10.031471252441406\n",
      "Training step  4000  of  100000  with loss  10.677947998046875\n",
      "Training step  4001  of  100000  with loss  9.367911338806152\n",
      "Training step  4002  of  100000  with loss  9.97233772277832\n",
      "Training step  4003  of  100000  with loss  10.61755084991455\n",
      "Training step  4004  of  100000  with loss  8.977038383483887\n",
      "Training step  4005  of  100000  with loss  11.83656120300293\n",
      "Training step  4006  of  100000  with loss  9.699862480163574\n",
      "Training step  4007  of  100000  with loss  9.54269027709961\n",
      "Training step  4008  of  100000  with loss  10.300403594970703\n",
      "Training step  4009  of  100000  with loss  8.724624633789062\n",
      "Training step  4010  of  100000  with loss  10.320619583129883\n",
      "Training step  4011  of  100000  with loss  9.788025856018066\n",
      "Training step  4012  of  100000  with loss  9.830281257629395\n",
      "Training step  4013  of  100000  with loss  10.747512817382812\n",
      "Training step  4014  of  100000  with loss  10.071476936340332\n",
      "Training step  4015  of  100000  with loss  9.169282913208008\n",
      "Training step  4016  of  100000  with loss  9.652656555175781\n",
      "Training step  4017  of  100000  with loss  9.07991886138916\n",
      "Training step  4018  of  100000  with loss  9.948147773742676\n",
      "Training step  4019  of  100000  with loss  8.771567344665527\n",
      "Training step  4020  of  100000  with loss  9.369759559631348\n",
      "Training step  4021  of  100000  with loss  10.179004669189453\n",
      "Training step  4022  of  100000  with loss  8.775372505187988\n",
      "Training step  4023  of  100000  with loss  10.38278579711914\n",
      "Training step  4024  of  100000  with loss  9.728452682495117\n",
      "Training step  4025  of  100000  with loss  9.575326919555664\n",
      "Training step  4026  of  100000  with loss  8.952005386352539\n",
      "Training step  4027  of  100000  with loss  10.424179077148438\n",
      "Training step  4028  of  100000  with loss  10.88310718536377\n",
      "Training step  4029  of  100000  with loss  10.979116439819336\n",
      "Training step  4030  of  100000  with loss  9.958486557006836\n",
      "Training step  4031  of  100000  with loss  9.983847618103027\n",
      "Training step  4032  of  100000  with loss  9.133559226989746\n",
      "Training step  4033  of  100000  with loss  9.746719360351562\n",
      "Training step  4034  of  100000  with loss  10.828088760375977\n",
      "Training step  4035  of  100000  with loss  9.857001304626465\n",
      "Training step  4036  of  100000  with loss  10.476147651672363\n",
      "Training step  4037  of  100000  with loss  9.845115661621094\n",
      "Training step  4038  of  100000  with loss  10.020221710205078\n",
      "Training step  4039  of  100000  with loss  10.37144660949707\n",
      "Training step  4040  of  100000  with loss  9.995063781738281\n",
      "Training step  4041  of  100000  with loss  10.985664367675781\n",
      "Training step  4042  of  100000  with loss  10.301717758178711\n",
      "Training step  4043  of  100000  with loss  11.225934982299805\n",
      "Training step  4044  of  100000  with loss  8.752910614013672\n",
      "Training step  4045  of  100000  with loss  10.53441047668457\n",
      "Training step  4046  of  100000  with loss  10.13003158569336\n",
      "Training step  4047  of  100000  with loss  8.72161865234375\n",
      "Training step  4048  of  100000  with loss  9.75357437133789\n",
      "Training step  4049  of  100000  with loss  9.34443473815918\n",
      "Training step  4050  of  100000  with loss  10.118780136108398\n",
      "Training step  4051  of  100000  with loss  9.309441566467285\n",
      "Training step  4052  of  100000  with loss  10.86579704284668\n",
      "Training step  4053  of  100000  with loss  9.581254959106445\n",
      "Training step  4054  of  100000  with loss  10.341527938842773\n",
      "Training step  4055  of  100000  with loss  9.606690406799316\n",
      "Training step  4056  of  100000  with loss  10.368494033813477\n",
      "Training step  4057  of  100000  with loss  10.674980163574219\n",
      "Training step  4058  of  100000  with loss  10.61415958404541\n",
      "Training step  4059  of  100000  with loss  10.567273139953613\n",
      "Training step  4060  of  100000  with loss  10.731451988220215\n",
      "Training step  4061  of  100000  with loss  10.442666053771973\n",
      "Training step  4062  of  100000  with loss  10.03201675415039\n",
      "Training step  4063  of  100000  with loss  9.893850326538086\n",
      "Training step  4064  of  100000  with loss  9.759571075439453\n",
      "Training step  4065  of  100000  with loss  10.239616394042969\n",
      "Training step  4066  of  100000  with loss  10.226282119750977\n",
      "Training step  4067  of  100000  with loss  9.14137077331543\n",
      "Training step  4068  of  100000  with loss  9.495565414428711\n",
      "Training step  4069  of  100000  with loss  9.080772399902344\n",
      "Training step  4070  of  100000  with loss  10.184606552124023\n",
      "Training step  4071  of  100000  with loss  9.685349464416504\n",
      "Training step  4072  of  100000  with loss  10.457513809204102\n",
      "Training step  4073  of  100000  with loss  10.738628387451172\n",
      "Training step  4074  of  100000  with loss  10.176778793334961\n",
      "Training step  4075  of  100000  with loss  9.790630340576172\n",
      "Training step  4076  of  100000  with loss  10.772217750549316\n",
      "Training step  4077  of  100000  with loss  11.008685111999512\n",
      "Training step  4078  of  100000  with loss  9.930408477783203\n",
      "Training step  4079  of  100000  with loss  9.71434211730957\n",
      "Training step  4080  of  100000  with loss  11.417346954345703\n",
      "Training step  4081  of  100000  with loss  10.599615097045898\n",
      "Training step  4082  of  100000  with loss  9.164763450622559\n",
      "Training step  4083  of  100000  with loss  10.40386962890625\n",
      "Training step  4084  of  100000  with loss  10.27535629272461\n",
      "Training step  4085  of  100000  with loss  9.026507377624512\n",
      "Training step  4086  of  100000  with loss  8.387327194213867\n",
      "Training step  4087  of  100000  with loss  9.102482795715332\n",
      "Training step  4088  of  100000  with loss  8.986396789550781\n",
      "Training step  4089  of  100000  with loss  10.318822860717773\n",
      "Training step  4090  of  100000  with loss  9.032804489135742\n",
      "Training step  4091  of  100000  with loss  10.00042724609375\n",
      "Training step  4092  of  100000  with loss  10.045462608337402\n",
      "Training step  4093  of  100000  with loss  10.009153366088867\n",
      "Training step  4094  of  100000  with loss  9.703821182250977\n",
      "Training step  4095  of  100000  with loss  9.61228084564209\n",
      "Training step  4096  of  100000  with loss  10.741743087768555\n",
      "Training step  4097  of  100000  with loss  9.740804672241211\n",
      "Training step  4098  of  100000  with loss  9.886801719665527\n",
      "Training step  4099  of  100000  with loss  10.267128944396973\n",
      "Training step  4100  of  100000  with loss  8.859749794006348\n",
      "Training step  4101  of  100000  with loss  11.185405731201172\n",
      "Training step  4102  of  100000  with loss  9.350028991699219\n",
      "Training step  4103  of  100000  with loss  9.105804443359375\n",
      "Training step  4104  of  100000  with loss  10.46602725982666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4105  of  100000  with loss  9.694731712341309\n",
      "Training step  4106  of  100000  with loss  11.926295280456543\n",
      "Training step  4107  of  100000  with loss  9.024023056030273\n",
      "Training step  4108  of  100000  with loss  10.401710510253906\n",
      "Training step  4109  of  100000  with loss  9.685136795043945\n",
      "Training step  4110  of  100000  with loss  8.511801719665527\n",
      "Training step  4111  of  100000  with loss  10.13329792022705\n",
      "Training step  4112  of  100000  with loss  10.685284614562988\n",
      "Training step  4113  of  100000  with loss  9.893799781799316\n",
      "Training step  4114  of  100000  with loss  9.702310562133789\n",
      "Training step  4115  of  100000  with loss  10.122396469116211\n",
      "Training step  4116  of  100000  with loss  10.398077964782715\n",
      "Training step  4117  of  100000  with loss  10.416858673095703\n",
      "Training step  4118  of  100000  with loss  10.078107833862305\n",
      "Training step  4119  of  100000  with loss  8.475776672363281\n",
      "Training step  4120  of  100000  with loss  9.811508178710938\n",
      "Training step  4121  of  100000  with loss  9.590330123901367\n",
      "Training step  4122  of  100000  with loss  9.036697387695312\n",
      "Training step  4123  of  100000  with loss  9.462525367736816\n",
      "Training step  4124  of  100000  with loss  10.845420837402344\n",
      "Training step  4125  of  100000  with loss  11.731803894042969\n",
      "Training step  4126  of  100000  with loss  10.286626815795898\n",
      "Training step  4127  of  100000  with loss  10.874319076538086\n",
      "Training step  4128  of  100000  with loss  11.929792404174805\n",
      "Training step  4129  of  100000  with loss  10.041594505310059\n",
      "Training step  4130  of  100000  with loss  10.492990493774414\n",
      "Training step  4131  of  100000  with loss  9.286649703979492\n",
      "Training step  4132  of  100000  with loss  10.306197166442871\n",
      "Training step  4133  of  100000  with loss  9.898391723632812\n",
      "Training step  4134  of  100000  with loss  9.102958679199219\n",
      "Training step  4135  of  100000  with loss  10.132118225097656\n",
      "Training step  4136  of  100000  with loss  11.337835311889648\n",
      "Training step  4137  of  100000  with loss  10.760513305664062\n",
      "Training step  4138  of  100000  with loss  10.912638664245605\n",
      "Training step  4139  of  100000  with loss  9.576517105102539\n",
      "Training step  4140  of  100000  with loss  9.76485824584961\n",
      "Training step  4141  of  100000  with loss  9.829719543457031\n",
      "Training step  4142  of  100000  with loss  10.083980560302734\n",
      "Training step  4143  of  100000  with loss  9.976760864257812\n",
      "Training step  4144  of  100000  with loss  10.05801773071289\n",
      "Training step  4145  of  100000  with loss  9.642263412475586\n",
      "Training step  4146  of  100000  with loss  8.307466506958008\n",
      "Training step  4147  of  100000  with loss  9.72228717803955\n",
      "Training step  4148  of  100000  with loss  10.367671012878418\n",
      "Training step  4149  of  100000  with loss  9.534757614135742\n",
      "Training step  4150  of  100000  with loss  10.779187202453613\n",
      "Training step  4151  of  100000  with loss  9.400052070617676\n",
      "Training step  4152  of  100000  with loss  11.178230285644531\n",
      "Training step  4153  of  100000  with loss  10.768976211547852\n",
      "Training step  4154  of  100000  with loss  9.28339672088623\n",
      "Training step  4155  of  100000  with loss  10.428862571716309\n",
      "Training step  4156  of  100000  with loss  10.307655334472656\n",
      "Training step  4157  of  100000  with loss  8.963872909545898\n",
      "Training step  4158  of  100000  with loss  11.577324867248535\n",
      "Training step  4159  of  100000  with loss  10.787967681884766\n",
      "Training step  4160  of  100000  with loss  9.179841041564941\n",
      "Training step  4161  of  100000  with loss  9.767125129699707\n",
      "Training step  4162  of  100000  with loss  9.319796562194824\n",
      "Training step  4163  of  100000  with loss  10.371943473815918\n",
      "Training step  4164  of  100000  with loss  8.60385513305664\n",
      "Training step  4165  of  100000  with loss  10.137516021728516\n",
      "Training step  4166  of  100000  with loss  9.883719444274902\n",
      "Training step  4167  of  100000  with loss  9.237286567687988\n",
      "Training step  4168  of  100000  with loss  10.847818374633789\n",
      "Training step  4169  of  100000  with loss  9.747103691101074\n",
      "Training step  4170  of  100000  with loss  9.876209259033203\n",
      "Training step  4171  of  100000  with loss  11.830376625061035\n",
      "Training step  4172  of  100000  with loss  9.912629127502441\n",
      "Training step  4173  of  100000  with loss  10.137479782104492\n",
      "Training step  4174  of  100000  with loss  9.103184700012207\n",
      "Training step  4175  of  100000  with loss  10.416542053222656\n",
      "Training step  4176  of  100000  with loss  8.117863655090332\n",
      "Training step  4177  of  100000  with loss  9.466582298278809\n",
      "Training step  4178  of  100000  with loss  10.532865524291992\n",
      "Training step  4179  of  100000  with loss  9.262554168701172\n",
      "Training step  4180  of  100000  with loss  12.313596725463867\n",
      "Training step  4181  of  100000  with loss  11.44320297241211\n",
      "Training step  4182  of  100000  with loss  9.74881649017334\n",
      "Training step  4183  of  100000  with loss  9.840655326843262\n",
      "Training step  4184  of  100000  with loss  10.780421257019043\n",
      "Training step  4185  of  100000  with loss  11.002551078796387\n",
      "Training step  4186  of  100000  with loss  9.695549011230469\n",
      "Training step  4187  of  100000  with loss  9.52650260925293\n",
      "Training step  4188  of  100000  with loss  9.262786865234375\n",
      "Training step  4189  of  100000  with loss  9.920790672302246\n",
      "Training step  4190  of  100000  with loss  9.50184154510498\n",
      "Training step  4191  of  100000  with loss  9.217723846435547\n",
      "Training step  4192  of  100000  with loss  10.924520492553711\n",
      "Training step  4193  of  100000  with loss  10.444801330566406\n",
      "Training step  4194  of  100000  with loss  9.296411514282227\n",
      "Training step  4195  of  100000  with loss  9.131175994873047\n",
      "Training step  4196  of  100000  with loss  9.561352729797363\n",
      "Training step  4197  of  100000  with loss  10.572336196899414\n",
      "Training step  4198  of  100000  with loss  10.816232681274414\n",
      "Training step  4199  of  100000  with loss  10.287653923034668\n",
      "Training step  4200  of  100000  with loss  9.470098495483398\n",
      "Training step  4201  of  100000  with loss  8.564581871032715\n",
      "Training step  4202  of  100000  with loss  10.150861740112305\n",
      "Training step  4203  of  100000  with loss  10.122983932495117\n",
      "Training step  4204  of  100000  with loss  9.254341125488281\n",
      "Training step  4205  of  100000  with loss  9.344010353088379\n",
      "Training step  4206  of  100000  with loss  10.449865341186523\n",
      "Training step  4207  of  100000  with loss  9.562033653259277\n",
      "Training step  4208  of  100000  with loss  8.826828956604004\n",
      "Training step  4209  of  100000  with loss  11.203012466430664\n",
      "Training step  4210  of  100000  with loss  9.581209182739258\n",
      "Training step  4211  of  100000  with loss  9.860685348510742\n",
      "Training step  4212  of  100000  with loss  9.816801071166992\n",
      "Training step  4213  of  100000  with loss  9.394116401672363\n",
      "Training step  4214  of  100000  with loss  10.449285507202148\n",
      "Training step  4215  of  100000  with loss  11.570106506347656\n",
      "Training step  4216  of  100000  with loss  9.76524543762207\n",
      "Training step  4217  of  100000  with loss  9.153709411621094\n",
      "Training step  4218  of  100000  with loss  9.985210418701172\n",
      "Training step  4219  of  100000  with loss  8.912041664123535\n",
      "Training step  4220  of  100000  with loss  10.240848541259766\n",
      "Training step  4221  of  100000  with loss  9.451395034790039\n",
      "Training step  4222  of  100000  with loss  11.078184127807617\n",
      "Training step  4223  of  100000  with loss  10.631900787353516\n",
      "Training step  4224  of  100000  with loss  10.218682289123535\n",
      "Training step  4225  of  100000  with loss  10.93875503540039\n",
      "Training step  4226  of  100000  with loss  9.358768463134766\n",
      "Training step  4227  of  100000  with loss  10.616607666015625\n",
      "Training step  4228  of  100000  with loss  9.33228588104248\n",
      "Training step  4229  of  100000  with loss  10.941722869873047\n",
      "Training step  4230  of  100000  with loss  9.022857666015625\n",
      "Training step  4231  of  100000  with loss  9.631847381591797\n",
      "Training step  4232  of  100000  with loss  10.082839965820312\n",
      "Training step  4233  of  100000  with loss  9.095398902893066\n",
      "Training step  4234  of  100000  with loss  9.245437622070312\n",
      "Training step  4235  of  100000  with loss  10.04463005065918\n",
      "Training step  4236  of  100000  with loss  9.785642623901367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4237  of  100000  with loss  10.71377182006836\n",
      "Training step  4238  of  100000  with loss  9.51966381072998\n",
      "Training step  4239  of  100000  with loss  9.123359680175781\n",
      "Training step  4240  of  100000  with loss  9.346949577331543\n",
      "Training step  4241  of  100000  with loss  11.273606300354004\n",
      "Training step  4242  of  100000  with loss  12.312253952026367\n",
      "Training step  4243  of  100000  with loss  9.76717758178711\n",
      "Training step  4244  of  100000  with loss  9.592114448547363\n",
      "Training step  4245  of  100000  with loss  9.728790283203125\n",
      "Training step  4246  of  100000  with loss  9.852392196655273\n",
      "Training step  4247  of  100000  with loss  10.414600372314453\n",
      "Training step  4248  of  100000  with loss  10.557441711425781\n",
      "Training step  4249  of  100000  with loss  10.660213470458984\n",
      "Training step  4250  of  100000  with loss  9.443105697631836\n",
      "Training step  4251  of  100000  with loss  11.03437328338623\n",
      "Training step  4252  of  100000  with loss  10.376498222351074\n",
      "Training step  4253  of  100000  with loss  10.887052536010742\n",
      "Training step  4254  of  100000  with loss  9.964353561401367\n",
      "Training step  4255  of  100000  with loss  9.987800598144531\n",
      "Training step  4256  of  100000  with loss  10.036554336547852\n",
      "Training step  4257  of  100000  with loss  10.976115226745605\n",
      "Training step  4258  of  100000  with loss  9.817806243896484\n",
      "Training step  4259  of  100000  with loss  11.656925201416016\n",
      "Training step  4260  of  100000  with loss  10.090177536010742\n",
      "Training step  4261  of  100000  with loss  9.841012001037598\n",
      "Training step  4262  of  100000  with loss  9.519308090209961\n",
      "Training step  4263  of  100000  with loss  10.423322677612305\n",
      "Training step  4264  of  100000  with loss  11.251401901245117\n",
      "Training step  4265  of  100000  with loss  9.35846996307373\n",
      "Training step  4266  of  100000  with loss  8.750965118408203\n",
      "Training step  4267  of  100000  with loss  9.626291275024414\n",
      "Training step  4268  of  100000  with loss  9.465591430664062\n",
      "Training step  4269  of  100000  with loss  10.386734962463379\n",
      "Training step  4270  of  100000  with loss  10.849018096923828\n",
      "Training step  4271  of  100000  with loss  9.101824760437012\n",
      "Training step  4272  of  100000  with loss  10.335403442382812\n",
      "Training step  4273  of  100000  with loss  10.04251766204834\n",
      "Training step  4274  of  100000  with loss  9.677248001098633\n",
      "Training step  4275  of  100000  with loss  9.456175804138184\n",
      "Training step  4276  of  100000  with loss  9.063962936401367\n",
      "Training step  4277  of  100000  with loss  8.983074188232422\n",
      "Training step  4278  of  100000  with loss  10.673213958740234\n",
      "Training step  4279  of  100000  with loss  10.105484008789062\n",
      "Training step  4280  of  100000  with loss  9.5873441696167\n",
      "Training step  4281  of  100000  with loss  9.929240226745605\n",
      "Training step  4282  of  100000  with loss  10.36452579498291\n",
      "Training step  4283  of  100000  with loss  11.37971305847168\n",
      "Training step  4284  of  100000  with loss  9.644672393798828\n",
      "Training step  4285  of  100000  with loss  10.546049118041992\n",
      "Training step  4286  of  100000  with loss  12.185144424438477\n",
      "Training step  4287  of  100000  with loss  9.924497604370117\n",
      "Training step  4288  of  100000  with loss  10.637240409851074\n",
      "Training step  4289  of  100000  with loss  9.831003189086914\n",
      "Training step  4290  of  100000  with loss  10.323497772216797\n",
      "Training step  4291  of  100000  with loss  10.848944664001465\n",
      "Training step  4292  of  100000  with loss  9.921550750732422\n",
      "Training step  4293  of  100000  with loss  10.071250915527344\n",
      "Training step  4294  of  100000  with loss  10.170507431030273\n",
      "Training step  4295  of  100000  with loss  10.321395874023438\n",
      "Training step  4296  of  100000  with loss  9.062763214111328\n",
      "Training step  4297  of  100000  with loss  9.052305221557617\n",
      "Training step  4298  of  100000  with loss  9.78070068359375\n",
      "Training step  4299  of  100000  with loss  10.40826416015625\n",
      "Training step  4300  of  100000  with loss  10.776906967163086\n",
      "Training step  4301  of  100000  with loss  11.301645278930664\n",
      "Training step  4302  of  100000  with loss  10.105051040649414\n",
      "Training step  4303  of  100000  with loss  9.621541023254395\n",
      "Training step  4304  of  100000  with loss  10.264228820800781\n",
      "Training step  4305  of  100000  with loss  9.002881050109863\n",
      "Training step  4306  of  100000  with loss  10.28462028503418\n",
      "Training step  4307  of  100000  with loss  9.394181251525879\n",
      "Training step  4308  of  100000  with loss  9.660381317138672\n",
      "Training step  4309  of  100000  with loss  8.614888191223145\n",
      "Training step  4310  of  100000  with loss  11.041061401367188\n",
      "Training step  4311  of  100000  with loss  9.677713394165039\n",
      "Training step  4312  of  100000  with loss  10.4243803024292\n",
      "Training step  4313  of  100000  with loss  9.891279220581055\n",
      "Training step  4314  of  100000  with loss  9.758563995361328\n",
      "Training step  4315  of  100000  with loss  9.006406784057617\n",
      "Training step  4316  of  100000  with loss  10.506529808044434\n",
      "Training step  4317  of  100000  with loss  9.340858459472656\n",
      "Training step  4318  of  100000  with loss  8.677289962768555\n",
      "Training step  4319  of  100000  with loss  10.03006649017334\n",
      "Training step  4320  of  100000  with loss  10.915840148925781\n",
      "Training step  4321  of  100000  with loss  10.584732055664062\n",
      "Training step  4322  of  100000  with loss  11.857670783996582\n",
      "Training step  4323  of  100000  with loss  9.174911499023438\n",
      "Training step  4324  of  100000  with loss  9.653775215148926\n",
      "Training step  4325  of  100000  with loss  11.028926849365234\n",
      "Training step  4326  of  100000  with loss  11.503792762756348\n",
      "Training step  4327  of  100000  with loss  10.770820617675781\n",
      "Training step  4328  of  100000  with loss  10.835884094238281\n",
      "Training step  4329  of  100000  with loss  9.240386962890625\n",
      "Training step  4330  of  100000  with loss  9.47317886352539\n",
      "Training step  4331  of  100000  with loss  9.39565658569336\n",
      "Training step  4332  of  100000  with loss  9.540398597717285\n",
      "Training step  4333  of  100000  with loss  9.102295875549316\n",
      "Training step  4334  of  100000  with loss  10.297016143798828\n",
      "Training step  4335  of  100000  with loss  11.538698196411133\n",
      "Training step  4336  of  100000  with loss  9.388296127319336\n",
      "Training step  4337  of  100000  with loss  11.64289665222168\n",
      "Training step  4338  of  100000  with loss  10.215400695800781\n",
      "Training step  4339  of  100000  with loss  11.097686767578125\n",
      "Training step  4340  of  100000  with loss  10.000886917114258\n",
      "Training step  4341  of  100000  with loss  9.705493927001953\n",
      "Training step  4342  of  100000  with loss  11.0704345703125\n",
      "Training step  4343  of  100000  with loss  10.085052490234375\n",
      "Training step  4344  of  100000  with loss  10.597969055175781\n",
      "Training step  4345  of  100000  with loss  9.744062423706055\n",
      "Training step  4346  of  100000  with loss  9.204421043395996\n",
      "Training step  4347  of  100000  with loss  9.680087089538574\n",
      "Training step  4348  of  100000  with loss  10.222112655639648\n",
      "Training step  4349  of  100000  with loss  9.137245178222656\n",
      "Training step  4350  of  100000  with loss  9.082207679748535\n",
      "Training step  4351  of  100000  with loss  8.910449981689453\n",
      "Training step  4352  of  100000  with loss  11.018218994140625\n",
      "Training step  4353  of  100000  with loss  10.012910842895508\n",
      "Training step  4354  of  100000  with loss  11.337268829345703\n",
      "Training step  4355  of  100000  with loss  10.571365356445312\n",
      "Training step  4356  of  100000  with loss  10.269721031188965\n",
      "Training step  4357  of  100000  with loss  9.655074119567871\n",
      "Training step  4358  of  100000  with loss  9.162723541259766\n",
      "Training step  4359  of  100000  with loss  11.336750984191895\n",
      "Training step  4360  of  100000  with loss  8.678333282470703\n",
      "Training step  4361  of  100000  with loss  9.499635696411133\n",
      "Training step  4362  of  100000  with loss  8.486272811889648\n",
      "Training step  4363  of  100000  with loss  10.957908630371094\n",
      "Training step  4364  of  100000  with loss  10.396196365356445\n",
      "Training step  4365  of  100000  with loss  10.79098129272461\n",
      "Training step  4366  of  100000  with loss  10.346817016601562\n",
      "Training step  4367  of  100000  with loss  9.576042175292969\n",
      "Training step  4368  of  100000  with loss  10.301891326904297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4369  of  100000  with loss  10.380541801452637\n",
      "Training step  4370  of  100000  with loss  11.760326385498047\n",
      "Training step  4371  of  100000  with loss  10.64523696899414\n",
      "Training step  4372  of  100000  with loss  10.213497161865234\n",
      "Training step  4373  of  100000  with loss  7.897950172424316\n",
      "Saving checkpoints\n",
      "Training step  4374  of  100000  with loss  11.26689338684082\n",
      "Training step  4375  of  100000  with loss  8.9871826171875\n",
      "Training step  4376  of  100000  with loss  9.071706771850586\n",
      "Training step  4377  of  100000  with loss  10.789667129516602\n",
      "Training step  4378  of  100000  with loss  10.003189086914062\n",
      "Training step  4379  of  100000  with loss  9.753022193908691\n",
      "Training step  4380  of  100000  with loss  11.762085914611816\n",
      "Training step  4381  of  100000  with loss  10.418523788452148\n",
      "Training step  4382  of  100000  with loss  10.50842571258545\n",
      "Training step  4383  of  100000  with loss  10.015464782714844\n",
      "Training step  4384  of  100000  with loss  10.030305862426758\n",
      "Training step  4385  of  100000  with loss  8.510988235473633\n",
      "Training step  4386  of  100000  with loss  9.675405502319336\n",
      "Training step  4387  of  100000  with loss  10.081695556640625\n",
      "Training step  4388  of  100000  with loss  10.382133483886719\n",
      "Training step  4389  of  100000  with loss  9.839106559753418\n",
      "Training step  4390  of  100000  with loss  8.593280792236328\n",
      "Training step  4391  of  100000  with loss  9.818824768066406\n",
      "Training step  4392  of  100000  with loss  11.28549575805664\n",
      "Training step  4393  of  100000  with loss  8.894338607788086\n",
      "Training step  4394  of  100000  with loss  9.754783630371094\n",
      "Training step  4395  of  100000  with loss  9.628896713256836\n",
      "Training step  4396  of  100000  with loss  11.386255264282227\n",
      "Training step  4397  of  100000  with loss  10.098230361938477\n",
      "Training step  4398  of  100000  with loss  10.860498428344727\n",
      "Training step  4399  of  100000  with loss  11.661258697509766\n",
      "Training step  4400  of  100000  with loss  9.691545486450195\n",
      "Training step  4401  of  100000  with loss  10.751063346862793\n",
      "Training step  4402  of  100000  with loss  10.56982135772705\n",
      "Training step  4403  of  100000  with loss  8.936820030212402\n",
      "Training step  4404  of  100000  with loss  9.075857162475586\n",
      "Training step  4405  of  100000  with loss  11.439095497131348\n",
      "Training step  4406  of  100000  with loss  9.859640121459961\n",
      "Training step  4407  of  100000  with loss  9.956405639648438\n",
      "Training step  4408  of  100000  with loss  10.746328353881836\n",
      "Training step  4409  of  100000  with loss  10.201587677001953\n",
      "Training step  4410  of  100000  with loss  10.66494369506836\n",
      "Training step  4411  of  100000  with loss  9.272790908813477\n",
      "Training step  4412  of  100000  with loss  9.31954574584961\n",
      "Training step  4413  of  100000  with loss  8.707721710205078\n",
      "Training step  4414  of  100000  with loss  9.911553382873535\n",
      "Training step  4415  of  100000  with loss  10.915193557739258\n",
      "Training step  4416  of  100000  with loss  9.938423156738281\n",
      "Training step  4417  of  100000  with loss  11.400558471679688\n",
      "Training step  4418  of  100000  with loss  9.145081520080566\n",
      "Training step  4419  of  100000  with loss  9.906774520874023\n",
      "Training step  4420  of  100000  with loss  12.336350440979004\n",
      "Training step  4421  of  100000  with loss  10.781095504760742\n",
      "Training step  4422  of  100000  with loss  9.624025344848633\n",
      "Training step  4423  of  100000  with loss  9.242003440856934\n",
      "Training step  4424  of  100000  with loss  10.301396369934082\n",
      "Training step  4425  of  100000  with loss  9.341075897216797\n",
      "Training step  4426  of  100000  with loss  11.664434432983398\n",
      "Training step  4427  of  100000  with loss  9.780832290649414\n",
      "Training step  4428  of  100000  with loss  10.165290832519531\n",
      "Training step  4429  of  100000  with loss  11.493249893188477\n",
      "Training step  4430  of  100000  with loss  10.847423553466797\n",
      "Training step  4431  of  100000  with loss  10.472027778625488\n",
      "Training step  4432  of  100000  with loss  9.776324272155762\n",
      "Training step  4433  of  100000  with loss  9.898615837097168\n",
      "Training step  4434  of  100000  with loss  10.5040864944458\n",
      "Training step  4435  of  100000  with loss  9.811284065246582\n",
      "Training step  4436  of  100000  with loss  9.535390853881836\n",
      "Training step  4437  of  100000  with loss  10.294509887695312\n",
      "Training step  4438  of  100000  with loss  9.70787239074707\n",
      "Training step  4439  of  100000  with loss  9.259832382202148\n",
      "Training step  4440  of  100000  with loss  9.661273002624512\n",
      "Training step  4441  of  100000  with loss  9.65229320526123\n",
      "Training step  4442  of  100000  with loss  10.297669410705566\n",
      "Training step  4443  of  100000  with loss  8.929791450500488\n",
      "Training step  4444  of  100000  with loss  8.948118209838867\n",
      "Training step  4445  of  100000  with loss  8.847640037536621\n",
      "Training step  4446  of  100000  with loss  9.331579208374023\n",
      "Training step  4447  of  100000  with loss  9.711813926696777\n",
      "Training step  4448  of  100000  with loss  9.770942687988281\n",
      "Training step  4449  of  100000  with loss  9.383646011352539\n",
      "Training step  4450  of  100000  with loss  9.163554191589355\n",
      "Training step  4451  of  100000  with loss  10.122956275939941\n",
      "Training step  4452  of  100000  with loss  10.14266586303711\n",
      "Training step  4453  of  100000  with loss  9.139602661132812\n",
      "Training step  4454  of  100000  with loss  10.047674179077148\n",
      "Training step  4455  of  100000  with loss  9.629114151000977\n",
      "Training step  4456  of  100000  with loss  9.945623397827148\n",
      "Training step  4457  of  100000  with loss  9.156349182128906\n",
      "Training step  4458  of  100000  with loss  10.965749740600586\n",
      "Training step  4459  of  100000  with loss  9.421952247619629\n",
      "Training step  4460  of  100000  with loss  9.681012153625488\n",
      "Training step  4461  of  100000  with loss  10.290523529052734\n",
      "Training step  4462  of  100000  with loss  9.082032203674316\n",
      "Training step  4463  of  100000  with loss  9.789676666259766\n",
      "Training step  4464  of  100000  with loss  10.888185501098633\n",
      "Training step  4465  of  100000  with loss  9.086214065551758\n",
      "Training step  4466  of  100000  with loss  8.436506271362305\n",
      "Training step  4467  of  100000  with loss  9.357595443725586\n",
      "Training step  4468  of  100000  with loss  11.329472541809082\n",
      "Training step  4469  of  100000  with loss  9.2787446975708\n",
      "Training step  4470  of  100000  with loss  9.770782470703125\n",
      "Training step  4471  of  100000  with loss  9.703337669372559\n",
      "Training step  4472  of  100000  with loss  10.346330642700195\n",
      "Training step  4473  of  100000  with loss  8.48309326171875\n",
      "Training step  4474  of  100000  with loss  9.914274215698242\n",
      "Training step  4475  of  100000  with loss  9.403014183044434\n",
      "Training step  4476  of  100000  with loss  10.87285327911377\n",
      "Training step  4477  of  100000  with loss  10.95659065246582\n",
      "Training step  4478  of  100000  with loss  10.080099105834961\n",
      "Training step  4479  of  100000  with loss  9.043270111083984\n",
      "Training step  4480  of  100000  with loss  9.290359497070312\n",
      "Training step  4481  of  100000  with loss  8.576647758483887\n",
      "Training step  4482  of  100000  with loss  10.171956062316895\n",
      "Training step  4483  of  100000  with loss  10.849921226501465\n",
      "Training step  4484  of  100000  with loss  11.066481590270996\n",
      "Training step  4485  of  100000  with loss  9.813196182250977\n",
      "Training step  4486  of  100000  with loss  9.539239883422852\n",
      "Training step  4487  of  100000  with loss  10.112386703491211\n",
      "Training step  4488  of  100000  with loss  9.063810348510742\n",
      "Training step  4489  of  100000  with loss  9.038323402404785\n",
      "Training step  4490  of  100000  with loss  9.137332916259766\n",
      "Training step  4491  of  100000  with loss  8.626471519470215\n",
      "Training step  4492  of  100000  with loss  8.664875984191895\n",
      "Training step  4493  of  100000  with loss  10.073151588439941\n",
      "Training step  4494  of  100000  with loss  9.572733879089355\n",
      "Training step  4495  of  100000  with loss  10.647554397583008\n",
      "Training step  4496  of  100000  with loss  9.697190284729004\n",
      "Training step  4497  of  100000  with loss  9.121748924255371\n",
      "Training step  4498  of  100000  with loss  10.198457717895508\n",
      "Training step  4499  of  100000  with loss  10.964155197143555\n",
      "Training step  4500  of  100000  with loss  11.24065113067627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4501  of  100000  with loss  9.749799728393555\n",
      "Training step  4502  of  100000  with loss  11.030046463012695\n",
      "Training step  4503  of  100000  with loss  11.402615547180176\n",
      "Training step  4504  of  100000  with loss  9.782400131225586\n",
      "Training step  4505  of  100000  with loss  8.839073181152344\n",
      "Training step  4506  of  100000  with loss  10.402789115905762\n",
      "Training step  4507  of  100000  with loss  10.105155944824219\n",
      "Training step  4508  of  100000  with loss  9.439570426940918\n",
      "Training step  4509  of  100000  with loss  11.345514297485352\n",
      "Training step  4510  of  100000  with loss  9.166634559631348\n",
      "Training step  4511  of  100000  with loss  11.396174430847168\n",
      "Training step  4512  of  100000  with loss  10.456415176391602\n",
      "Training step  4513  of  100000  with loss  8.622136116027832\n",
      "Training step  4514  of  100000  with loss  9.564558029174805\n",
      "Training step  4515  of  100000  with loss  8.525251388549805\n",
      "Training step  4516  of  100000  with loss  10.866260528564453\n",
      "Training step  4517  of  100000  with loss  9.205047607421875\n",
      "Training step  4518  of  100000  with loss  11.18466567993164\n",
      "Training step  4519  of  100000  with loss  9.874650955200195\n",
      "Training step  4520  of  100000  with loss  8.965353012084961\n",
      "Training step  4521  of  100000  with loss  9.191997528076172\n",
      "Training step  4522  of  100000  with loss  9.799257278442383\n",
      "Training step  4523  of  100000  with loss  9.312938690185547\n",
      "Training step  4524  of  100000  with loss  10.6260986328125\n",
      "Training step  4525  of  100000  with loss  10.979299545288086\n",
      "Training step  4526  of  100000  with loss  10.127848625183105\n",
      "Training step  4527  of  100000  with loss  9.818541526794434\n",
      "Training step  4528  of  100000  with loss  9.066841125488281\n",
      "Training step  4529  of  100000  with loss  9.150466918945312\n",
      "Training step  4530  of  100000  with loss  10.0647554397583\n",
      "Training step  4531  of  100000  with loss  9.245599746704102\n",
      "Training step  4532  of  100000  with loss  9.159292221069336\n",
      "Training step  4533  of  100000  with loss  9.437353134155273\n",
      "Training step  4534  of  100000  with loss  11.252483367919922\n",
      "Training step  4535  of  100000  with loss  9.551312446594238\n",
      "Training step  4536  of  100000  with loss  9.906593322753906\n",
      "Training step  4537  of  100000  with loss  10.458789825439453\n",
      "Training step  4538  of  100000  with loss  9.516819953918457\n",
      "Training step  4539  of  100000  with loss  9.728789329528809\n",
      "Training step  4540  of  100000  with loss  10.507757186889648\n",
      "Training step  4541  of  100000  with loss  10.501628875732422\n",
      "Training step  4542  of  100000  with loss  11.622062683105469\n",
      "Training step  4543  of  100000  with loss  9.254262924194336\n",
      "Training step  4544  of  100000  with loss  10.086345672607422\n",
      "Training step  4545  of  100000  with loss  10.579504013061523\n",
      "Training step  4546  of  100000  with loss  9.922274589538574\n",
      "Training step  4547  of  100000  with loss  9.565922737121582\n",
      "Training step  4548  of  100000  with loss  10.456995964050293\n",
      "Training step  4549  of  100000  with loss  9.117009162902832\n",
      "Training step  4550  of  100000  with loss  9.764241218566895\n",
      "Training step  4551  of  100000  with loss  9.123165130615234\n",
      "Training step  4552  of  100000  with loss  10.747648239135742\n",
      "Training step  4553  of  100000  with loss  9.962007522583008\n",
      "Training step  4554  of  100000  with loss  10.484349250793457\n",
      "Training step  4555  of  100000  with loss  11.33236312866211\n",
      "Training step  4556  of  100000  with loss  9.58658218383789\n",
      "Training step  4557  of  100000  with loss  8.867180824279785\n",
      "Training step  4558  of  100000  with loss  9.692955017089844\n",
      "Training step  4559  of  100000  with loss  9.510496139526367\n",
      "Training step  4560  of  100000  with loss  9.21761417388916\n",
      "Training step  4561  of  100000  with loss  9.736601829528809\n",
      "Training step  4562  of  100000  with loss  10.119487762451172\n",
      "Training step  4563  of  100000  with loss  10.177961349487305\n",
      "Training step  4564  of  100000  with loss  10.36848258972168\n",
      "Training step  4565  of  100000  with loss  9.098689079284668\n",
      "Training step  4566  of  100000  with loss  10.667825698852539\n",
      "Training step  4567  of  100000  with loss  9.586908340454102\n",
      "Training step  4568  of  100000  with loss  9.394399642944336\n",
      "Training step  4569  of  100000  with loss  11.000913619995117\n",
      "Training step  4570  of  100000  with loss  10.348518371582031\n",
      "Training step  4571  of  100000  with loss  9.772454261779785\n",
      "Training step  4572  of  100000  with loss  9.219182968139648\n",
      "Training step  4573  of  100000  with loss  11.142927169799805\n",
      "Training step  4574  of  100000  with loss  9.995689392089844\n",
      "Training step  4575  of  100000  with loss  11.182319641113281\n",
      "Training step  4576  of  100000  with loss  10.401961326599121\n",
      "Training step  4577  of  100000  with loss  9.731958389282227\n",
      "Training step  4578  of  100000  with loss  9.458282470703125\n",
      "Training step  4579  of  100000  with loss  9.746683120727539\n",
      "Training step  4580  of  100000  with loss  9.876598358154297\n",
      "Training step  4581  of  100000  with loss  10.610445976257324\n",
      "Training step  4582  of  100000  with loss  10.135819435119629\n",
      "Training step  4583  of  100000  with loss  10.235471725463867\n",
      "Training step  4584  of  100000  with loss  9.51811408996582\n",
      "Training step  4585  of  100000  with loss  10.43399429321289\n",
      "Training step  4586  of  100000  with loss  10.581424713134766\n",
      "Training step  4587  of  100000  with loss  10.138949394226074\n",
      "Training step  4588  of  100000  with loss  10.286737442016602\n",
      "Training step  4589  of  100000  with loss  10.607383728027344\n",
      "Training step  4590  of  100000  with loss  9.9815034866333\n",
      "Training step  4591  of  100000  with loss  8.807440757751465\n",
      "Training step  4592  of  100000  with loss  10.151789665222168\n",
      "Training step  4593  of  100000  with loss  9.273524284362793\n",
      "Training step  4594  of  100000  with loss  9.979290008544922\n",
      "Training step  4595  of  100000  with loss  11.306817054748535\n",
      "Training step  4596  of  100000  with loss  10.52189826965332\n",
      "Training step  4597  of  100000  with loss  10.495538711547852\n",
      "Training step  4598  of  100000  with loss  8.646106719970703\n",
      "Training step  4599  of  100000  with loss  11.294778823852539\n",
      "Training step  4600  of  100000  with loss  9.42784309387207\n",
      "Training step  4601  of  100000  with loss  8.959874153137207\n",
      "Training step  4602  of  100000  with loss  9.819000244140625\n",
      "Training step  4603  of  100000  with loss  10.267868041992188\n",
      "Training step  4604  of  100000  with loss  9.538917541503906\n",
      "Training step  4605  of  100000  with loss  9.521232604980469\n",
      "Training step  4606  of  100000  with loss  8.912546157836914\n",
      "Training step  4607  of  100000  with loss  9.484539031982422\n",
      "Training step  4608  of  100000  with loss  9.159900665283203\n",
      "Training step  4609  of  100000  with loss  8.781355857849121\n",
      "Training step  4610  of  100000  with loss  12.317340850830078\n",
      "Training step  4611  of  100000  with loss  9.610352516174316\n",
      "Training step  4612  of  100000  with loss  9.620009422302246\n",
      "Training step  4613  of  100000  with loss  9.506608009338379\n",
      "Training step  4614  of  100000  with loss  10.286216735839844\n",
      "Training step  4615  of  100000  with loss  10.237208366394043\n",
      "Training step  4616  of  100000  with loss  10.259328842163086\n",
      "Training step  4617  of  100000  with loss  9.004844665527344\n",
      "Training step  4618  of  100000  with loss  9.430063247680664\n",
      "Training step  4619  of  100000  with loss  9.650522232055664\n",
      "Training step  4620  of  100000  with loss  10.865202903747559\n",
      "Training step  4621  of  100000  with loss  10.10766887664795\n",
      "Training step  4622  of  100000  with loss  11.270853042602539\n",
      "Training step  4623  of  100000  with loss  10.539979934692383\n",
      "Training step  4624  of  100000  with loss  11.444283485412598\n",
      "Training step  4625  of  100000  with loss  9.044352531433105\n",
      "Training step  4626  of  100000  with loss  9.823273658752441\n",
      "Training step  4627  of  100000  with loss  10.147119522094727\n",
      "Training step  4628  of  100000  with loss  9.890325546264648\n",
      "Training step  4629  of  100000  with loss  12.472855567932129\n",
      "Training step  4630  of  100000  with loss  9.906844139099121\n",
      "Training step  4631  of  100000  with loss  10.895721435546875\n",
      "Training step  4632  of  100000  with loss  9.252443313598633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4633  of  100000  with loss  9.242982864379883\n",
      "Training step  4634  of  100000  with loss  10.929267883300781\n",
      "Training step  4635  of  100000  with loss  9.760750770568848\n",
      "Training step  4636  of  100000  with loss  10.787160873413086\n",
      "Training step  4637  of  100000  with loss  9.223655700683594\n",
      "Training step  4638  of  100000  with loss  9.270814895629883\n",
      "Training step  4639  of  100000  with loss  10.252498626708984\n",
      "Training step  4640  of  100000  with loss  11.483343124389648\n",
      "Training step  4641  of  100000  with loss  10.533432006835938\n",
      "Training step  4642  of  100000  with loss  9.50085163116455\n",
      "Training step  4643  of  100000  with loss  9.359533309936523\n",
      "Training step  4644  of  100000  with loss  9.063583374023438\n",
      "Training step  4645  of  100000  with loss  8.575654983520508\n",
      "Training step  4646  of  100000  with loss  10.534521102905273\n",
      "Training step  4647  of  100000  with loss  8.440312385559082\n",
      "Training step  4648  of  100000  with loss  10.739582061767578\n",
      "Training step  4649  of  100000  with loss  9.089527130126953\n",
      "Training step  4650  of  100000  with loss  9.380529403686523\n",
      "Training step  4651  of  100000  with loss  10.424667358398438\n",
      "Training step  4652  of  100000  with loss  9.832010269165039\n",
      "Training step  4653  of  100000  with loss  9.858274459838867\n",
      "Training step  4654  of  100000  with loss  10.058328628540039\n",
      "Training step  4655  of  100000  with loss  9.809585571289062\n",
      "Training step  4656  of  100000  with loss  10.889389991760254\n",
      "Training step  4657  of  100000  with loss  10.185787200927734\n",
      "Training step  4658  of  100000  with loss  8.576601028442383\n",
      "Training step  4659  of  100000  with loss  9.331993103027344\n",
      "Training step  4660  of  100000  with loss  9.961177825927734\n",
      "Training step  4661  of  100000  with loss  9.326431274414062\n",
      "Training step  4662  of  100000  with loss  9.155982971191406\n",
      "Training step  4663  of  100000  with loss  9.459439277648926\n",
      "Training step  4664  of  100000  with loss  9.779378890991211\n",
      "Training step  4665  of  100000  with loss  9.963850021362305\n",
      "Training step  4666  of  100000  with loss  9.36909008026123\n",
      "Training step  4667  of  100000  with loss  9.821427345275879\n",
      "Training step  4668  of  100000  with loss  8.872753143310547\n",
      "Training step  4669  of  100000  with loss  9.447553634643555\n",
      "Training step  4670  of  100000  with loss  11.177075386047363\n",
      "Training step  4671  of  100000  with loss  10.443717956542969\n",
      "Training step  4672  of  100000  with loss  11.482671737670898\n",
      "Training step  4673  of  100000  with loss  10.1719970703125\n",
      "Training step  4674  of  100000  with loss  9.799544334411621\n",
      "Training step  4675  of  100000  with loss  10.545263290405273\n",
      "Training step  4676  of  100000  with loss  9.588077545166016\n",
      "Training step  4677  of  100000  with loss  10.160133361816406\n",
      "Training step  4678  of  100000  with loss  10.496452331542969\n",
      "Training step  4679  of  100000  with loss  10.824052810668945\n",
      "Training step  4680  of  100000  with loss  10.607036590576172\n",
      "Training step  4681  of  100000  with loss  10.084592819213867\n",
      "Training step  4682  of  100000  with loss  9.990194320678711\n",
      "Training step  4683  of  100000  with loss  8.472187042236328\n",
      "Training step  4684  of  100000  with loss  9.773639678955078\n",
      "Training step  4685  of  100000  with loss  11.575286865234375\n",
      "Training step  4686  of  100000  with loss  9.021086692810059\n",
      "Training step  4687  of  100000  with loss  11.267585754394531\n",
      "Training step  4688  of  100000  with loss  9.781514167785645\n",
      "Training step  4689  of  100000  with loss  10.705162048339844\n",
      "Training step  4690  of  100000  with loss  11.436098098754883\n",
      "Training step  4691  of  100000  with loss  10.492992401123047\n",
      "Training step  4692  of  100000  with loss  9.948939323425293\n",
      "Training step  4693  of  100000  with loss  9.53980827331543\n",
      "Training step  4694  of  100000  with loss  10.583287239074707\n",
      "Training step  4695  of  100000  with loss  9.574385643005371\n",
      "Training step  4696  of  100000  with loss  10.947078704833984\n",
      "Training step  4697  of  100000  with loss  10.071340560913086\n",
      "Training step  4698  of  100000  with loss  9.53551197052002\n",
      "Training step  4699  of  100000  with loss  9.28792953491211\n",
      "Training step  4700  of  100000  with loss  9.051750183105469\n",
      "Training step  4701  of  100000  with loss  10.2944917678833\n",
      "Training step  4702  of  100000  with loss  9.555391311645508\n",
      "Training step  4703  of  100000  with loss  10.862972259521484\n",
      "Training step  4704  of  100000  with loss  9.819478988647461\n",
      "Training step  4705  of  100000  with loss  10.697763442993164\n",
      "Training step  4706  of  100000  with loss  10.607498168945312\n",
      "Training step  4707  of  100000  with loss  9.453408241271973\n",
      "Training step  4708  of  100000  with loss  10.186241149902344\n",
      "Training step  4709  of  100000  with loss  10.367049217224121\n",
      "Training step  4710  of  100000  with loss  11.244194984436035\n",
      "Training step  4711  of  100000  with loss  9.73913288116455\n",
      "Training step  4712  of  100000  with loss  11.094635009765625\n",
      "Training step  4713  of  100000  with loss  9.730515480041504\n",
      "Training step  4714  of  100000  with loss  9.768528938293457\n",
      "Training step  4715  of  100000  with loss  9.72580337524414\n",
      "Training step  4716  of  100000  with loss  10.620800018310547\n",
      "Training step  4717  of  100000  with loss  8.668548583984375\n",
      "Training step  4718  of  100000  with loss  9.545877456665039\n",
      "Training step  4719  of  100000  with loss  10.441648483276367\n",
      "Training step  4720  of  100000  with loss  10.860550880432129\n",
      "Training step  4721  of  100000  with loss  9.424174308776855\n",
      "Training step  4722  of  100000  with loss  8.941370010375977\n",
      "Training step  4723  of  100000  with loss  9.6863374710083\n",
      "Training step  4724  of  100000  with loss  9.642600059509277\n",
      "Training step  4725  of  100000  with loss  9.650062561035156\n",
      "Training step  4726  of  100000  with loss  11.830078125\n",
      "Training step  4727  of  100000  with loss  9.021590232849121\n",
      "Training step  4728  of  100000  with loss  9.683521270751953\n",
      "Training step  4729  of  100000  with loss  9.50619888305664\n",
      "Training step  4730  of  100000  with loss  9.404809951782227\n",
      "Training step  4731  of  100000  with loss  10.39210033416748\n",
      "Training step  4732  of  100000  with loss  10.084142684936523\n",
      "Training step  4733  of  100000  with loss  10.162519454956055\n",
      "Training step  4734  of  100000  with loss  12.285633087158203\n",
      "Training step  4735  of  100000  with loss  9.50115966796875\n",
      "Training step  4736  of  100000  with loss  9.139785766601562\n",
      "Training step  4737  of  100000  with loss  10.154415130615234\n",
      "Training step  4738  of  100000  with loss  9.942349433898926\n",
      "Training step  4739  of  100000  with loss  10.272951126098633\n",
      "Training step  4740  of  100000  with loss  9.607521057128906\n",
      "Training step  4741  of  100000  with loss  10.52398681640625\n",
      "Training step  4742  of  100000  with loss  8.340279579162598\n",
      "Training step  4743  of  100000  with loss  9.997699737548828\n",
      "Training step  4744  of  100000  with loss  9.292407035827637\n",
      "Training step  4745  of  100000  with loss  9.019107818603516\n",
      "Training step  4746  of  100000  with loss  9.289518356323242\n",
      "Training step  4747  of  100000  with loss  9.390377044677734\n",
      "Training step  4748  of  100000  with loss  9.6559419631958\n",
      "Training step  4749  of  100000  with loss  11.090593338012695\n",
      "Training step  4750  of  100000  with loss  10.1055908203125\n",
      "Training step  4751  of  100000  with loss  10.107418060302734\n",
      "Training step  4752  of  100000  with loss  10.20781135559082\n",
      "Training step  4753  of  100000  with loss  9.015432357788086\n",
      "Training step  4754  of  100000  with loss  9.498661041259766\n",
      "Training step  4755  of  100000  with loss  9.99106502532959\n",
      "Training step  4756  of  100000  with loss  9.473934173583984\n",
      "Training step  4757  of  100000  with loss  10.64077091217041\n",
      "Training step  4758  of  100000  with loss  8.740653991699219\n",
      "Training step  4759  of  100000  with loss  11.434082984924316\n",
      "Training step  4760  of  100000  with loss  10.083297729492188\n",
      "Training step  4761  of  100000  with loss  8.978873252868652\n",
      "Training step  4762  of  100000  with loss  10.791065216064453\n",
      "Training step  4763  of  100000  with loss  12.197919845581055\n",
      "Training step  4764  of  100000  with loss  9.995304107666016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4765  of  100000  with loss  9.880678176879883\n",
      "Training step  4766  of  100000  with loss  11.095903396606445\n",
      "Training step  4767  of  100000  with loss  10.42354965209961\n",
      "Training step  4768  of  100000  with loss  10.19432544708252\n",
      "Training step  4769  of  100000  with loss  8.712583541870117\n",
      "Training step  4770  of  100000  with loss  8.98666000366211\n",
      "Training step  4771  of  100000  with loss  9.860858917236328\n",
      "Training step  4772  of  100000  with loss  10.256699562072754\n",
      "Training step  4773  of  100000  with loss  10.036968231201172\n",
      "Training step  4774  of  100000  with loss  9.463106155395508\n",
      "Training step  4775  of  100000  with loss  12.078750610351562\n",
      "Training step  4776  of  100000  with loss  9.283353805541992\n",
      "Training step  4777  of  100000  with loss  9.435975074768066\n",
      "Training step  4778  of  100000  with loss  9.896590232849121\n",
      "Training step  4779  of  100000  with loss  10.59530258178711\n",
      "Training step  4780  of  100000  with loss  9.913339614868164\n",
      "Training step  4781  of  100000  with loss  10.461368560791016\n",
      "Training step  4782  of  100000  with loss  10.158378601074219\n",
      "Training step  4783  of  100000  with loss  10.428474426269531\n",
      "Training step  4784  of  100000  with loss  11.455734252929688\n",
      "Training step  4785  of  100000  with loss  9.992671966552734\n",
      "Training step  4786  of  100000  with loss  10.75136661529541\n",
      "Training step  4787  of  100000  with loss  10.081445693969727\n",
      "Training step  4788  of  100000  with loss  8.950404167175293\n",
      "Training step  4789  of  100000  with loss  10.573379516601562\n",
      "Training step  4790  of  100000  with loss  9.966569900512695\n",
      "Training step  4791  of  100000  with loss  10.48198127746582\n",
      "Training step  4792  of  100000  with loss  9.905647277832031\n",
      "Training step  4793  of  100000  with loss  8.79987907409668\n",
      "Training step  4794  of  100000  with loss  10.103565216064453\n",
      "Training step  4795  of  100000  with loss  10.265008926391602\n",
      "Training step  4796  of  100000  with loss  11.414998054504395\n",
      "Training step  4797  of  100000  with loss  9.881832122802734\n",
      "Training step  4798  of  100000  with loss  10.647472381591797\n",
      "Training step  4799  of  100000  with loss  10.861597061157227\n",
      "Training step  4800  of  100000  with loss  9.869363784790039\n",
      "Training step  4801  of  100000  with loss  9.429117202758789\n",
      "Training step  4802  of  100000  with loss  9.667947769165039\n",
      "Training step  4803  of  100000  with loss  11.887724876403809\n",
      "Training step  4804  of  100000  with loss  9.578729629516602\n",
      "Training step  4805  of  100000  with loss  10.298639297485352\n",
      "Training step  4806  of  100000  with loss  11.146936416625977\n",
      "Training step  4807  of  100000  with loss  11.283815383911133\n",
      "Training step  4808  of  100000  with loss  9.26679801940918\n",
      "Training step  4809  of  100000  with loss  10.491880416870117\n",
      "Training step  4810  of  100000  with loss  10.88198471069336\n",
      "Training step  4811  of  100000  with loss  10.877686500549316\n",
      "Training step  4812  of  100000  with loss  8.923218727111816\n",
      "Training step  4813  of  100000  with loss  11.387624740600586\n",
      "Training step  4814  of  100000  with loss  9.537052154541016\n",
      "Training step  4815  of  100000  with loss  10.358968734741211\n",
      "Training step  4816  of  100000  with loss  9.55435562133789\n",
      "Training step  4817  of  100000  with loss  9.999420166015625\n",
      "Training step  4818  of  100000  with loss  10.446250915527344\n",
      "Training step  4819  of  100000  with loss  10.473538398742676\n",
      "Training step  4820  of  100000  with loss  11.024478912353516\n",
      "Training step  4821  of  100000  with loss  10.251876831054688\n",
      "Training step  4822  of  100000  with loss  8.941293716430664\n",
      "Training step  4823  of  100000  with loss  10.128766059875488\n",
      "Training step  4824  of  100000  with loss  9.162109375\n",
      "Training step  4825  of  100000  with loss  11.611835479736328\n",
      "Training step  4826  of  100000  with loss  10.101251602172852\n",
      "Training step  4827  of  100000  with loss  10.199522018432617\n",
      "Training step  4828  of  100000  with loss  9.72485637664795\n",
      "Training step  4829  of  100000  with loss  10.668834686279297\n",
      "Training step  4830  of  100000  with loss  10.204816818237305\n",
      "Training step  4831  of  100000  with loss  10.651884078979492\n",
      "Training step  4832  of  100000  with loss  8.889144897460938\n",
      "Training step  4833  of  100000  with loss  9.8296480178833\n",
      "Training step  4834  of  100000  with loss  9.311388969421387\n",
      "Training step  4835  of  100000  with loss  9.903949737548828\n",
      "Training step  4836  of  100000  with loss  12.057437896728516\n",
      "Training step  4837  of  100000  with loss  10.294992446899414\n",
      "Training step  4838  of  100000  with loss  9.580101013183594\n",
      "Training step  4839  of  100000  with loss  9.832565307617188\n",
      "Training step  4840  of  100000  with loss  11.022743225097656\n",
      "Training step  4841  of  100000  with loss  9.323662757873535\n",
      "Training step  4842  of  100000  with loss  8.944753646850586\n",
      "Training step  4843  of  100000  with loss  8.844030380249023\n",
      "Training step  4844  of  100000  with loss  10.873335838317871\n",
      "Training step  4845  of  100000  with loss  9.985039710998535\n",
      "Training step  4846  of  100000  with loss  11.014389038085938\n",
      "Training step  4847  of  100000  with loss  9.887838363647461\n",
      "Training step  4848  of  100000  with loss  11.063772201538086\n",
      "Training step  4849  of  100000  with loss  10.331015586853027\n",
      "Training step  4850  of  100000  with loss  10.204453468322754\n",
      "Training step  4851  of  100000  with loss  9.185419082641602\n",
      "Training step  4852  of  100000  with loss  10.04692268371582\n",
      "Training step  4853  of  100000  with loss  9.615665435791016\n",
      "Training step  4854  of  100000  with loss  10.760669708251953\n",
      "Training step  4855  of  100000  with loss  10.742578506469727\n",
      "Training step  4856  of  100000  with loss  9.3831787109375\n",
      "Training step  4857  of  100000  with loss  11.479634284973145\n",
      "Training step  4858  of  100000  with loss  9.744415283203125\n",
      "Training step  4859  of  100000  with loss  9.736347198486328\n",
      "Training step  4860  of  100000  with loss  10.139410018920898\n",
      "Training step  4861  of  100000  with loss  9.352407455444336\n",
      "Training step  4862  of  100000  with loss  9.448341369628906\n",
      "Training step  4863  of  100000  with loss  9.886415481567383\n",
      "Training step  4864  of  100000  with loss  9.785837173461914\n",
      "Training step  4865  of  100000  with loss  10.841079711914062\n",
      "Training step  4866  of  100000  with loss  9.950471878051758\n",
      "Training step  4867  of  100000  with loss  9.9940824508667\n",
      "Training step  4868  of  100000  with loss  9.808897972106934\n",
      "Training step  4869  of  100000  with loss  10.22033405303955\n",
      "Training step  4870  of  100000  with loss  10.185232162475586\n",
      "Training step  4871  of  100000  with loss  10.517499923706055\n",
      "Training step  4872  of  100000  with loss  9.14285659790039\n",
      "Training step  4873  of  100000  with loss  9.937606811523438\n",
      "Training step  4874  of  100000  with loss  10.588716506958008\n",
      "Training step  4875  of  100000  with loss  10.069341659545898\n",
      "Training step  4876  of  100000  with loss  9.946782112121582\n",
      "Training step  4877  of  100000  with loss  11.753231048583984\n",
      "Training step  4878  of  100000  with loss  9.967262268066406\n",
      "Training step  4879  of  100000  with loss  10.296823501586914\n",
      "Training step  4880  of  100000  with loss  9.720995903015137\n",
      "Training step  4881  of  100000  with loss  10.124940872192383\n",
      "Training step  4882  of  100000  with loss  11.780092239379883\n",
      "Training step  4883  of  100000  with loss  10.562145233154297\n",
      "Training step  4884  of  100000  with loss  9.04825210571289\n",
      "Training step  4885  of  100000  with loss  10.013410568237305\n",
      "Training step  4886  of  100000  with loss  9.63390827178955\n",
      "Training step  4887  of  100000  with loss  10.113537788391113\n",
      "Training step  4888  of  100000  with loss  9.487849235534668\n",
      "Training step  4889  of  100000  with loss  9.256938934326172\n",
      "Training step  4890  of  100000  with loss  9.46529483795166\n",
      "Training step  4891  of  100000  with loss  10.387275695800781\n",
      "Training step  4892  of  100000  with loss  10.263348579406738\n",
      "Training step  4893  of  100000  with loss  9.401054382324219\n",
      "Training step  4894  of  100000  with loss  8.52145767211914\n",
      "Training step  4895  of  100000  with loss  9.023466110229492\n",
      "Training step  4896  of  100000  with loss  8.818137168884277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  4897  of  100000  with loss  11.019430160522461\n",
      "Training step  4898  of  100000  with loss  10.428117752075195\n",
      "Training step  4899  of  100000  with loss  9.674772262573242\n",
      "Training step  4900  of  100000  with loss  9.420690536499023\n",
      "Training step  4901  of  100000  with loss  9.426559448242188\n",
      "Training step  4902  of  100000  with loss  9.822840690612793\n",
      "Training step  4903  of  100000  with loss  10.193233489990234\n",
      "Training step  4904  of  100000  with loss  9.7137451171875\n",
      "Training step  4905  of  100000  with loss  9.046425819396973\n",
      "Training step  4906  of  100000  with loss  10.084076881408691\n",
      "Training step  4907  of  100000  with loss  9.793537139892578\n",
      "Training step  4908  of  100000  with loss  9.697158813476562\n",
      "Training step  4909  of  100000  with loss  9.56043529510498\n",
      "Training step  4910  of  100000  with loss  9.202566146850586\n",
      "Training step  4911  of  100000  with loss  9.201059341430664\n",
      "Training step  4912  of  100000  with loss  11.289676666259766\n",
      "Training step  4913  of  100000  with loss  9.428475379943848\n",
      "Training step  4914  of  100000  with loss  10.717435836791992\n",
      "Training step  4915  of  100000  with loss  9.167786598205566\n",
      "Training step  4916  of  100000  with loss  10.81692123413086\n",
      "Training step  4917  of  100000  with loss  9.684616088867188\n",
      "Training step  4918  of  100000  with loss  10.040915489196777\n",
      "Training step  4919  of  100000  with loss  9.976139068603516\n",
      "Training step  4920  of  100000  with loss  9.04456901550293\n",
      "Training step  4921  of  100000  with loss  9.262530326843262\n",
      "Training step  4922  of  100000  with loss  8.665153503417969\n",
      "Training step  4923  of  100000  with loss  12.356295585632324\n",
      "Training step  4924  of  100000  with loss  10.461220741271973\n",
      "Training step  4925  of  100000  with loss  10.32099723815918\n",
      "Training step  4926  of  100000  with loss  9.758642196655273\n",
      "Training step  4927  of  100000  with loss  9.054418563842773\n",
      "Training step  4928  of  100000  with loss  11.087654113769531\n",
      "Training step  4929  of  100000  with loss  9.532734870910645\n",
      "Training step  4930  of  100000  with loss  9.863351821899414\n",
      "Training step  4931  of  100000  with loss  11.796316146850586\n",
      "Training step  4932  of  100000  with loss  11.26982307434082\n",
      "Training step  4933  of  100000  with loss  9.543534278869629\n",
      "Training step  4934  of  100000  with loss  9.252257347106934\n",
      "Training step  4935  of  100000  with loss  8.691668510437012\n",
      "Training step  4936  of  100000  with loss  10.299732208251953\n",
      "Training step  4937  of  100000  with loss  10.58642578125\n",
      "Training step  4938  of  100000  with loss  9.300878524780273\n",
      "Training step  4939  of  100000  with loss  9.17689323425293\n",
      "Training step  4940  of  100000  with loss  9.535162925720215\n",
      "Training step  4941  of  100000  with loss  9.299694061279297\n",
      "Training step  4942  of  100000  with loss  9.211380004882812\n",
      "Training step  4943  of  100000  with loss  9.574084281921387\n",
      "Training step  4944  of  100000  with loss  10.301738739013672\n",
      "Training step  4945  of  100000  with loss  10.372730255126953\n",
      "Training step  4946  of  100000  with loss  10.2652006149292\n",
      "Training step  4947  of  100000  with loss  10.402511596679688\n",
      "Training step  4948  of  100000  with loss  9.600915908813477\n",
      "Training step  4949  of  100000  with loss  10.010285377502441\n",
      "Training step  4950  of  100000  with loss  9.761565208435059\n",
      "Training step  4951  of  100000  with loss  9.483133316040039\n",
      "Training step  4952  of  100000  with loss  10.801214218139648\n",
      "Training step  4953  of  100000  with loss  10.506102561950684\n",
      "Training step  4954  of  100000  with loss  10.21090316772461\n",
      "Training step  4955  of  100000  with loss  9.55117130279541\n",
      "Training step  4956  of  100000  with loss  8.942806243896484\n",
      "Training step  4957  of  100000  with loss  9.33200740814209\n",
      "Training step  4958  of  100000  with loss  9.50910758972168\n",
      "Training step  4959  of  100000  with loss  10.941641807556152\n",
      "Training step  4960  of  100000  with loss  9.351524353027344\n",
      "Training step  4961  of  100000  with loss  9.363302230834961\n",
      "Training step  4962  of  100000  with loss  10.015020370483398\n",
      "Training step  4963  of  100000  with loss  9.509739875793457\n",
      "Training step  4964  of  100000  with loss  9.471962928771973\n",
      "Training step  4965  of  100000  with loss  9.38853645324707\n",
      "Training step  4966  of  100000  with loss  9.446310997009277\n",
      "Training step  4967  of  100000  with loss  8.876096725463867\n",
      "Training step  4968  of  100000  with loss  10.321846008300781\n",
      "Training step  4969  of  100000  with loss  10.116371154785156\n",
      "Training step  4970  of  100000  with loss  10.90977668762207\n",
      "Training step  4971  of  100000  with loss  9.878726959228516\n",
      "Training step  4972  of  100000  with loss  10.320688247680664\n",
      "Training step  4973  of  100000  with loss  9.096097946166992\n",
      "Training step  4974  of  100000  with loss  10.054166793823242\n",
      "Training step  4975  of  100000  with loss  10.649845123291016\n",
      "Training step  4976  of  100000  with loss  9.984729766845703\n",
      "Training step  4977  of  100000  with loss  10.104490280151367\n",
      "Training step  4978  of  100000  with loss  9.09300708770752\n",
      "Training step  4979  of  100000  with loss  9.266425132751465\n",
      "Training step  4980  of  100000  with loss  10.161151885986328\n",
      "Training step  4981  of  100000  with loss  10.20305061340332\n",
      "Training step  4982  of  100000  with loss  9.540517807006836\n",
      "Training step  4983  of  100000  with loss  10.231762886047363\n",
      "Training step  4984  of  100000  with loss  8.580894470214844\n",
      "Training step  4985  of  100000  with loss  9.68919563293457\n",
      "Training step  4986  of  100000  with loss  9.060195922851562\n",
      "Training step  4987  of  100000  with loss  10.241060256958008\n",
      "Training step  4988  of  100000  with loss  9.651752471923828\n",
      "Training step  4989  of  100000  with loss  10.34211254119873\n",
      "Training step  4990  of  100000  with loss  9.62800407409668\n",
      "Training step  4991  of  100000  with loss  10.968276023864746\n",
      "Training step  4992  of  100000  with loss  11.739801406860352\n",
      "Training step  4993  of  100000  with loss  9.268378257751465\n",
      "Training step  4994  of  100000  with loss  9.01168155670166\n",
      "Training step  4995  of  100000  with loss  9.627809524536133\n",
      "Training step  4996  of  100000  with loss  9.938278198242188\n",
      "Training step  4997  of  100000  with loss  10.962077140808105\n",
      "Training step  4998  of  100000  with loss  9.896821975708008\n",
      "Training step  4999  of  100000  with loss  9.464984893798828\n",
      "Training step  5000  of  100000  with loss  11.245038986206055\n",
      "Training step  5001  of  100000  with loss  9.791686058044434\n",
      "Training step  5002  of  100000  with loss  10.12823486328125\n",
      "Training step  5003  of  100000  with loss  9.988065719604492\n",
      "Training step  5004  of  100000  with loss  9.19731330871582\n",
      "Training step  5005  of  100000  with loss  9.482114791870117\n",
      "Training step  5006  of  100000  with loss  8.694993019104004\n",
      "Training step  5007  of  100000  with loss  10.133626937866211\n",
      "Training step  5008  of  100000  with loss  8.936534881591797\n",
      "Training step  5009  of  100000  with loss  10.825094223022461\n",
      "Training step  5010  of  100000  with loss  9.739385604858398\n",
      "Training step  5011  of  100000  with loss  10.134994506835938\n",
      "Training step  5012  of  100000  with loss  9.633184432983398\n",
      "Training step  5013  of  100000  with loss  11.328473091125488\n",
      "Training step  5014  of  100000  with loss  8.928842544555664\n",
      "Training step  5015  of  100000  with loss  10.380338668823242\n",
      "Training step  5016  of  100000  with loss  10.049979209899902\n",
      "Training step  5017  of  100000  with loss  10.490610122680664\n",
      "Training step  5018  of  100000  with loss  10.150105476379395\n",
      "Training step  5019  of  100000  with loss  10.311469078063965\n",
      "Training step  5020  of  100000  with loss  10.499135971069336\n",
      "Training step  5021  of  100000  with loss  9.347408294677734\n",
      "Training step  5022  of  100000  with loss  11.973758697509766\n",
      "Training step  5023  of  100000  with loss  9.965630531311035\n",
      "Training step  5024  of  100000  with loss  9.81200885772705\n",
      "Training step  5025  of  100000  with loss  10.37039566040039\n",
      "Training step  5026  of  100000  with loss  9.537195205688477\n",
      "Training step  5027  of  100000  with loss  9.95475959777832\n",
      "Training step  5028  of  100000  with loss  9.41889762878418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5029  of  100000  with loss  9.402379989624023\n",
      "Training step  5030  of  100000  with loss  10.187734603881836\n",
      "Training step  5031  of  100000  with loss  11.99789047241211\n",
      "Training step  5032  of  100000  with loss  7.952140808105469\n",
      "Training step  5033  of  100000  with loss  10.933151245117188\n",
      "Training step  5034  of  100000  with loss  10.727781295776367\n",
      "Training step  5035  of  100000  with loss  9.23553466796875\n",
      "Training step  5036  of  100000  with loss  10.469086647033691\n",
      "Training step  5037  of  100000  with loss  8.817954063415527\n",
      "Training step  5038  of  100000  with loss  9.732124328613281\n",
      "Training step  5039  of  100000  with loss  9.532604217529297\n",
      "Training step  5040  of  100000  with loss  8.845837593078613\n",
      "Training step  5041  of  100000  with loss  9.511709213256836\n",
      "Training step  5042  of  100000  with loss  9.857617378234863\n",
      "Training step  5043  of  100000  with loss  8.768320083618164\n",
      "Training step  5044  of  100000  with loss  10.111841201782227\n",
      "Training step  5045  of  100000  with loss  9.742130279541016\n",
      "Training step  5046  of  100000  with loss  9.421167373657227\n",
      "Training step  5047  of  100000  with loss  10.700362205505371\n",
      "Training step  5048  of  100000  with loss  9.925050735473633\n",
      "Training step  5049  of  100000  with loss  11.167343139648438\n",
      "Training step  5050  of  100000  with loss  11.311738967895508\n",
      "Training step  5051  of  100000  with loss  9.997379302978516\n",
      "Training step  5052  of  100000  with loss  11.043216705322266\n",
      "Training step  5053  of  100000  with loss  10.279179573059082\n",
      "Training step  5054  of  100000  with loss  11.767115592956543\n",
      "Training step  5055  of  100000  with loss  9.620126724243164\n",
      "Training step  5056  of  100000  with loss  9.75850772857666\n",
      "Training step  5057  of  100000  with loss  8.165273666381836\n",
      "Training step  5058  of  100000  with loss  9.315706253051758\n",
      "Training step  5059  of  100000  with loss  9.700054168701172\n",
      "Training step  5060  of  100000  with loss  9.356012344360352\n",
      "Training step  5061  of  100000  with loss  8.408646583557129\n",
      "Training step  5062  of  100000  with loss  10.321612358093262\n",
      "Training step  5063  of  100000  with loss  9.28335189819336\n",
      "Training step  5064  of  100000  with loss  10.454608917236328\n",
      "Training step  5065  of  100000  with loss  9.876850128173828\n",
      "Training step  5066  of  100000  with loss  11.724571228027344\n",
      "Training step  5067  of  100000  with loss  10.154407501220703\n",
      "Training step  5068  of  100000  with loss  10.650667190551758\n",
      "Training step  5069  of  100000  with loss  8.618819236755371\n",
      "Training step  5070  of  100000  with loss  8.880285263061523\n",
      "Training step  5071  of  100000  with loss  10.7943115234375\n",
      "Training step  5072  of  100000  with loss  9.619020462036133\n",
      "Training step  5073  of  100000  with loss  9.283544540405273\n",
      "Training step  5074  of  100000  with loss  9.563626289367676\n",
      "Training step  5075  of  100000  with loss  9.867610931396484\n",
      "Training step  5076  of  100000  with loss  10.639483451843262\n",
      "Training step  5077  of  100000  with loss  10.940662384033203\n",
      "Training step  5078  of  100000  with loss  10.504274368286133\n",
      "Training step  5079  of  100000  with loss  9.952622413635254\n",
      "Training step  5080  of  100000  with loss  10.500728607177734\n",
      "Training step  5081  of  100000  with loss  10.036613464355469\n",
      "Training step  5082  of  100000  with loss  9.76266098022461\n",
      "Training step  5083  of  100000  with loss  9.079854965209961\n",
      "Training step  5084  of  100000  with loss  9.808177947998047\n",
      "Training step  5085  of  100000  with loss  10.941274642944336\n",
      "Training step  5086  of  100000  with loss  9.987017631530762\n",
      "Training step  5087  of  100000  with loss  10.16346263885498\n",
      "Training step  5088  of  100000  with loss  11.472212791442871\n",
      "Training step  5089  of  100000  with loss  9.814126968383789\n",
      "Training step  5090  of  100000  with loss  10.199690818786621\n",
      "Training step  5091  of  100000  with loss  11.377201080322266\n",
      "Training step  5092  of  100000  with loss  11.116228103637695\n",
      "Training step  5093  of  100000  with loss  10.941078186035156\n",
      "Training step  5094  of  100000  with loss  9.484914779663086\n",
      "Training step  5095  of  100000  with loss  8.820674896240234\n",
      "Training step  5096  of  100000  with loss  9.896571159362793\n",
      "Training step  5097  of  100000  with loss  8.798526763916016\n",
      "Training step  5098  of  100000  with loss  9.389620780944824\n",
      "Training step  5099  of  100000  with loss  10.867744445800781\n",
      "Training step  5100  of  100000  with loss  10.066478729248047\n",
      "Training step  5101  of  100000  with loss  9.697277069091797\n",
      "Training step  5102  of  100000  with loss  9.078144073486328\n",
      "Training step  5103  of  100000  with loss  9.22391128540039\n",
      "Training step  5104  of  100000  with loss  9.61851692199707\n",
      "Training step  5105  of  100000  with loss  8.695874214172363\n",
      "Training step  5106  of  100000  with loss  10.039072036743164\n",
      "Training step  5107  of  100000  with loss  9.012974739074707\n",
      "Training step  5108  of  100000  with loss  9.444758415222168\n",
      "Training step  5109  of  100000  with loss  10.484102249145508\n",
      "Training step  5110  of  100000  with loss  9.997882843017578\n",
      "Training step  5111  of  100000  with loss  10.159342765808105\n",
      "Training step  5112  of  100000  with loss  10.651395797729492\n",
      "Training step  5113  of  100000  with loss  9.778495788574219\n",
      "Training step  5114  of  100000  with loss  10.728996276855469\n",
      "Training step  5115  of  100000  with loss  10.34747314453125\n",
      "Training step  5116  of  100000  with loss  10.410865783691406\n",
      "Training step  5117  of  100000  with loss  9.250755310058594\n",
      "Training step  5118  of  100000  with loss  9.403626441955566\n",
      "Training step  5119  of  100000  with loss  10.859115600585938\n",
      "Training step  5120  of  100000  with loss  10.138208389282227\n",
      "Training step  5121  of  100000  with loss  9.159090042114258\n",
      "Training step  5122  of  100000  with loss  10.910511016845703\n",
      "Training step  5123  of  100000  with loss  8.579198837280273\n",
      "Training step  5124  of  100000  with loss  8.56475830078125\n",
      "Training step  5125  of  100000  with loss  10.975391387939453\n",
      "Training step  5126  of  100000  with loss  10.89918327331543\n",
      "Training step  5127  of  100000  with loss  10.189048767089844\n",
      "Training step  5128  of  100000  with loss  10.957049369812012\n",
      "Training step  5129  of  100000  with loss  8.944046020507812\n",
      "Training step  5130  of  100000  with loss  10.622102737426758\n",
      "Training step  5131  of  100000  with loss  8.475625038146973\n",
      "Training step  5132  of  100000  with loss  10.679449081420898\n",
      "Training step  5133  of  100000  with loss  10.245994567871094\n",
      "Training step  5134  of  100000  with loss  9.68427848815918\n",
      "Training step  5135  of  100000  with loss  10.455448150634766\n",
      "Training step  5136  of  100000  with loss  12.068050384521484\n",
      "Training step  5137  of  100000  with loss  10.034479141235352\n",
      "Training step  5138  of  100000  with loss  9.673028945922852\n",
      "Training step  5139  of  100000  with loss  9.672469139099121\n",
      "Training step  5140  of  100000  with loss  9.843999862670898\n",
      "Training step  5141  of  100000  with loss  10.387786865234375\n",
      "Training step  5142  of  100000  with loss  11.082208633422852\n",
      "Training step  5143  of  100000  with loss  9.813215255737305\n",
      "Training step  5144  of  100000  with loss  9.79883098602295\n",
      "Training step  5145  of  100000  with loss  8.672304153442383\n",
      "Training step  5146  of  100000  with loss  9.553006172180176\n",
      "Training step  5147  of  100000  with loss  10.019918441772461\n",
      "Training step  5148  of  100000  with loss  10.728211402893066\n",
      "Training step  5149  of  100000  with loss  9.035503387451172\n",
      "Training step  5150  of  100000  with loss  9.311325073242188\n",
      "Training step  5151  of  100000  with loss  9.86764907836914\n",
      "Training step  5152  of  100000  with loss  10.733593940734863\n",
      "Training step  5153  of  100000  with loss  10.576705932617188\n",
      "Training step  5154  of  100000  with loss  9.167957305908203\n",
      "Training step  5155  of  100000  with loss  9.908635139465332\n",
      "Training step  5156  of  100000  with loss  10.855042457580566\n",
      "Training step  5157  of  100000  with loss  10.62159538269043\n",
      "Training step  5158  of  100000  with loss  10.926328659057617\n",
      "Training step  5159  of  100000  with loss  11.174379348754883\n",
      "Training step  5160  of  100000  with loss  10.1516752243042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5161  of  100000  with loss  9.872184753417969\n",
      "Training step  5162  of  100000  with loss  9.340057373046875\n",
      "Training step  5163  of  100000  with loss  8.92611312866211\n",
      "Training step  5164  of  100000  with loss  9.826297760009766\n",
      "Training step  5165  of  100000  with loss  10.068857192993164\n",
      "Training step  5166  of  100000  with loss  10.309844017028809\n",
      "Training step  5167  of  100000  with loss  11.934137344360352\n",
      "Training step  5168  of  100000  with loss  9.914043426513672\n",
      "Training step  5169  of  100000  with loss  9.733695983886719\n",
      "Training step  5170  of  100000  with loss  9.991811752319336\n",
      "Training step  5171  of  100000  with loss  10.189340591430664\n",
      "Training step  5172  of  100000  with loss  9.499335289001465\n",
      "Training step  5173  of  100000  with loss  9.660144805908203\n",
      "Training step  5174  of  100000  with loss  9.767226219177246\n",
      "Training step  5175  of  100000  with loss  9.65254020690918\n",
      "Training step  5176  of  100000  with loss  9.66641616821289\n",
      "Training step  5177  of  100000  with loss  11.496429443359375\n",
      "Training step  5178  of  100000  with loss  10.942866325378418\n",
      "Training step  5179  of  100000  with loss  11.253429412841797\n",
      "Training step  5180  of  100000  with loss  11.71723461151123\n",
      "Training step  5181  of  100000  with loss  9.972633361816406\n",
      "Training step  5182  of  100000  with loss  10.871359825134277\n",
      "Training step  5183  of  100000  with loss  11.104421615600586\n",
      "Training step  5184  of  100000  with loss  10.730831146240234\n",
      "Training step  5185  of  100000  with loss  11.465877532958984\n",
      "Training step  5186  of  100000  with loss  9.360832214355469\n",
      "Training step  5187  of  100000  with loss  8.633675575256348\n",
      "Training step  5188  of  100000  with loss  10.772049903869629\n",
      "Training step  5189  of  100000  with loss  12.11549186706543\n",
      "Training step  5190  of  100000  with loss  9.264986991882324\n",
      "Training step  5191  of  100000  with loss  9.272464752197266\n",
      "Training step  5192  of  100000  with loss  10.374204635620117\n",
      "Training step  5193  of  100000  with loss  11.160318374633789\n",
      "Training step  5194  of  100000  with loss  10.454349517822266\n",
      "Training step  5195  of  100000  with loss  9.045618057250977\n",
      "Training step  5196  of  100000  with loss  9.554835319519043\n",
      "Training step  5197  of  100000  with loss  10.04707145690918\n",
      "Training step  5198  of  100000  with loss  10.3654146194458\n",
      "Training step  5199  of  100000  with loss  10.148883819580078\n",
      "Training step  5200  of  100000  with loss  10.741235733032227\n",
      "Training step  5201  of  100000  with loss  10.66905403137207\n",
      "Training step  5202  of  100000  with loss  9.340346336364746\n",
      "Training step  5203  of  100000  with loss  9.203710556030273\n",
      "Training step  5204  of  100000  with loss  9.153230667114258\n",
      "Training step  5205  of  100000  with loss  10.800483703613281\n",
      "Training step  5206  of  100000  with loss  9.710027694702148\n",
      "Training step  5207  of  100000  with loss  10.439812660217285\n",
      "Training step  5208  of  100000  with loss  9.81513500213623\n",
      "Training step  5209  of  100000  with loss  9.060699462890625\n",
      "Training step  5210  of  100000  with loss  9.844865798950195\n",
      "Training step  5211  of  100000  with loss  10.227617263793945\n",
      "Training step  5212  of  100000  with loss  9.069315910339355\n",
      "Training step  5213  of  100000  with loss  10.04553508758545\n",
      "Training step  5214  of  100000  with loss  9.558412551879883\n",
      "Training step  5215  of  100000  with loss  8.106327056884766\n",
      "Training step  5216  of  100000  with loss  10.66729736328125\n",
      "Training step  5217  of  100000  with loss  9.212980270385742\n",
      "Training step  5218  of  100000  with loss  10.468637466430664\n",
      "Training step  5219  of  100000  with loss  8.74666976928711\n",
      "Training step  5220  of  100000  with loss  10.744958877563477\n",
      "Training step  5221  of  100000  with loss  9.33682632446289\n",
      "Training step  5222  of  100000  with loss  9.13532829284668\n",
      "Training step  5223  of  100000  with loss  9.617263793945312\n",
      "Training step  5224  of  100000  with loss  9.748729705810547\n",
      "Training step  5225  of  100000  with loss  9.561408996582031\n",
      "Training step  5226  of  100000  with loss  9.655065536499023\n",
      "Training step  5227  of  100000  with loss  10.122425079345703\n",
      "Training step  5228  of  100000  with loss  9.685895919799805\n",
      "Training step  5229  of  100000  with loss  10.688042640686035\n",
      "Training step  5230  of  100000  with loss  8.989336967468262\n",
      "Training step  5231  of  100000  with loss  10.442049026489258\n",
      "Training step  5232  of  100000  with loss  10.31916332244873\n",
      "Training step  5233  of  100000  with loss  10.207842826843262\n",
      "Training step  5234  of  100000  with loss  9.243053436279297\n",
      "Training step  5235  of  100000  with loss  10.855195999145508\n",
      "Training step  5236  of  100000  with loss  8.401144981384277\n",
      "Training step  5237  of  100000  with loss  10.32139778137207\n",
      "Training step  5238  of  100000  with loss  9.410295486450195\n",
      "Training step  5239  of  100000  with loss  9.064581871032715\n",
      "Training step  5240  of  100000  with loss  9.830278396606445\n",
      "Training step  5241  of  100000  with loss  8.082070350646973\n",
      "Training step  5242  of  100000  with loss  10.130337715148926\n",
      "Training step  5243  of  100000  with loss  9.046469688415527\n",
      "Training step  5244  of  100000  with loss  10.251655578613281\n",
      "Training step  5245  of  100000  with loss  10.012364387512207\n",
      "Training step  5246  of  100000  with loss  12.862985610961914\n",
      "Training step  5247  of  100000  with loss  9.443136215209961\n",
      "Training step  5248  of  100000  with loss  9.24098014831543\n",
      "Training step  5249  of  100000  with loss  9.685103416442871\n",
      "Training step  5250  of  100000  with loss  10.936397552490234\n",
      "Training step  5251  of  100000  with loss  9.688028335571289\n",
      "Training step  5252  of  100000  with loss  10.237009048461914\n",
      "Training step  5253  of  100000  with loss  9.56892204284668\n",
      "Training step  5254  of  100000  with loss  9.742692947387695\n",
      "Training step  5255  of  100000  with loss  10.869634628295898\n",
      "Training step  5256  of  100000  with loss  9.828824043273926\n",
      "Training step  5257  of  100000  with loss  10.327302932739258\n",
      "Training step  5258  of  100000  with loss  10.515235900878906\n",
      "Training step  5259  of  100000  with loss  10.364997863769531\n",
      "Training step  5260  of  100000  with loss  10.391044616699219\n",
      "Training step  5261  of  100000  with loss  9.14094352722168\n",
      "Training step  5262  of  100000  with loss  11.534111976623535\n",
      "Training step  5263  of  100000  with loss  10.56393051147461\n",
      "Training step  5264  of  100000  with loss  10.443901062011719\n",
      "Training step  5265  of  100000  with loss  9.90499496459961\n",
      "Training step  5266  of  100000  with loss  10.749645233154297\n",
      "Training step  5267  of  100000  with loss  9.833259582519531\n",
      "Training step  5268  of  100000  with loss  11.067132949829102\n",
      "Training step  5269  of  100000  with loss  11.048349380493164\n",
      "Training step  5270  of  100000  with loss  9.752044677734375\n",
      "Training step  5271  of  100000  with loss  9.742162704467773\n",
      "Training step  5272  of  100000  with loss  10.190193176269531\n",
      "Training step  5273  of  100000  with loss  9.054584503173828\n",
      "Training step  5274  of  100000  with loss  10.798784255981445\n",
      "Training step  5275  of  100000  with loss  8.677362442016602\n",
      "Training step  5276  of  100000  with loss  10.4900541305542\n",
      "Training step  5277  of  100000  with loss  10.160407066345215\n",
      "Training step  5278  of  100000  with loss  9.478376388549805\n",
      "Training step  5279  of  100000  with loss  9.59825611114502\n",
      "Training step  5280  of  100000  with loss  9.525751113891602\n",
      "Training step  5281  of  100000  with loss  10.577749252319336\n",
      "Training step  5282  of  100000  with loss  9.922967910766602\n",
      "Training step  5283  of  100000  with loss  9.823967933654785\n",
      "Training step  5284  of  100000  with loss  9.592934608459473\n",
      "Training step  5285  of  100000  with loss  10.544642448425293\n",
      "Training step  5286  of  100000  with loss  9.49845027923584\n",
      "Training step  5287  of  100000  with loss  9.6427640914917\n",
      "Training step  5288  of  100000  with loss  8.936845779418945\n",
      "Training step  5289  of  100000  with loss  11.799750328063965\n",
      "Training step  5290  of  100000  with loss  9.027839660644531\n",
      "Training step  5291  of  100000  with loss  9.253706932067871\n",
      "Training step  5292  of  100000  with loss  10.49412727355957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5293  of  100000  with loss  9.469756126403809\n",
      "Training step  5294  of  100000  with loss  10.037816047668457\n",
      "Training step  5295  of  100000  with loss  11.372489929199219\n",
      "Training step  5296  of  100000  with loss  11.019546508789062\n",
      "Training step  5297  of  100000  with loss  9.047698974609375\n",
      "Training step  5298  of  100000  with loss  10.075946807861328\n",
      "Training step  5299  of  100000  with loss  10.809353828430176\n",
      "Training step  5300  of  100000  with loss  9.214555740356445\n",
      "Training step  5301  of  100000  with loss  12.078831672668457\n",
      "Training step  5302  of  100000  with loss  10.1680269241333\n",
      "Training step  5303  of  100000  with loss  8.455167770385742\n",
      "Training step  5304  of  100000  with loss  10.604525566101074\n",
      "Training step  5305  of  100000  with loss  10.720281600952148\n",
      "Training step  5306  of  100000  with loss  9.571722984313965\n",
      "Training step  5307  of  100000  with loss  9.496469497680664\n",
      "Training step  5308  of  100000  with loss  8.890790939331055\n",
      "Training step  5309  of  100000  with loss  8.478096008300781\n",
      "Training step  5310  of  100000  with loss  9.968191146850586\n",
      "Training step  5311  of  100000  with loss  10.187237739562988\n",
      "Training step  5312  of  100000  with loss  11.461220741271973\n",
      "Training step  5313  of  100000  with loss  9.525137901306152\n",
      "Training step  5314  of  100000  with loss  10.544301986694336\n",
      "Training step  5315  of  100000  with loss  9.96802806854248\n",
      "Training step  5316  of  100000  with loss  9.334260940551758\n",
      "Training step  5317  of  100000  with loss  9.659388542175293\n",
      "Training step  5318  of  100000  with loss  9.162408828735352\n",
      "Training step  5319  of  100000  with loss  9.512916564941406\n",
      "Training step  5320  of  100000  with loss  9.529099464416504\n",
      "Training step  5321  of  100000  with loss  9.70344352722168\n",
      "Training step  5322  of  100000  with loss  9.612733840942383\n",
      "Training step  5323  of  100000  with loss  9.716217041015625\n",
      "Training step  5324  of  100000  with loss  10.980182647705078\n",
      "Training step  5325  of  100000  with loss  9.655876159667969\n",
      "Training step  5326  of  100000  with loss  9.610627174377441\n",
      "Training step  5327  of  100000  with loss  10.964239120483398\n",
      "Training step  5328  of  100000  with loss  10.461466789245605\n",
      "Training step  5329  of  100000  with loss  9.746467590332031\n",
      "Training step  5330  of  100000  with loss  11.436620712280273\n",
      "Training step  5331  of  100000  with loss  9.151718139648438\n",
      "Training step  5332  of  100000  with loss  8.968683242797852\n",
      "Training step  5333  of  100000  with loss  9.804003715515137\n",
      "Training step  5334  of  100000  with loss  11.3568696975708\n",
      "Training step  5335  of  100000  with loss  11.091705322265625\n",
      "Training step  5336  of  100000  with loss  8.949197769165039\n",
      "Training step  5337  of  100000  with loss  9.875600814819336\n",
      "Training step  5338  of  100000  with loss  9.489821434020996\n",
      "Training step  5339  of  100000  with loss  10.524956703186035\n",
      "Training step  5340  of  100000  with loss  11.500787734985352\n",
      "Training step  5341  of  100000  with loss  9.979637145996094\n",
      "Training step  5342  of  100000  with loss  9.17850399017334\n",
      "Training step  5343  of  100000  with loss  11.851536750793457\n",
      "Training step  5344  of  100000  with loss  10.586565017700195\n",
      "Training step  5345  of  100000  with loss  10.400663375854492\n",
      "Training step  5346  of  100000  with loss  9.479354858398438\n",
      "Training step  5347  of  100000  with loss  10.110967636108398\n",
      "Training step  5348  of  100000  with loss  8.390663146972656\n",
      "Training step  5349  of  100000  with loss  8.847579002380371\n",
      "Training step  5350  of  100000  with loss  10.388591766357422\n",
      "Training step  5351  of  100000  with loss  9.676680564880371\n",
      "Training step  5352  of  100000  with loss  10.499900817871094\n",
      "Training step  5353  of  100000  with loss  9.35980224609375\n",
      "Training step  5354  of  100000  with loss  9.289608001708984\n",
      "Training step  5355  of  100000  with loss  10.824382781982422\n",
      "Training step  5356  of  100000  with loss  10.109977722167969\n",
      "Training step  5357  of  100000  with loss  8.858500480651855\n",
      "Training step  5358  of  100000  with loss  9.889498710632324\n",
      "Training step  5359  of  100000  with loss  9.19264030456543\n",
      "Training step  5360  of  100000  with loss  10.551234245300293\n",
      "Training step  5361  of  100000  with loss  8.560364723205566\n",
      "Training step  5362  of  100000  with loss  10.225404739379883\n",
      "Training step  5363  of  100000  with loss  9.537242889404297\n",
      "Training step  5364  of  100000  with loss  11.554652214050293\n",
      "Training step  5365  of  100000  with loss  9.247028350830078\n",
      "Training step  5366  of  100000  with loss  9.549385070800781\n",
      "Training step  5367  of  100000  with loss  11.040157318115234\n",
      "Training step  5368  of  100000  with loss  9.831323623657227\n",
      "Training step  5369  of  100000  with loss  11.321527481079102\n",
      "Training step  5370  of  100000  with loss  10.029882431030273\n",
      "Training step  5371  of  100000  with loss  9.399267196655273\n",
      "Training step  5372  of  100000  with loss  10.335359573364258\n",
      "Training step  5373  of  100000  with loss  9.983804702758789\n",
      "Training step  5374  of  100000  with loss  9.740266799926758\n",
      "Training step  5375  of  100000  with loss  10.921022415161133\n",
      "Training step  5376  of  100000  with loss  9.295927047729492\n",
      "Training step  5377  of  100000  with loss  10.619443893432617\n",
      "Training step  5378  of  100000  with loss  11.586624145507812\n",
      "Training step  5379  of  100000  with loss  8.291009902954102\n",
      "Training step  5380  of  100000  with loss  9.494638442993164\n",
      "Training step  5381  of  100000  with loss  9.505989074707031\n",
      "Training step  5382  of  100000  with loss  10.897887229919434\n",
      "Training step  5383  of  100000  with loss  10.255645751953125\n",
      "Training step  5384  of  100000  with loss  9.219280242919922\n",
      "Training step  5385  of  100000  with loss  10.741864204406738\n",
      "Training step  5386  of  100000  with loss  9.524040222167969\n",
      "Training step  5387  of  100000  with loss  9.237068176269531\n",
      "Training step  5388  of  100000  with loss  10.349825859069824\n",
      "Training step  5389  of  100000  with loss  10.019742965698242\n",
      "Training step  5390  of  100000  with loss  10.422208786010742\n",
      "Training step  5391  of  100000  with loss  10.417228698730469\n",
      "Training step  5392  of  100000  with loss  10.199981689453125\n",
      "Training step  5393  of  100000  with loss  10.575736045837402\n",
      "Training step  5394  of  100000  with loss  10.6300687789917\n",
      "Training step  5395  of  100000  with loss  9.482263565063477\n",
      "Training step  5396  of  100000  with loss  9.848609924316406\n",
      "Training step  5397  of  100000  with loss  11.03038501739502\n",
      "Training step  5398  of  100000  with loss  9.943727493286133\n",
      "Training step  5399  of  100000  with loss  9.31572151184082\n",
      "Training step  5400  of  100000  with loss  8.93996524810791\n",
      "Training step  5401  of  100000  with loss  10.591110229492188\n",
      "Training step  5402  of  100000  with loss  9.333076477050781\n",
      "Training step  5403  of  100000  with loss  9.337611198425293\n",
      "Training step  5404  of  100000  with loss  10.023796081542969\n",
      "Training step  5405  of  100000  with loss  9.395514488220215\n",
      "Training step  5406  of  100000  with loss  11.426050186157227\n",
      "Training step  5407  of  100000  with loss  8.317532539367676\n",
      "Training step  5408  of  100000  with loss  9.526975631713867\n",
      "Training step  5409  of  100000  with loss  10.814786911010742\n",
      "Training step  5410  of  100000  with loss  10.090211868286133\n",
      "Training step  5411  of  100000  with loss  10.989128112792969\n",
      "Training step  5412  of  100000  with loss  9.305715560913086\n",
      "Training step  5413  of  100000  with loss  9.999078750610352\n",
      "Training step  5414  of  100000  with loss  10.485151290893555\n",
      "Training step  5415  of  100000  with loss  11.035172462463379\n",
      "Training step  5416  of  100000  with loss  10.272072792053223\n",
      "Training step  5417  of  100000  with loss  9.188558578491211\n",
      "Training step  5418  of  100000  with loss  10.435733795166016\n",
      "Training step  5419  of  100000  with loss  9.460760116577148\n",
      "Training step  5420  of  100000  with loss  10.478044509887695\n",
      "Training step  5421  of  100000  with loss  10.25723648071289\n",
      "Training step  5422  of  100000  with loss  11.089940071105957\n",
      "Training step  5423  of  100000  with loss  10.641462326049805\n",
      "Training step  5424  of  100000  with loss  9.873498916625977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5425  of  100000  with loss  9.826560020446777\n",
      "Training step  5426  of  100000  with loss  9.788091659545898\n",
      "Training step  5427  of  100000  with loss  9.643242835998535\n",
      "Training step  5428  of  100000  with loss  9.333488464355469\n",
      "Training step  5429  of  100000  with loss  8.572295188903809\n",
      "Training step  5430  of  100000  with loss  9.36591911315918\n",
      "Training step  5431  of  100000  with loss  9.362724304199219\n",
      "Training step  5432  of  100000  with loss  8.811410903930664\n",
      "Training step  5433  of  100000  with loss  9.968683242797852\n",
      "Training step  5434  of  100000  with loss  10.630759239196777\n",
      "Training step  5435  of  100000  with loss  9.282407760620117\n",
      "Training step  5436  of  100000  with loss  10.40601634979248\n",
      "Training step  5437  of  100000  with loss  10.739561080932617\n",
      "Training step  5438  of  100000  with loss  10.857486724853516\n",
      "Training step  5439  of  100000  with loss  10.628717422485352\n",
      "Training step  5440  of  100000  with loss  10.92681884765625\n",
      "Training step  5441  of  100000  with loss  9.627336502075195\n",
      "Training step  5442  of  100000  with loss  10.041693687438965\n",
      "Training step  5443  of  100000  with loss  10.181451797485352\n",
      "Training step  5444  of  100000  with loss  9.435884475708008\n",
      "Training step  5445  of  100000  with loss  8.952829360961914\n",
      "Training step  5446  of  100000  with loss  9.61562442779541\n",
      "Training step  5447  of  100000  with loss  9.673794746398926\n",
      "Training step  5448  of  100000  with loss  9.372410774230957\n",
      "Training step  5449  of  100000  with loss  10.81086254119873\n",
      "Training step  5450  of  100000  with loss  9.935089111328125\n",
      "Training step  5451  of  100000  with loss  10.386507034301758\n",
      "Training step  5452  of  100000  with loss  9.896370887756348\n",
      "Training step  5453  of  100000  with loss  10.267895698547363\n",
      "Training step  5454  of  100000  with loss  8.822303771972656\n",
      "Training step  5455  of  100000  with loss  11.129061698913574\n",
      "Training step  5456  of  100000  with loss  9.3512601852417\n",
      "Training step  5457  of  100000  with loss  9.931676864624023\n",
      "Training step  5458  of  100000  with loss  8.26422119140625\n",
      "Training step  5459  of  100000  with loss  9.918022155761719\n",
      "Training step  5460  of  100000  with loss  9.398723602294922\n",
      "Training step  5461  of  100000  with loss  10.131522178649902\n",
      "Training step  5462  of  100000  with loss  9.778560638427734\n",
      "Training step  5463  of  100000  with loss  8.324300765991211\n",
      "Training step  5464  of  100000  with loss  10.241289138793945\n",
      "Training step  5465  of  100000  with loss  11.560966491699219\n",
      "Training step  5466  of  100000  with loss  9.696357727050781\n",
      "Training step  5467  of  100000  with loss  11.700054168701172\n",
      "Training step  5468  of  100000  with loss  10.433679580688477\n",
      "Training step  5469  of  100000  with loss  9.393035888671875\n",
      "Training step  5470  of  100000  with loss  10.732444763183594\n",
      "Training step  5471  of  100000  with loss  9.421852111816406\n",
      "Training step  5472  of  100000  with loss  10.940468788146973\n",
      "Training step  5473  of  100000  with loss  8.999478340148926\n",
      "Training step  5474  of  100000  with loss  9.959091186523438\n",
      "Training step  5475  of  100000  with loss  10.411433219909668\n",
      "Training step  5476  of  100000  with loss  9.687726974487305\n",
      "Training step  5477  of  100000  with loss  9.118462562561035\n",
      "Training step  5478  of  100000  with loss  11.136967658996582\n",
      "Training step  5479  of  100000  with loss  9.39394474029541\n",
      "Training step  5480  of  100000  with loss  9.421972274780273\n",
      "Training step  5481  of  100000  with loss  9.440488815307617\n",
      "Training step  5482  of  100000  with loss  10.040040969848633\n",
      "Training step  5483  of  100000  with loss  9.865682601928711\n",
      "Training step  5484  of  100000  with loss  11.644892692565918\n",
      "Training step  5485  of  100000  with loss  10.395732879638672\n",
      "Training step  5486  of  100000  with loss  10.752630233764648\n",
      "Training step  5487  of  100000  with loss  10.66744327545166\n",
      "Training step  5488  of  100000  with loss  11.723393440246582\n",
      "Training step  5489  of  100000  with loss  10.250354766845703\n",
      "Training step  5490  of  100000  with loss  10.063241004943848\n",
      "Training step  5491  of  100000  with loss  10.151595115661621\n",
      "Training step  5492  of  100000  with loss  9.337264060974121\n",
      "Training step  5493  of  100000  with loss  10.112104415893555\n",
      "Training step  5494  of  100000  with loss  11.149343490600586\n",
      "Training step  5495  of  100000  with loss  8.552939414978027\n",
      "Training step  5496  of  100000  with loss  10.245216369628906\n",
      "Training step  5497  of  100000  with loss  10.194971084594727\n",
      "Training step  5498  of  100000  with loss  10.191658020019531\n",
      "Training step  5499  of  100000  with loss  9.63865852355957\n",
      "Training step  5500  of  100000  with loss  9.832480430603027\n",
      "Training step  5501  of  100000  with loss  10.318086624145508\n",
      "Training step  5502  of  100000  with loss  9.036977767944336\n",
      "Training step  5503  of  100000  with loss  9.695594787597656\n",
      "Training step  5504  of  100000  with loss  9.541318893432617\n",
      "Training step  5505  of  100000  with loss  10.431144714355469\n",
      "Training step  5506  of  100000  with loss  9.381902694702148\n",
      "Training step  5507  of  100000  with loss  8.782487869262695\n",
      "Training step  5508  of  100000  with loss  8.935707092285156\n",
      "Training step  5509  of  100000  with loss  8.752376556396484\n",
      "Training step  5510  of  100000  with loss  10.750734329223633\n",
      "Training step  5511  of  100000  with loss  9.670646667480469\n",
      "Training step  5512  of  100000  with loss  9.891156196594238\n",
      "Training step  5513  of  100000  with loss  10.038360595703125\n",
      "Training step  5514  of  100000  with loss  10.168990135192871\n",
      "Training step  5515  of  100000  with loss  9.468585014343262\n",
      "Training step  5516  of  100000  with loss  11.294212341308594\n",
      "Training step  5517  of  100000  with loss  9.38548469543457\n",
      "Training step  5518  of  100000  with loss  11.132147789001465\n",
      "Training step  5519  of  100000  with loss  10.031264305114746\n",
      "Training step  5520  of  100000  with loss  11.468013763427734\n",
      "Training step  5521  of  100000  with loss  10.297416687011719\n",
      "Training step  5522  of  100000  with loss  9.004955291748047\n",
      "Training step  5523  of  100000  with loss  10.164436340332031\n",
      "Training step  5524  of  100000  with loss  9.865586280822754\n",
      "Training step  5525  of  100000  with loss  10.197105407714844\n",
      "Training step  5526  of  100000  with loss  10.330757141113281\n",
      "Training step  5527  of  100000  with loss  9.465627670288086\n",
      "Training step  5528  of  100000  with loss  12.53342056274414\n",
      "Training step  5529  of  100000  with loss  10.308377265930176\n",
      "Training step  5530  of  100000  with loss  10.612471580505371\n",
      "Training step  5531  of  100000  with loss  9.586376190185547\n",
      "Training step  5532  of  100000  with loss  10.448284149169922\n",
      "Training step  5533  of  100000  with loss  10.948709487915039\n",
      "Training step  5534  of  100000  with loss  10.428428649902344\n",
      "Training step  5535  of  100000  with loss  9.225128173828125\n",
      "Training step  5536  of  100000  with loss  11.342635154724121\n",
      "Training step  5537  of  100000  with loss  10.373335838317871\n",
      "Training step  5538  of  100000  with loss  10.135775566101074\n",
      "Training step  5539  of  100000  with loss  10.798399925231934\n",
      "Training step  5540  of  100000  with loss  9.043376922607422\n",
      "Training step  5541  of  100000  with loss  9.618961334228516\n",
      "Training step  5542  of  100000  with loss  10.012063980102539\n",
      "Training step  5543  of  100000  with loss  10.008451461791992\n",
      "Training step  5544  of  100000  with loss  10.258771896362305\n",
      "Training step  5545  of  100000  with loss  9.81333065032959\n",
      "Training step  5546  of  100000  with loss  10.433175086975098\n",
      "Training step  5547  of  100000  with loss  9.910027503967285\n",
      "Training step  5548  of  100000  with loss  9.423320770263672\n",
      "Training step  5549  of  100000  with loss  9.109033584594727\n",
      "Training step  5550  of  100000  with loss  10.295133590698242\n",
      "Training step  5551  of  100000  with loss  10.375658988952637\n",
      "Training step  5552  of  100000  with loss  10.86005973815918\n",
      "Training step  5553  of  100000  with loss  10.134489059448242\n",
      "Training step  5554  of  100000  with loss  10.035036087036133\n",
      "Training step  5555  of  100000  with loss  9.696678161621094\n",
      "Training step  5556  of  100000  with loss  9.736286163330078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5557  of  100000  with loss  9.559284210205078\n",
      "Training step  5558  of  100000  with loss  8.446537971496582\n",
      "Training step  5559  of  100000  with loss  9.457221984863281\n",
      "Training step  5560  of  100000  with loss  10.043050765991211\n",
      "Training step  5561  of  100000  with loss  10.902681350708008\n",
      "Training step  5562  of  100000  with loss  11.436840057373047\n",
      "Training step  5563  of  100000  with loss  9.982864379882812\n",
      "Training step  5564  of  100000  with loss  9.636985778808594\n",
      "Training step  5565  of  100000  with loss  9.84273910522461\n",
      "Training step  5566  of  100000  with loss  9.967805862426758\n",
      "Training step  5567  of  100000  with loss  9.737488746643066\n",
      "Training step  5568  of  100000  with loss  8.90349006652832\n",
      "Training step  5569  of  100000  with loss  10.233125686645508\n",
      "Training step  5570  of  100000  with loss  10.73939323425293\n",
      "Training step  5571  of  100000  with loss  10.039070129394531\n",
      "Training step  5572  of  100000  with loss  8.535747528076172\n",
      "Training step  5573  of  100000  with loss  9.969922065734863\n",
      "Training step  5574  of  100000  with loss  9.427584648132324\n",
      "Training step  5575  of  100000  with loss  9.625946998596191\n",
      "Training step  5576  of  100000  with loss  11.749166488647461\n",
      "Training step  5577  of  100000  with loss  8.968278884887695\n",
      "Training step  5578  of  100000  with loss  9.001583099365234\n",
      "Training step  5579  of  100000  with loss  10.227472305297852\n",
      "Training step  5580  of  100000  with loss  9.902212142944336\n",
      "Training step  5581  of  100000  with loss  10.384052276611328\n",
      "Training step  5582  of  100000  with loss  9.473873138427734\n",
      "Training step  5583  of  100000  with loss  10.174102783203125\n",
      "Training step  5584  of  100000  with loss  9.148881912231445\n",
      "Training step  5585  of  100000  with loss  10.34394359588623\n",
      "Training step  5586  of  100000  with loss  10.528369903564453\n",
      "Training step  5587  of  100000  with loss  9.061264991760254\n",
      "Training step  5588  of  100000  with loss  10.604671478271484\n",
      "Training step  5589  of  100000  with loss  9.640310287475586\n",
      "Training step  5590  of  100000  with loss  9.664612770080566\n",
      "Training step  5591  of  100000  with loss  9.48442268371582\n",
      "Training step  5592  of  100000  with loss  9.690898895263672\n",
      "Training step  5593  of  100000  with loss  8.947820663452148\n",
      "Training step  5594  of  100000  with loss  10.795854568481445\n",
      "Training step  5595  of  100000  with loss  10.552305221557617\n",
      "Training step  5596  of  100000  with loss  10.08632755279541\n",
      "Training step  5597  of  100000  with loss  10.658272743225098\n",
      "Training step  5598  of  100000  with loss  11.403627395629883\n",
      "Training step  5599  of  100000  with loss  10.082818031311035\n",
      "Training step  5600  of  100000  with loss  9.558052062988281\n",
      "Training step  5601  of  100000  with loss  8.807657241821289\n",
      "Training step  5602  of  100000  with loss  9.800703048706055\n",
      "Training step  5603  of  100000  with loss  10.873462677001953\n",
      "Training step  5604  of  100000  with loss  11.153100967407227\n",
      "Training step  5605  of  100000  with loss  10.323848724365234\n",
      "Training step  5606  of  100000  with loss  11.027921676635742\n",
      "Training step  5607  of  100000  with loss  9.079906463623047\n",
      "Training step  5608  of  100000  with loss  8.959288597106934\n",
      "Training step  5609  of  100000  with loss  9.336030960083008\n",
      "Training step  5610  of  100000  with loss  10.250709533691406\n",
      "Training step  5611  of  100000  with loss  9.820201873779297\n",
      "Training step  5612  of  100000  with loss  9.546609878540039\n",
      "Training step  5613  of  100000  with loss  10.776676177978516\n",
      "Training step  5614  of  100000  with loss  11.191390037536621\n",
      "Training step  5615  of  100000  with loss  8.825627326965332\n",
      "Training step  5616  of  100000  with loss  9.943559646606445\n",
      "Training step  5617  of  100000  with loss  9.20461654663086\n",
      "Training step  5618  of  100000  with loss  9.994297981262207\n",
      "Training step  5619  of  100000  with loss  10.47075080871582\n",
      "Training step  5620  of  100000  with loss  10.76278305053711\n",
      "Training step  5621  of  100000  with loss  9.72123908996582\n",
      "Training step  5622  of  100000  with loss  11.037580490112305\n",
      "Training step  5623  of  100000  with loss  11.375463485717773\n",
      "Training step  5624  of  100000  with loss  9.089508056640625\n",
      "Training step  5625  of  100000  with loss  10.071146011352539\n",
      "Training step  5626  of  100000  with loss  11.553764343261719\n",
      "Training step  5627  of  100000  with loss  12.112691879272461\n",
      "Training step  5628  of  100000  with loss  10.94629192352295\n",
      "Training step  5629  of  100000  with loss  9.899087905883789\n",
      "Training step  5630  of  100000  with loss  8.593330383300781\n",
      "Training step  5631  of  100000  with loss  10.09538459777832\n",
      "Training step  5632  of  100000  with loss  11.23564624786377\n",
      "Training step  5633  of  100000  with loss  9.696002960205078\n",
      "Training step  5634  of  100000  with loss  9.110448837280273\n",
      "Training step  5635  of  100000  with loss  10.299156188964844\n",
      "Training step  5636  of  100000  with loss  9.344781875610352\n",
      "Training step  5637  of  100000  with loss  10.711555480957031\n",
      "Training step  5638  of  100000  with loss  10.674637794494629\n",
      "Training step  5639  of  100000  with loss  10.612236022949219\n",
      "Training step  5640  of  100000  with loss  11.23874568939209\n",
      "Training step  5641  of  100000  with loss  9.088444709777832\n",
      "Training step  5642  of  100000  with loss  8.369407653808594\n",
      "Training step  5643  of  100000  with loss  10.716764450073242\n",
      "Training step  5644  of  100000  with loss  11.12374496459961\n",
      "Training step  5645  of  100000  with loss  10.071691513061523\n",
      "Training step  5646  of  100000  with loss  10.375675201416016\n",
      "Training step  5647  of  100000  with loss  9.833662033081055\n",
      "Training step  5648  of  100000  with loss  9.166775703430176\n",
      "Training step  5649  of  100000  with loss  10.28891372680664\n",
      "Training step  5650  of  100000  with loss  10.793033599853516\n",
      "Training step  5651  of  100000  with loss  9.139545440673828\n",
      "Training step  5652  of  100000  with loss  9.811283111572266\n",
      "Training step  5653  of  100000  with loss  10.53005313873291\n",
      "Training step  5654  of  100000  with loss  9.654598236083984\n",
      "Training step  5655  of  100000  with loss  9.602874755859375\n",
      "Training step  5656  of  100000  with loss  9.170381546020508\n",
      "Training step  5657  of  100000  with loss  10.285395622253418\n",
      "Training step  5658  of  100000  with loss  11.016427993774414\n",
      "Training step  5659  of  100000  with loss  9.02554702758789\n",
      "Training step  5660  of  100000  with loss  8.586633682250977\n",
      "Training step  5661  of  100000  with loss  10.308719635009766\n",
      "Training step  5662  of  100000  with loss  8.72113037109375\n",
      "Training step  5663  of  100000  with loss  8.499866485595703\n",
      "Training step  5664  of  100000  with loss  9.611364364624023\n",
      "Training step  5665  of  100000  with loss  9.361404418945312\n",
      "Training step  5666  of  100000  with loss  9.75739574432373\n",
      "Training step  5667  of  100000  with loss  9.406026840209961\n",
      "Training step  5668  of  100000  with loss  10.088211059570312\n",
      "Training step  5669  of  100000  with loss  10.010774612426758\n",
      "Training step  5670  of  100000  with loss  9.777627944946289\n",
      "Training step  5671  of  100000  with loss  9.954790115356445\n",
      "Training step  5672  of  100000  with loss  10.372127532958984\n",
      "Training step  5673  of  100000  with loss  9.909984588623047\n",
      "Training step  5674  of  100000  with loss  10.74867057800293\n",
      "Training step  5675  of  100000  with loss  9.162416458129883\n",
      "Training step  5676  of  100000  with loss  9.825102806091309\n",
      "Training step  5677  of  100000  with loss  10.948343276977539\n",
      "Training step  5678  of  100000  with loss  9.45722484588623\n",
      "Training step  5679  of  100000  with loss  9.757950782775879\n",
      "Training step  5680  of  100000  with loss  10.917606353759766\n",
      "Training step  5681  of  100000  with loss  10.95989990234375\n",
      "Training step  5682  of  100000  with loss  9.703838348388672\n",
      "Training step  5683  of  100000  with loss  9.153343200683594\n",
      "Training step  5684  of  100000  with loss  10.719759941101074\n",
      "Training step  5685  of  100000  with loss  10.106878280639648\n",
      "Training step  5686  of  100000  with loss  10.519657135009766\n",
      "Training step  5687  of  100000  with loss  8.912652969360352\n",
      "Training step  5688  of  100000  with loss  10.494940757751465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5689  of  100000  with loss  10.020195960998535\n",
      "Training step  5690  of  100000  with loss  10.415895462036133\n",
      "Training step  5691  of  100000  with loss  9.710322380065918\n",
      "Training step  5692  of  100000  with loss  10.445195198059082\n",
      "Training step  5693  of  100000  with loss  11.080669403076172\n",
      "Training step  5694  of  100000  with loss  9.849540710449219\n",
      "Training step  5695  of  100000  with loss  9.310627937316895\n",
      "Training step  5696  of  100000  with loss  10.86663818359375\n",
      "Training step  5697  of  100000  with loss  10.33059024810791\n",
      "Training step  5698  of  100000  with loss  9.949666976928711\n",
      "Training step  5699  of  100000  with loss  10.346395492553711\n",
      "Training step  5700  of  100000  with loss  8.49976921081543\n",
      "Training step  5701  of  100000  with loss  10.295238494873047\n",
      "Training step  5702  of  100000  with loss  9.084062576293945\n",
      "Training step  5703  of  100000  with loss  11.048797607421875\n",
      "Training step  5704  of  100000  with loss  10.931863784790039\n",
      "Training step  5705  of  100000  with loss  10.730215072631836\n",
      "Training step  5706  of  100000  with loss  10.505392074584961\n",
      "Training step  5707  of  100000  with loss  11.086424827575684\n",
      "Training step  5708  of  100000  with loss  10.527525901794434\n",
      "Training step  5709  of  100000  with loss  8.864747047424316\n",
      "Training step  5710  of  100000  with loss  10.934870719909668\n",
      "Training step  5711  of  100000  with loss  10.22802448272705\n",
      "Training step  5712  of  100000  with loss  10.936312675476074\n",
      "Training step  5713  of  100000  with loss  9.736564636230469\n",
      "Training step  5714  of  100000  with loss  9.415236473083496\n",
      "Training step  5715  of  100000  with loss  10.554378509521484\n",
      "Training step  5716  of  100000  with loss  10.515405654907227\n",
      "Training step  5717  of  100000  with loss  11.084696769714355\n",
      "Training step  5718  of  100000  with loss  9.827765464782715\n",
      "Training step  5719  of  100000  with loss  12.555442810058594\n",
      "Training step  5720  of  100000  with loss  10.662139892578125\n",
      "Training step  5721  of  100000  with loss  8.921574592590332\n",
      "Training step  5722  of  100000  with loss  10.330150604248047\n",
      "Training step  5723  of  100000  with loss  9.045133590698242\n",
      "Training step  5724  of  100000  with loss  8.709065437316895\n",
      "Training step  5725  of  100000  with loss  10.401187896728516\n",
      "Training step  5726  of  100000  with loss  12.242912292480469\n",
      "Training step  5727  of  100000  with loss  10.408580780029297\n",
      "Training step  5728  of  100000  with loss  9.141944885253906\n",
      "Training step  5729  of  100000  with loss  9.839798927307129\n",
      "Training step  5730  of  100000  with loss  9.939676284790039\n",
      "Training step  5731  of  100000  with loss  10.338737487792969\n",
      "Training step  5732  of  100000  with loss  11.538488388061523\n",
      "Training step  5733  of  100000  with loss  10.235685348510742\n",
      "Training step  5734  of  100000  with loss  11.17231559753418\n",
      "Training step  5735  of  100000  with loss  9.588501930236816\n",
      "Training step  5736  of  100000  with loss  8.757573127746582\n",
      "Training step  5737  of  100000  with loss  10.656331062316895\n",
      "Training step  5738  of  100000  with loss  11.038978576660156\n",
      "Training step  5739  of  100000  with loss  10.031720161437988\n",
      "Training step  5740  of  100000  with loss  10.657705307006836\n",
      "Training step  5741  of  100000  with loss  10.919745445251465\n",
      "Training step  5742  of  100000  with loss  10.336261749267578\n",
      "Training step  5743  of  100000  with loss  10.826395034790039\n",
      "Training step  5744  of  100000  with loss  10.257378578186035\n",
      "Training step  5745  of  100000  with loss  9.66182804107666\n",
      "Training step  5746  of  100000  with loss  10.031031608581543\n",
      "Training step  5747  of  100000  with loss  8.71983528137207\n",
      "Training step  5748  of  100000  with loss  10.482158660888672\n",
      "Training step  5749  of  100000  with loss  8.999692916870117\n",
      "Training step  5750  of  100000  with loss  9.327966690063477\n",
      "Training step  5751  of  100000  with loss  9.89208984375\n",
      "Training step  5752  of  100000  with loss  10.67851448059082\n",
      "Training step  5753  of  100000  with loss  11.43275260925293\n",
      "Training step  5754  of  100000  with loss  9.36050033569336\n",
      "Training step  5755  of  100000  with loss  9.332049369812012\n",
      "Training step  5756  of  100000  with loss  10.480592727661133\n",
      "Training step  5757  of  100000  with loss  9.868965148925781\n",
      "Training step  5758  of  100000  with loss  9.149221420288086\n",
      "Training step  5759  of  100000  with loss  9.535813331604004\n",
      "Training step  5760  of  100000  with loss  11.027868270874023\n",
      "Training step  5761  of  100000  with loss  10.077492713928223\n",
      "Training step  5762  of  100000  with loss  10.098909378051758\n",
      "Training step  5763  of  100000  with loss  10.20863151550293\n",
      "Training step  5764  of  100000  with loss  9.061697006225586\n",
      "Training step  5765  of  100000  with loss  9.863382339477539\n",
      "Training step  5766  of  100000  with loss  9.13101577758789\n",
      "Training step  5767  of  100000  with loss  10.833717346191406\n",
      "Training step  5768  of  100000  with loss  9.851597785949707\n",
      "Training step  5769  of  100000  with loss  10.441732406616211\n",
      "Training step  5770  of  100000  with loss  9.538408279418945\n",
      "Training step  5771  of  100000  with loss  9.620626449584961\n",
      "Training step  5772  of  100000  with loss  9.6653413772583\n",
      "Training step  5773  of  100000  with loss  10.349542617797852\n",
      "Training step  5774  of  100000  with loss  10.504098892211914\n",
      "Training step  5775  of  100000  with loss  9.028114318847656\n",
      "Training step  5776  of  100000  with loss  10.338967323303223\n",
      "Training step  5777  of  100000  with loss  10.873214721679688\n",
      "Training step  5778  of  100000  with loss  9.378925323486328\n",
      "Training step  5779  of  100000  with loss  9.496757507324219\n",
      "Training step  5780  of  100000  with loss  10.563830375671387\n",
      "Training step  5781  of  100000  with loss  9.5204439163208\n",
      "Training step  5782  of  100000  with loss  10.656450271606445\n",
      "Training step  5783  of  100000  with loss  9.275141716003418\n",
      "Training step  5784  of  100000  with loss  10.117401123046875\n",
      "Training step  5785  of  100000  with loss  10.762474060058594\n",
      "Training step  5786  of  100000  with loss  9.350265502929688\n",
      "Training step  5787  of  100000  with loss  8.722672462463379\n",
      "Training step  5788  of  100000  with loss  8.901068687438965\n",
      "Training step  5789  of  100000  with loss  9.96440315246582\n",
      "Training step  5790  of  100000  with loss  10.691204071044922\n",
      "Training step  5791  of  100000  with loss  10.346932411193848\n",
      "Training step  5792  of  100000  with loss  10.581727027893066\n",
      "Training step  5793  of  100000  with loss  9.657309532165527\n",
      "Training step  5794  of  100000  with loss  10.78634262084961\n",
      "Training step  5795  of  100000  with loss  9.916321754455566\n",
      "Training step  5796  of  100000  with loss  9.814865112304688\n",
      "Training step  5797  of  100000  with loss  9.732731819152832\n",
      "Training step  5798  of  100000  with loss  10.290112495422363\n",
      "Training step  5799  of  100000  with loss  10.180091857910156\n",
      "Training step  5800  of  100000  with loss  8.68157958984375\n",
      "Training step  5801  of  100000  with loss  9.3036470413208\n",
      "Training step  5802  of  100000  with loss  10.110145568847656\n",
      "Training step  5803  of  100000  with loss  9.125089645385742\n",
      "Training step  5804  of  100000  with loss  10.050338745117188\n",
      "Training step  5805  of  100000  with loss  9.304909706115723\n",
      "Training step  5806  of  100000  with loss  9.416299819946289\n",
      "Training step  5807  of  100000  with loss  8.877017974853516\n",
      "Training step  5808  of  100000  with loss  9.15893268585205\n",
      "Training step  5809  of  100000  with loss  12.318624496459961\n",
      "Training step  5810  of  100000  with loss  9.918021202087402\n",
      "Training step  5811  of  100000  with loss  10.804946899414062\n",
      "Training step  5812  of  100000  with loss  9.763806343078613\n",
      "Training step  5813  of  100000  with loss  10.478250503540039\n",
      "Training step  5814  of  100000  with loss  10.310859680175781\n",
      "Training step  5815  of  100000  with loss  11.535868644714355\n",
      "Training step  5816  of  100000  with loss  8.780499458312988\n",
      "Training step  5817  of  100000  with loss  10.960845947265625\n",
      "Training step  5818  of  100000  with loss  10.459141731262207\n",
      "Training step  5819  of  100000  with loss  10.238495826721191\n",
      "Training step  5820  of  100000  with loss  9.466794967651367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step  5821  of  100000  with loss  10.228574752807617\n",
      "Training step  5822  of  100000  with loss  10.853724479675293\n",
      "Training step  5823  of  100000  with loss  9.735176086425781\n",
      "Training step  5824  of  100000  with loss  10.913928985595703\n",
      "Training step  5825  of  100000  with loss  11.407281875610352\n",
      "Training step  5826  of  100000  with loss  10.692718505859375\n",
      "Training step  5827  of  100000  with loss  9.115845680236816\n",
      "Training step  5828  of  100000  with loss  10.024150848388672\n",
      "Training step  5829  of  100000  with loss  9.964813232421875\n",
      "Training step  5830  of  100000  with loss  9.905853271484375\n",
      "Training step  5831  of  100000  with loss  9.999879837036133\n",
      "Training step  5832  of  100000  with loss  10.846918106079102\n",
      "Training step  5833  of  100000  with loss  9.30868148803711\n",
      "Training step  5834  of  100000  with loss  10.138010025024414\n",
      "Training step  5835  of  100000  with loss  10.4908447265625\n",
      "Training step  5836  of  100000  with loss  10.60083293914795\n",
      "Training step  5837  of  100000  with loss  10.469125747680664\n",
      "Training step  5838  of  100000  with loss  9.019411087036133\n",
      "Training step  5839  of  100000  with loss  10.375349044799805\n",
      "Training step  5840  of  100000  with loss  11.556894302368164\n",
      "Training step  5841  of  100000  with loss  9.942523956298828\n",
      "Training step  5842  of  100000  with loss  9.227516174316406\n",
      "Training step  5843  of  100000  with loss  9.366239547729492\n",
      "Training step  5844  of  100000  with loss  10.398397445678711\n",
      "Training step  5845  of  100000  with loss  11.480782508850098\n",
      "Training step  5846  of  100000  with loss  9.899528503417969\n",
      "Training step  5847  of  100000  with loss  10.470712661743164\n",
      "Training step  5848  of  100000  with loss  10.463149070739746\n",
      "Training step  5849  of  100000  with loss  9.574480056762695\n",
      "Training step  5850  of  100000  with loss  11.747708320617676\n",
      "Training step  5851  of  100000  with loss  9.400672912597656\n",
      "Training step  5852  of  100000  with loss  9.721328735351562\n",
      "Training step  5853  of  100000  with loss  8.964417457580566\n",
      "Training step  5854  of  100000  with loss  9.724058151245117\n",
      "Training step  5855  of  100000  with loss  8.799005508422852\n",
      "Training step  5856  of  100000  with loss  11.762097358703613\n",
      "Training step  5857  of  100000  with loss  11.805366516113281\n",
      "Training step  5858  of  100000  with loss  11.284022331237793\n",
      "Training step  5859  of  100000  with loss  10.523927688598633\n",
      "Training step  5860  of  100000  with loss  9.531242370605469\n",
      "Training step  5861  of  100000  with loss  10.118006706237793\n",
      "Training step  5862  of  100000  with loss  10.567497253417969\n",
      "Training step  5863  of  100000  with loss  10.534692764282227\n",
      "Training step  5864  of  100000  with loss  10.80435848236084\n",
      "Training step  5865  of  100000  with loss  10.118058204650879\n",
      "Training step  5866  of  100000  with loss  11.418907165527344\n",
      "Training step  5867  of  100000  with loss  11.405752182006836\n",
      "Training step  5868  of  100000  with loss  9.456398010253906\n",
      "Training step  5869  of  100000  with loss  9.152029037475586\n",
      "Training step  5870  of  100000  with loss  9.478134155273438\n",
      "Training step  5871  of  100000  with loss  9.929845809936523\n",
      "Training step  5872  of  100000  with loss  9.484601974487305\n",
      "Training step  5873  of  100000  with loss  9.605259895324707\n",
      "Training step  5874  of  100000  with loss  9.209274291992188\n",
      "Training step  5875  of  100000  with loss  8.69239616394043\n",
      "Training step  5876  of  100000  with loss  9.233097076416016\n",
      "Training step  5877  of  100000  with loss  10.313673973083496\n",
      "Training step  5878  of  100000  with loss  10.602076530456543\n",
      "Training step  5879  of  100000  with loss  10.176342010498047\n"
     ]
    }
   ],
   "source": [
    "myloss = LpLoss(size_average=False)\n",
    "train_mse = 0\n",
    "train_l2 = 0\n",
    "S = T_in = T = 64 \n",
    "for i in range(10000):\n",
    "    model.train()\n",
    "    # Loading data\n",
    "    voxels_batch, divergence_tensor_batch = loader_train.generate_data()\n",
    "    \n",
    "    voxels_batch = torch.Tensor(voxels_batch).cuda()\n",
    "    divergence_tensor_batch = torch.Tensor(divergence_tensor_batch).cuda()\n",
    "    \n",
    "    div_normalizer = UnitGaussianNormalizer(divergence_tensor_batch)\n",
    "    divergence_tensor_batch = div_normalizer.encode(divergence_tensor_batch)\n",
    "    \n",
    "    vox_normalizer = UnitGaussianNormalizer(voxels_batch)\n",
    "    voxels_batch = vox_normalizer.encode(voxels_batch)\n",
    "    \n",
    "    divergence_tensor_batch_resh = divergence_tensor_batch.reshape(batch_size,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pred = model(divergence_tensor_batch_resh).view(batch_size, S, S, T)\n",
    "\n",
    "    mse = F.mse_loss(pred, voxels_batch, reduction='mean')\n",
    "    \n",
    "    voxels_batch = vox_normalizer.decode(voxels_batch)\n",
    "    pred = div_normalizer.decode(pred)\n",
    "    l2 = myloss(pred.view(batch_size, -1), voxels_batch.view(batch_size, -1))\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print('Training step ', i, ' of ', 100000, ' with loss ', l2.cpu().detach().numpy())\n",
    "    \n",
    "    if l2 < best_loss:\n",
    "        print(\"Saving checkpoints\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        best_loss = l2\n",
    "        \n",
    "    l2.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2e6c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57524ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
